[
  {
    "objectID": "dataviz.html",
    "href": "dataviz.html",
    "title": "Data Visualisation",
    "section": "",
    "text": "Why do we visualise data? For data to tell us something we need to look for patterns, and we are much better at finding these patterns in colours and shapes than in a table of raw data. Visualisations are key to developing the story we want to tell with our data.\nWhen do we visualise data? There are two main moments when working with data that we need to visualise it. First, in the exploratory phase, when we are trying to understand the data, to get insights that lead to fruitful lines of enquiry. These visualisations are rough and ready, meant for us or at most a select few around us to generate debate about what information the data might contain.\nSecond, in the explanatory phase, when we have understood the data and move on to insightful analyses that generate new understanding. These visualisations communicate what we have learned from the data to others. They need to be clear, because we are trying to explain conclusions we have made from intimate knowledge of the data to people who have not worked with it, and are trusting us to explain faithfully what we have learned.\nIn libraries this covers visualisations for users of our services designed to improve content discovery and so they can understand our data, as well as research carried out by librarians and digital humanists that generates new knowledge. Particularly for our users, whose needs should be at the heart of the services we supply, visual routes we supply into our data need to be as clear as anything we’re presenting as research.\nHow do we visualise data? There are a huge variety of tools available. Practitioners may lovingly hand draw images (physically or digitally), from early 19th century visualisations by Florence Nightingale and W. E. B. Du Bois to the work, verging on art, of Federica Fragapane. More commonly there are deeply customisable packages in modern programming languages like R, Python or Javascript, or commercial plotting software like Tableau. Excel has endured through its simple learning curve, ubiquity and reliable outputs. A whole separate suite of software exists for geospatial and linked data. Ultimately the right choice is decided by our use case, data, resources and skills.",
    "crumbs": [
      "TOPIC GUIDES",
      "Data Visualisation"
    ]
  },
  {
    "objectID": "dataviz.html#introduction",
    "href": "dataviz.html#introduction",
    "title": "Data Visualisation",
    "section": "",
    "text": "Why do we visualise data? For data to tell us something we need to look for patterns, and we are much better at finding these patterns in colours and shapes than in a table of raw data. Visualisations are key to developing the story we want to tell with our data.\nWhen do we visualise data? There are two main moments when working with data that we need to visualise it. First, in the exploratory phase, when we are trying to understand the data, to get insights that lead to fruitful lines of enquiry. These visualisations are rough and ready, meant for us or at most a select few around us to generate debate about what information the data might contain.\nSecond, in the explanatory phase, when we have understood the data and move on to insightful analyses that generate new understanding. These visualisations communicate what we have learned from the data to others. They need to be clear, because we are trying to explain conclusions we have made from intimate knowledge of the data to people who have not worked with it, and are trusting us to explain faithfully what we have learned.\nIn libraries this covers visualisations for users of our services designed to improve content discovery and so they can understand our data, as well as research carried out by librarians and digital humanists that generates new knowledge. Particularly for our users, whose needs should be at the heart of the services we supply, visual routes we supply into our data need to be as clear as anything we’re presenting as research.\nHow do we visualise data? There are a huge variety of tools available. Practitioners may lovingly hand draw images (physically or digitally), from early 19th century visualisations by Florence Nightingale and W. E. B. Du Bois to the work, verging on art, of Federica Fragapane. More commonly there are deeply customisable packages in modern programming languages like R, Python or Javascript, or commercial plotting software like Tableau. Excel has endured through its simple learning curve, ubiquity and reliable outputs. A whole separate suite of software exists for geospatial and linked data. Ultimately the right choice is decided by our use case, data, resources and skills.",
    "crumbs": [
      "TOPIC GUIDES",
      "Data Visualisation"
    ]
  },
  {
    "objectID": "dataviz.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "href": "dataviz.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "title": "Data Visualisation",
    "section": "Relevance to the Library Sector (Case Studies/Use Cases)",
    "text": "Relevance to the Library Sector (Case Studies/Use Cases)\nExploratory data visualisations are both quite generic and very dataset specific. Simple plots like bar charts, histograms, scatter plots, and time series are simple enough to be reliable and fit the ethos of being quick and informative of the features of your data. This Power BI dashboard from Brandi Jagars at University of South Florida Libraries shows how simple visualisations give quick insights into a visitor dataset.\n\n\n\nA dashboard of exploratory graphs\n\n\nVisualisations designed for users and for publication are much more varied, and (usually) more polished. Maps are an eye-catching and engaging interface into collections that tap into users’ sense of place. The Mapping Manuscript Migrations project offers a map view of global manuscript migrations allowing users to track the movement of manuscripts filtered by things like collection, author and date of publication.\n\n\n\nMovement of manuscripts from the collection of Sir Thomas Phillipps\n\n\nPeripleo is a browser based map viewer that can be used with any cultural heritage dataset with associated location information. It was used in the Heritage for All project to displaying items in hyper-local contexts.\n\n\n\nMap of cultural heritage item locations around Exeter\n\n\nBoth of these initiatives rely on the concept of Linked Open Data. Each element of linked data is linked to other elements by one of a defined set of relationships, rather than the traditional spreadsheet model where each row is an item with a certain set of properties. This transforms the data into a network, which allows for intuitive, interactive visualisations that let users navigate material contextualised by the items closely linked to it.\nThe Semantic Name Authority Cymru (SNARC) provides views into a linked database of name authority records linked to Wales and the Welsh language. This makes graphs like this family tree of Charlotte Guest, a translator, businesswoman and noble, easy to produce. Displaying parts of the network let users understand the connections within it, as in this rather large, but very satisfying, graph of Welsh estates, houses and their owners.\n\n\n\nSNARC Welsh estates network graph\n\n\nThere’s also huge value in making visualisations like this available in physical form within the spaces of a library. The Bohemian Bookshelf was a 2011 project to increase serendipitous book discovery that was installed in the University of Calgary Library. It used 5 different visualisations to ‘entice curiosity’ by taking users to books and authors they might not have otherwise explored. This echoes Dr Mia Ridge’s proposed metric of ‘clicks to curiosity inspired’ in seeking ways to make it easy for users to be inspired by the collection. The ‘book pile’ arranged books by size and page count, acknowledging our natural fascination with the very large and the very small.\n\n\n\nThe Bohemian Bookshelf ‘Book Pile’\n\n\nYou can explore other use cases in this helpful list from the University of Minnesota Libraries. They’ve catalogued library specific resources for a range of use cases like the teaching, evaluation, and history of data visualisation in libraries.",
    "crumbs": [
      "TOPIC GUIDES",
      "Data Visualisation"
    ]
  },
  {
    "objectID": "dataviz.html#hands-on-activity-and-other-self-guided-tutorials",
    "href": "dataviz.html#hands-on-activity-and-other-self-guided-tutorials",
    "title": "Data Visualisation",
    "section": "Hands-on activity and other self-guided tutorial(s)",
    "text": "Hands-on activity and other self-guided tutorial(s)\nThe best way to understand the value of data visualisations is to produce them for your datasets. Here are a few tools you can plug datasets into, organised by type and the skills needed to use them.\n\nImmediate results\nRAWGraphs is an online platform (no sign up required) you can upload a spreadsheet to (save it as a CSV first) or a JSON file and point and click your way down the page to produce a visualisation. It’s perfect for exploratory analysis and learning about the different kinds of visualisations available.\nVoyant Tools provides a similarly easy entry for corpus scale text data (whole works, or collections of works), though it helps if you know a little about corpus linguistics. There are ‘pre-built’ corpora of Shakespeare, Austen and Frankenstein available if you don’t have your own files to upload.\n\n\nSpreadsheet based\nExcel remains such an easy way to interact with spreadsheet data. If you haven’t used it before there are lots of resources available online or your institution may have Microsoft Office skills courses. This gentle intro from University of Minnesota libraries assumes some knowledge but not too much. PowerBI is a more advanced Microsoft Office app that allows you to create dashboards from data. It interfaces easily with Office software but the visualisations aren’t hugely inspiring. Justin Kelly has an introduction for librarians. Google Charts and Sheets and OpenOffice Calc and Impress are equivalent alternatives.\nTableau is one of many commercial softwares for visualisation. There’s a learning curve similar to Excel, and a free (sign-up required) public platform you can try in browser, use the learning resources to get started.\n\n\nIntro to coding\nThe R for Data Science Data Visualisation tutorial covers using ggplot2, the de facto standard for plotting in R. You can code along with an R environment in browser using Posit Cloud (requires a free account).\nSeaborn is one of the main plotting packages in Python and follows a similar philosophy to ggplot2. You can code along to their tutorial with a Python environment in browser using Google Colab (requires a Google account).\n\n\nMapping and Linked Data\nGeospatial and linked data (where elements of the data can be explicitly linked to other elements) have their own worlds of tools, with functionality also often covered by the types of tools already listed. ArcGIS (now common in its online form) and QGIS are the most common paid and open source Geographic Information Software (GIS) tools available. You can use these to work with data with geographic components and make display worthy maps. Their outputs also plug into Python, R and JavaScript libraries like leaflet or Dash. Programming Historian have a series of mapping lessons, from an intro to QGIS to converting historical place names into locations on a map.\nFor linked data tools like Gephi or Nodegoat have graphical user interfaces, or there are programming packages like igraph, NetworkX, and D3.js.",
    "crumbs": [
      "TOPIC GUIDES",
      "Data Visualisation"
    ]
  },
  {
    "objectID": "dataviz.html#recommended-readingviewing",
    "href": "dataviz.html#recommended-readingviewing",
    "title": "Data Visualisation",
    "section": "Recommended Reading/Viewing",
    "text": "Recommended Reading/Viewing\nMuch data visualisation is communication, and so is deeply subjective. Good visualisations are guided by design philosophies built upon how we process visual information. Two influential books that develop these philosophies are The Grammar of Graphics by Leland Wilkinson and The Visual Display of Quantitative Information (2nd Ed.) by Edward R. Tufte. The Grammar of Graphics is a hefty tome that proposes a core set of components for graphics then builds them from the ground up, with reference to programming. Visual Display is perhaps a little more accessible and uses the idea of how ink is used (digitally or physically) to understand what is and is not important in a graphic.\nIf visualisation is communication and how we understand visual communication is subjective, then catering generously to how different people process visual information is important. We might call this accessibility. This talk explains some of the basics of how our brains handle colour, and the importance of colour in visualisation. The Seaborn explanation of colour palettes is a helpful reference, and there is a free colour blindness tester to check that your visualisations encode information in colours that everyone can distinguish. Use alt-text for screen reader access and review for keyboard and content accessibility. Harvard have a helpful guide.\n\n\n\nThe importance of colour in recognising categories\n\n\nWith these considerations in mind there are graphics catalogues that help guide you towards the best visualisation for your purposes. from Data to Viz starts with types of data and leads you to appropriate graphs, while the Financial Times Visual Vocabulary starts with relationships between elements of your data and guides from there. Both are valuable.",
    "crumbs": [
      "TOPIC GUIDES",
      "Data Visualisation"
    ]
  },
  {
    "objectID": "dataviz.html#finding-communities-of-practice",
    "href": "dataviz.html#finding-communities-of-practice",
    "title": "Data Visualisation",
    "section": "Finding Communities of Practice",
    "text": "Finding Communities of Practice\nData visualisation, like any other skill, takes practice and familiarity with tools to get the best results. It is, however, relatively easy to make simple but effective visualisations that help you understand your data or explain it to someone else. So take some of your data and begin to play around with it. Play is an important word, you are being creative! Make mistakes and do the unexpected as you learn and you will be better for it. It is, unfortunately, just as easy to make bad visualisations that confuse you and your audience. Start simply, more complex visualisations will come with time.\nIf you haven’t done any visualisation before start with something like RAWGraphs or Excel for tabular data, or Voyant Tools for text data. If you have geographic data find a GIS specialist, or use the tutorials for QGIS or ArcGIS. If you have some experience with visualisations then tailor your choice of tool to your data. And if you’re familiar with programming then look at the plotting packages available, and enjoy the flexibility and reproducibility they give you.\nEngage with designers if they’re available to you and you are producing work for users or the wider public. The art of designing things for people applies as much to data visualisation as it does to anything else.\nAbove all remember your audience. Keep clear in your mind what it is you are trying to communicate, and to who, and ask yourself if your visualisation does that. Continue to iterate until it does, and you will have explained the story in your data clearly.",
    "crumbs": [
      "TOPIC GUIDES",
      "Data Visualisation"
    ]
  },
  {
    "objectID": "lod.html",
    "href": "lod.html",
    "title": "Linked Open Data in Library Use Today",
    "section": "",
    "text": "The Semantic Web was first introduced in the 2000s by Tim Berners Lee as an extension of the current Web. Instead of providing information in the form of documents and unstructured text like in traditional webpages, the Semantic Web facilitates the publication of machine-readable data on the web through standards such as Resource Description Framework (RDF) and Web Ontology Language (OWL).\nWhat does publishing linked open data enable? Linked Open Data (LOD) is a method of publishing structured data about things using the RDF to enable interlinking and semantic queries across datasets. The data is organised in “triples”, each consisting of a subject (e.g., Named Person), predicate (IsAuthorOf), and object (Book Title), identified by Uniform Resource Identifiers (URIs) to ensure global uniqueness and interoperability. It allows metadata to be connected and enriched, so that different representations of the same content can be found, and links made between related resources.\nHave a quick look at this video from Europeana explaining the high-level basic principle of LOD before we dive a bit deeper into how it practically works:\n Linked Open Data | Europeana PRO\n\n\nRDF triples are the fundamental building blocks of Linked Open Data. Triples follow the RDF standard and consist of three components:\n\nSubject: This is the entity or resource being described. It is usually represented by a URI that uniquely identifies the resource.\nPredicate: This represents the relationship or property of the subject. It is also identified by a URI and specifies the type of relationship between the subject and the object.\nObject: This is the value or resource that is related to the subject. The object can be another URI (representing another resource) or a literal value (such as a string or number), amongst others.\n\nAn example of a triple stating “Miguel de Cervantes is author of El Quijote.” would look like this:\n\nSubject: &lt;http://www.wikidata.org/entity/Q5682&gt; (Wikidata URI reference to Miguel de Cervantes)\nPredicate: &lt;http://purl.org/dc/terms/creator&gt; (Dublin Core URI term for creator/author)\nObject: &lt;http://www.wikidata.org/entity/Q480&gt; (Wikidata URI reference to the book El Quijote)\n\nIn a 2020 survey of LIBER members, the LIBER Linked Open Data Working Group identified the following as the most frequently used datasets by libraries to enrich their catalogues but there are many more that can be used depending on your needs Linked Data Survey (oclc.org) and some examples of advanced data models are Bibliographic Framework (BIBFRAME) and Library Reference Model (LRM). In addition, the lod-cloud provides more than one thousand LOD repositories classified by categories and based on different domains such as geography and government.\n\nSo let’s go back to our triple that describes the relationship between the resource “Miguel de Cervantes” and the book of “El Quijote”. When different triples share the same URI for a subject, predicate, or object, they create a connection. For example:\nTriple 1: Miguel de Cervantes is author of El Quijote\n\nSubject: &lt;http://www.wikidata.org/entity/Q5682&gt; (Wikidata identifier for the author Miguel de Cervantes)\nPredicate: &lt;http://purl.org/dc/terms/creator&gt; (Dublin Core term for creator/author)\nObject: &lt;http://www.wikidata.org/entity/Q480&gt; (Wikidata identifier for the work El Quijote)\n\nTriple 2: El Quijote is a work of Spanish Literature\n\nSubject: &lt;http://www.wikidata.org/entity/Q480&gt; (Wikidata identifier for the work El Quijote)\nPredicate: &lt;http://purl.org/dc/terms/subject&gt; (Dublin Core term for subject)\nObject: &lt;http://dbpedia.org/resource/Spanish_literature&gt; (DBpedia identifier for Spanish literature)\n\nHere, the object of the first triple (&lt;http://www.wikidata.org/entity/Q480&gt;) is the subject of the second triple, linking information about the book to information about its subject matter. So an example catalogue record combining many triples then might look like:\n&lt;http://example.org/catalogue/El_Quijote&gt; &gt;rdf:type schema:Book; schema:name “El_Quijote”; schema:author &lt;http://www.wikidata.org/entity/Q5682&gt;; schema:genre &lt;http://dbpedia.org/resource/Novel&gt;; schema:inLanguage &lt;http://id.loc.gov/vocabulary/iso639-1/es&gt;; schema:datePublished “1605”; schema:about &lt;http://dbpedia.org/resource/Spanish_literature&gt;; schema:about &lt;http://dbpedia.org/resource/Spanish_Golden_Age&gt;; schema:sameAs &lt;http://dbpedia.org/resource/Don_Quixote&gt;.\n&lt;http://www.wikidata.org/entity/Q5682&gt; &gt;rdf:type schema:Person; schema:name “Miguel de Cervantes”; schema:birthPlace &lt;http://dbpedia.org/resource/Alcala_de_Henares&gt;; schema:birthDate “1547-09-29”.\n&lt;http://dbpedia.org/resource/Alcala_de_Henares**&gt; &gt;rdf:type schema:Place; schema:name “Alcalá de Henares”; geo:country &lt;http://sws.geonames.org/2510769/&gt;.\n&lt;http://sws.geonames.org/2510769/&gt; &gt;rdf:type schema:Country; schema:name “Spain” .",
    "crumbs": [
      "TOPIC GUIDES",
      "Linked Open Data in Library Use Today"
    ]
  },
  {
    "objectID": "lod.html#introduction",
    "href": "lod.html#introduction",
    "title": "Linked Open Data in Library Use Today",
    "section": "",
    "text": "The Semantic Web was first introduced in the 2000s by Tim Berners Lee as an extension of the current Web. Instead of providing information in the form of documents and unstructured text like in traditional webpages, the Semantic Web facilitates the publication of machine-readable data on the web through standards such as Resource Description Framework (RDF) and Web Ontology Language (OWL).\nWhat does publishing linked open data enable? Linked Open Data (LOD) is a method of publishing structured data about things using the RDF to enable interlinking and semantic queries across datasets. The data is organised in “triples”, each consisting of a subject (e.g., Named Person), predicate (IsAuthorOf), and object (Book Title), identified by Uniform Resource Identifiers (URIs) to ensure global uniqueness and interoperability. It allows metadata to be connected and enriched, so that different representations of the same content can be found, and links made between related resources.\nHave a quick look at this video from Europeana explaining the high-level basic principle of LOD before we dive a bit deeper into how it practically works:\n Linked Open Data | Europeana PRO\n\n\nRDF triples are the fundamental building blocks of Linked Open Data. Triples follow the RDF standard and consist of three components:\n\nSubject: This is the entity or resource being described. It is usually represented by a URI that uniquely identifies the resource.\nPredicate: This represents the relationship or property of the subject. It is also identified by a URI and specifies the type of relationship between the subject and the object.\nObject: This is the value or resource that is related to the subject. The object can be another URI (representing another resource) or a literal value (such as a string or number), amongst others.\n\nAn example of a triple stating “Miguel de Cervantes is author of El Quijote.” would look like this:\n\nSubject: &lt;http://www.wikidata.org/entity/Q5682&gt; (Wikidata URI reference to Miguel de Cervantes)\nPredicate: &lt;http://purl.org/dc/terms/creator&gt; (Dublin Core URI term for creator/author)\nObject: &lt;http://www.wikidata.org/entity/Q480&gt; (Wikidata URI reference to the book El Quijote)\n\nIn a 2020 survey of LIBER members, the LIBER Linked Open Data Working Group identified the following as the most frequently used datasets by libraries to enrich their catalogues but there are many more that can be used depending on your needs Linked Data Survey (oclc.org) and some examples of advanced data models are Bibliographic Framework (BIBFRAME) and Library Reference Model (LRM). In addition, the lod-cloud provides more than one thousand LOD repositories classified by categories and based on different domains such as geography and government.\n\nSo let’s go back to our triple that describes the relationship between the resource “Miguel de Cervantes” and the book of “El Quijote”. When different triples share the same URI for a subject, predicate, or object, they create a connection. For example:\nTriple 1: Miguel de Cervantes is author of El Quijote\n\nSubject: &lt;http://www.wikidata.org/entity/Q5682&gt; (Wikidata identifier for the author Miguel de Cervantes)\nPredicate: &lt;http://purl.org/dc/terms/creator&gt; (Dublin Core term for creator/author)\nObject: &lt;http://www.wikidata.org/entity/Q480&gt; (Wikidata identifier for the work El Quijote)\n\nTriple 2: El Quijote is a work of Spanish Literature\n\nSubject: &lt;http://www.wikidata.org/entity/Q480&gt; (Wikidata identifier for the work El Quijote)\nPredicate: &lt;http://purl.org/dc/terms/subject&gt; (Dublin Core term for subject)\nObject: &lt;http://dbpedia.org/resource/Spanish_literature&gt; (DBpedia identifier for Spanish literature)\n\nHere, the object of the first triple (&lt;http://www.wikidata.org/entity/Q480&gt;) is the subject of the second triple, linking information about the book to information about its subject matter. So an example catalogue record combining many triples then might look like:\n&lt;http://example.org/catalogue/El_Quijote&gt; &gt;rdf:type schema:Book; schema:name “El_Quijote”; schema:author &lt;http://www.wikidata.org/entity/Q5682&gt;; schema:genre &lt;http://dbpedia.org/resource/Novel&gt;; schema:inLanguage &lt;http://id.loc.gov/vocabulary/iso639-1/es&gt;; schema:datePublished “1605”; schema:about &lt;http://dbpedia.org/resource/Spanish_literature&gt;; schema:about &lt;http://dbpedia.org/resource/Spanish_Golden_Age&gt;; schema:sameAs &lt;http://dbpedia.org/resource/Don_Quixote&gt;.\n&lt;http://www.wikidata.org/entity/Q5682&gt; &gt;rdf:type schema:Person; schema:name “Miguel de Cervantes”; schema:birthPlace &lt;http://dbpedia.org/resource/Alcala_de_Henares&gt;; schema:birthDate “1547-09-29”.\n&lt;http://dbpedia.org/resource/Alcala_de_Henares**&gt; &gt;rdf:type schema:Place; schema:name “Alcalá de Henares”; geo:country &lt;http://sws.geonames.org/2510769/&gt;.\n&lt;http://sws.geonames.org/2510769/&gt; &gt;rdf:type schema:Country; schema:name “Spain” .",
    "crumbs": [
      "TOPIC GUIDES",
      "Linked Open Data in Library Use Today"
    ]
  },
  {
    "objectID": "lod.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "href": "lod.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "title": "Linked Open Data in Library Use Today",
    "section": "Relevance to the Library Sector (Case Studies/Use Cases)",
    "text": "Relevance to the Library Sector (Case Studies/Use Cases)\nGLAM institutions and in particular, libraries, have played a leading role in the publication of their data, primarily collections metadata, as LOD and using them including:\n\nBibliothèque nationale de France\nBiblioteca Virtual Miguel de Cervantes\nBritish Library\nEuropeana\nLibrary of Congress\nNational Library of Scotland\nNational Library of Spain\n\nAdditional examples from other related domains such as museums and Digital Humanities initiatives are the Rijksmuseum and Smithsonian American Art Museum, and Linked Open Data Infrastructure for Digital Humanities in Finland (LODI4DH).\nThe benefits of the publishing and use of the Semantic Web and LOD for:\n\nSemantic Enrichment: LOD helps libraries improve searchability and enables more precise queries by enriching existing catalogue records. Libraries have started to enrich their catalogues with external LOD repositories in order to provide additional contextual information that may be missing from your own catalogue (e.g., author nationalities (VIAF), geographic coordinates (GeoNames) relating to birth places of authors, or related subjects (Library of Congress Subject Headings). As in the example above a catalogue record for the book “El Quijote,” could be enriched with metadata about the author, language, publication date, related literary movements, and geographical information, all connected through LOD triples.\nInterconnectedness: LOD allows libraries to link their data with other rich datasets, creating a web of interconnected information. This enables users to discover related resources beyond their own library’s holdings. For example: a library could link their catalogue data with other LOD repositories, to enhance search results. Searching for “El Quijote” in the catalogue could return results not only from their own collection but also from other institutions that use LOD.\nIncreased Visibility: By publishing data as LOD, institutions can increase their visibility on the web as researchers, developers, and other institutions can easily find and reuse library data. For example: Adding information about a rare copy of El Quijote in your collection to Wikidata would aid its discovery through Wikipedia articles (Libraries and Wikidata: Using linked data to expand access to library collections worldwide – Wiki Education).\nInnovation: LOD encourages creative applications and tools. Developers can build new services, visualisations, and applications using linked library data. For example: LOD allows the creation of new types of visualisations, such as timelines, maps and graph charts that can be useful to gain insight, in some cases without the need to install additional software thanks to the use of APIs. Some examples include:\n\na tutorial in Spanish to create map visualisations based on Wikidata and using several data repositories (e.g., members of the International GLAM Labs Community) as content\nthe exploration of machine-readable visual configurations to browse LOD repositories provided by Cultural Heritage institutions, including libraries, in the form of Jupyter Notebooks\na map representing the geographic locations mentioned in the metadata provided by a corpus of historical documents and paintings.\n\n\nThough there are many benefits, SPARQL is the means by with Linked Open Data is queried and accessed and it’s worth being aware that the use of API’s based on SPARQL can be complex for less technical users since they need to understand how the data is modelled as well as be able to type a query. In addition, data quality has become crucial and several initiatives are focused on the assessment of the data quality provided by the catalogues.\n\nCase Study: Manuscripts on Wikidata: the state of the art? | by Martin L Poulter | Medium\nThis example shows how to use Wikidata, a community-driven approach based on the Semantic Web and LOD that enables volunteers to edit the metadata, to describe manuscripts. It shows the expressivity of the vocabulary provided by Wikidata and the benefits of using Wikidata as a repository in terms of visibility and reuse.",
    "crumbs": [
      "TOPIC GUIDES",
      "Linked Open Data in Library Use Today"
    ]
  },
  {
    "objectID": "lod.html#hands-on-activity-and-other-self-guided-tutorials",
    "href": "lod.html#hands-on-activity-and-other-self-guided-tutorials",
    "title": "Linked Open Data in Library Use Today",
    "section": "Hands-on activity and other self-guided tutorial(s)",
    "text": "Hands-on activity and other self-guided tutorial(s)\nAs part of my National Research Librarian’s fellowship at National Library of Scotland exploring the adoption of Semantic Web technologies to transform, enrich and assess the Data Foundry’s digital collections, I created a collection of Jupyter Notebooks that enables users to:\n\nunderstand the benefits of the adoption of the Semantic Web;\ncreate an RDF repository from a traditional dataset;\nenrich a dataset with external repositories such as Wikidata;\nreproduce the analysis and visualisations based on the datasets created.\n\nI can also highly recommend starting with this Introduction to the Principles of Linked Open Data | Programming Historian tutorial which gives a great walk through of creating linked open data and includes an activity for using SPARQL to query LOD.\nThe course about Linked Open Data in cultural heritage collections, developed at Leiden University also includes a tutorial about a number of tools that can be used to create and to publish LOD. More specifically, it contains discussions of the LDwizard and CLARIAH Data Legend tool ‘COW’.\nTo be able to retrieve and analyse Linked Open Data, you need to know how to build SPARQL queries. The following course can be helpful:\n\nIntroduction to SPARQL\n\nExamples of SPARQL queries used to collect and analyse data from heritage institutions can be found in the notebooks below:\n\nThe Europeana SPARQL endpoint\nWikidata\nShort Title Catalogue of the Netherlands\nThe Dutch Institute for Art History",
    "crumbs": [
      "TOPIC GUIDES",
      "Linked Open Data in Library Use Today"
    ]
  },
  {
    "objectID": "lod.html#recommended-readingviewing",
    "href": "lod.html#recommended-readingviewing",
    "title": "Linked Open Data in Library Use Today",
    "section": "Recommended Reading/Viewing",
    "text": "Recommended Reading/Viewing\nIf you are interested in learning more about LOD in terms of how to transform traditional bibliographic information into the Semantic Web, check out my research work performed as part of a fellowship at the National Library of Scotland in order to publish digital collections as LOD.\nI can also recommend the excellent Best Practices for Library Linked Open Data (LOD) guide published by the LIBER Linked Open Data (LOD) Working Group in 2021 which outlines in detail six steps for publishing library linked data.\n\nSome examples of research articles to read providing additional details and information include:\n\nTowards a semantic approach in GLAM Labs: The case of the Data Foundry at the National Library of Scotland\nLIBER’s Linked Open Data Working Group Publishes ‘Best Practices for Library Linked Open Data (LOD) Publication’ - LIBER Europe\nAn automatic data quality approach to assess semantic data from cultural heritage institutions\nA Shape Expression approach for assessing the quality of Linked Open Data in libraries\nAn Ontological Approach for Unlocking the Colonial Archive. (Example of transformation into RDF of a collection of maps using Open Refine.)\nEvaluating the quality of linked open data in digital libraries - Gustavo Candela, Pilar Escobar, Rafael C Carrasco, Manuel Marco-Such, 2022 (sagepub.com)\n\nYou can also find innovative ideas in the research articles published at the Semantic Web Journal.",
    "crumbs": [
      "TOPIC GUIDES",
      "Linked Open Data in Library Use Today"
    ]
  },
  {
    "objectID": "lod.html#finding-communities-of-practice",
    "href": "lod.html#finding-communities-of-practice",
    "title": "Linked Open Data in Library Use Today",
    "section": "Finding Communities of Practice",
    "text": "Finding Communities of Practice\nThe LD4 Community is a community of practice for linked data in libraries.\nLinked Art is a community working together to create a shared model based on LOD to describe cultural heritage with a particular focus on art.\nCode4Lib is a community effort including a mailing list and a journal providing open articles based on the library domain and including LOD.",
    "crumbs": [
      "TOPIC GUIDES",
      "Linked Open Data in Library Use Today"
    ]
  },
  {
    "objectID": "llms.html",
    "href": "llms.html",
    "title": "Understanding Large Language Models",
    "section": "",
    "text": "Contributor by: Nora McGregor, ORCID iD\nSuggested Citation: Nora McGregor, “Understanding Large Language Models,” Digital Scholarship & Data Science Essentials for Library Professionals (2024), [DOI link tbd]\n\n\n\nThis Topic Guide, based on a Hack & Yack delivered as part of the British Library’s Digital Scholarship Training Programme, offers a brief introduction to Large Language models (LLMS) by way of ChatGPT, as a means of demystifying both quickly. Through hands-on activities and case studies, we’ll explore potential challenges and opportunities for the use of LLMs and ChatGPT in current and future library services.\n\n\nA large language model (LLM) is a type of machine learning model that can perform natural language processing tasks such as generating and classifying text, answering questions, and translating text.\nIf your eyes just crossed reading that sentence, no wonder, there’s a lot of terminology and jargon to unpack there in that one little sentence. Let’s go back a few steps and take it a little slower!\nIt helps to first understand a little bit about what machine learning is. Machine learning (ML) is a core technology that underpins a lot of work in artificial intelligence work today. Artificial intelligence is actually a broad field that encompasses the development of systems and machines capable of performing tasks that typically require human intelligence, such as reasoning, problem-solving, learning, and perception, and…chatting!\nNatural Language Processing (NLP) is a specialised area within artificial intelligence (AI) that looks specifically at the challenges of processing and understanding human language (another is Computer Vision (CV) which is, on the other hand, concerned with helping computers process and understand imagery in the vein of human vision). NLP plays a vital role in enhancing the capabilities of AI systems by working to make them more capable of natural and effective interaction with humans.\nNLP involves the development of algorithms, models, and systems for analysing, understanding and extracting meaningful information from textual data representing human language. The field relies heavily on the use of machine learning to make sense of our complex textual data, which might come from literature, historical documents, articles, twitter, wikipedia, you name it!\nMachine learning involves the development of algorithms and models that allow computers to learn patterns and relationships from data and make predictions on new data. Instead of being explicitly programmed for specific tasks, ML algorithms use data to learn and improve their performance over time.\nA machine learning algorithm is designed to recognize patterns, relationships, and trends in data and will adjust their internal parameters based on examples to improve their performance over time.\nA machine learning model represents what was learned by a machine learning algorithm. The model that’s created in the process and saved after running a machine learning algorithm on training data and represents the rules, numbers, and any other algorithm-specific data structures required to make predictions on new data.\nSo back to our definition:\nA large language model (LLM) is a type of machine learning model that can perform natural language processing tasks such as generating and classifying text, answering questions, and translating text.\nLanguage models are a type of machine learning model designed to predict the likelihood of a sequence of text, which means that they can be set up to predict the most likely way to continue a conversation. The models behind ChatGPT are large, complex neural networks that have been exposed to an enormous amount of text from books, articles, websites, and more. These models have learned something about patterns in grammar and word meaning, including the way that meaning arises contextually across multiple sentences and multiple turns in a conversation. When you ask ChatGPT a question, you are presenting the model with new information it tries to make a prediction on, in this case, it tries to generate a response that matches the pattern of conversation. Large language models are trained on massive amounts of text data and are essentially the backbone of NLP today. There are and have been for many years, large language models out there actually but ChatGPT has currently caught the popular imagination because of its publicly available interface and remarkable performance.\n\n\n\nChatGPT is a platform providing an interface specifically to the large language models developed by OpenAI. The GPT stands for Generative Pre-Trained Transformers which is just a fancy way of saying that the models you are chatting with have already been trained on a lot of data.\nIt's a chatbot essentially designed to generate human-like text responses based on the input it receives. Or some say to think of it as a fancy predictive text generator. You ask questions or give prompts, and it provides responses in natural language, or rather, estimates what should come next in a conversation.\n\n\n\nGoogle Search Box: Unlike Google, ChatGPT doesn't search the internet for information. Instead, it generates responses based on a massive dataset it was trained on. This training dataset includes large segments of text sampled from the internet at a specific point in time, and so can reflect language describing content on the internet, but it doesn't have real-time access to the internet. When ChatGPT answers a question, it isn’t actually looking up information and then composing that information into a response; it's just making an estimation of a response based on patterns it has seen. So, when you ask it factual questions, especially ones with common answers or phrases, it might give you an answer that sounds right but remember this is because it’s mimicking what it has seen in its training data. Think of it perhaps as a very smart parrot, sometimes 'repeating' things it has seen before.\nHuman Mind: ChatGPT is not a human; it's a machine learning model. It doesn't understand or reason like a human. It generates evidently linguistic responses based on patterns it learned from text data.\n\n\n\n\n\nLanguage Modelling: So ChatGPT models are members of this class of models we’re talking about: “large language models” (LLMs). A machine learning model represents what was learned by a machine learning algorithm. The model is created and saved after running a machine learning algorithm on training data and represents the rules, numbers, and any other algorithm-specific data structures required to make predictions on new data. Language models are designed to predict the likelihood of a sequence of text, which means that they can be set up to predict the most likely way to continue a conversation. The models behind ChatGPT are large, complex neural networks that have been exposed to an enormous amount of text from books, articles, websites, and more. These models have learned something about patterns in grammar and word meaning, including the way that meaning arises contextually across multiple sentences and multiple turns in a conversation. When you ask ChatGPT a question, it tries to generate a response that matches these patterns.\nContextual Understanding: ChatGPT also looks at the context of the question you ask, including what’s happened so far in your conversation and any instructions or details you offer about how it should respond. It tries to understand the context and generate a response that is contextually relevant, which can make its answers seem quite accurate.\nExisting Knowledge: It can recall and blend information it has observed in its training data. So, when you ask a factual question, it can sometimes generate a response that seems factual because it has encountered similar information during training. But, it can also make mistakes or provide information that is outdated or biassed because it doesn't have the ability to verify the accuracy of what it says, and it is influenced by any views inherent in its training data, whether they are right or wrong. It's like the parrot repeating something it heard: it can't check if what it's saying is true or up-to-date. That's why it's important to double-check information output by ChatGPT with reliable sources, especially when using ChatGPT for research or critical tasks.\nUser Feedback Loop: ChatGPT models like the latest GPT-4 (openai.com) have been tuned and improved over time with user feedback, as part of a model training process known as “reinforcement learning”. So for example, when users request things like python code, and try it out, users provide feedback on whether or not it worked. This feedback helps the model get better at generating code that is more likely to work.\n\n\n\n\n\nIdea Generation: ChatGPT can help brainstorm ideas for projects, essays, or creative endeavours. For example, you can ask it for ideas on new business ventures, book plots, or marketing campaigns.\nThesaurus and Rephrasing: It's excellent for finding synonyms, rephrasing sentences, or improving the clarity of your writing. You can ask it to provide alternative words or rewrite a paragraph for better readability.\nCreative Writing: ChatGPT can assist with creative writing tasks, including writing short stories, poems, or generating dialogues for characters.\nSome Learning and Explanation: It can provide explanations and answers to questions on a wide range of very general topics, making it useful for learning new concepts or understanding complex ideas. But again, always best to double check against other trusted resources.\nLanguage Translation: ChatGPT can offer some basic translation assistance, such as translating phrases or short sentences between languages.\nGenerating code snippets: It may not produce highly complex or critical code reliably but you can use it as a starting point for some common coding tasks.\n\n\n\nQuerying structured data: ChatGPT can provide outputs in the form of data structures including for instance SQL queries and JSON. So for instance if we have an SQL database with information about the content of a corpus, we can prompt ChatGPT to output queries that would apply to that database. We can then begin to imagine an interface where a non-expert user could make such a query using their own natural language, and ChatGPT could provide a connection with the structured data. This is sometimes referred to as “function calling” in the ChatGPT literature.\n\n\n\n\n\n\n[Need to work on this section with written examples/more narrative around opportunities and challenges]\n\nA Tech Librarian Explains How to Build AI Literacy - Choice 360\nChatGPT: Implications for academic libraries | Cox | College & Research Libraries News (acrl.org)\nUsing GPT on Library Collections (Matt Miller)\nhttps://programminghistorian.org/en/lessons/interrogating-national-narrative-gpt\n\n\n\n\nThe following activity was delivered to British Library staff as part of a monthly Hack & Yack.\n\n\nFor this activity we’ll primarily use the freely available ChatGPT (openai.com) interface. For this you’ll need to have a free google account.\n\n\n\nTo get a useful response from ChatGPT, “prompting” is key. If you only ask a simple question, you may not be happy with the results and decide to dismiss the technology too quickly, but today’s purpose is to have a deeper play in order to develop our critical thinking and information evaluation skills, allowing us to make informed decisions about utilising tools like ChatGPT in our endeavours.\nSome best practices for writing a good prompt (helpful hints/tips gleaned from the suggested readings in this guide):\n\nGive the context. The more you explain the ins and outs of what you want ChatGPT to do, the more relevant your answer will be. For example, “You are an expert in [fill in the blank for your topic].”\nBe very specific and concrete about what you want it to do (and equally, what you don’t want it to do). For instance you may want to specify word count, how many items you’d like in a list, tone of voice, etc.\nGive clear instructions on what the output should look like, and be simple and concise in your language.\nProvide examples. Much like a human, ChatGPT often understands best when you provide an example for it to work with, especially if you want it to produce something that closely resembles something you’ve seen online.\nAsk ChatGPT to “act like” someone: Sometimes, it can help to start your prompt by asking ChatGPT to “act like” a certain type of person that would be particularly well-placed to respond to the query you're posing.\n\nIf you’re not satisfied with any part of the answer, you can keep building on it, asking ChatGPT to revise it in any way you like as it will continue on from previous enquiries in a session. (If you’d rather it not do that you can add “Please ignore all previous instructions” to start a prompt fresh). To learn more about prompting, there is a free online course: Learn Prompting.\n\n\n\n\nHave a play generating responses to some of the below questions (or come up with your own)!\nCritically evaluate the responses you receive from ChatGPT.\n\nIs the information/response credible?\nAre there any biases in the responses?\nDoes the information align with what you know from other sources?\n\nConsider your findings, the strengths and weaknesses, ethical considerations and challenges of using AI tools such as this.\n\n\n\n\nTry this….\n**Example Prompts\nFurther considerations/Notes\n\n\n\n\nAsk ChatGPT to create a title for a new exhibition\n\n\n\n\nAsk ChatGPT to create an exhibition label for items in an exhibition\n“Write an exhibition label for this archived website http://moorfootru nners.blogspot.co.uk/”\n\n\n\nAsk ChatGPT to create a blog post on a topic for which you are very familiar\n\n\n\n\nAsk ChatGPT to help you come up with ideas for teaching\nTry something like this:\n“You are an academic librarian focusing on instruction. Please make an outline of important topics to cover for a classroom lecture on ChatGPT. This will be part of a series of instruction sessions about information literacy. You have already worked with this class on the basic concepts of information literacy. Create the outline as a bulleted list and follow it with a classroom activity based on one of the topics you’ve discussed about ChatGPT.”\nFrom: A Tech Librarian Explains How to Build AI Literacy - Choice 36 0\nWhen you get the results, you can then ask it to give you an additional activity or set of activities on the same topic.\nHave a play around with different training subject areas.\n\n\nAsk ChatGPT to write a bio for yourself, providing it with details for instance as a list of facts about you\n\n\n\n\nAsk ChatGPT to Act as a Translator\nTry something like this:\n“I want you to act as an English translator, spelling corrector and improver. I will speak to you in any language and you will detect the language, translate it and answer in the corrected and improved version of my text, in English. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, upper level English words and sentences. Keep the meaning same, but make them more literary. I want you to only reply the correction, the improvements and nothing else, do not write explanations. My first sentence is”istanbulu cok seviyom burada olmak cok guzel”\nFrom: Awesome ChatGPT Prompts | This repo includes ChatGPT prompt curation to use ChatGPT better. \n\n\n\nAsk ChatGPT to create an outline for a PowerPoint presentation\n\n\n\n\nAsk ChatGPT to extract metadata from a provided text\n\n\n\n\nAsk ChatGPT to write a query for a suppositional SQL database that you describe\n“We have an SQL database with the following tables: 'books' and 'authors'. The 'books' table has columns 'title', 'date', and 'topic'. The 'authors' table has columns 'name', 'birth_date', 'death_date', and 'gender'. I'm going to write some questions about things in this database, and I would like you to respond with SQL queries that would find the information I'm asking about.”\nRESPONSE: “Of course! Feel free to ask any questions you have about the database, and I'll provide you with SQL queries to retrieve the information you need. Please go ahead and ask your questions.”\nINPUT: “I'd like to find books about the second world war written by women born after the war ended.”\nRESPONSE: “To find books about the Second World War written by women born after the war ended, you can use the following SQL query:”\nSELECT b.title, b.date, a.name\nFROM books b\nJOIN authors a ON b.author_id = a.author_id\nWHERE b.topic = 'Second World War'\nAND YEAR(a.birth_date) &gt; 1945\nAND a.gender = 'female';\n\n\n\nHave a look at this project Matt Miller did experimenting with [Using GPT on Library Collections (thisismattmill er.com)]{.underlin e}\n“You are a helpful assistant that is summarizing and extracting data from a journal written by Susan B. Anthony in {RECORD_DATE_HERE}. You only answer using the text\ngiven to you. You do not make-up additional information, the answer has to be contained in the text provided to you. Each page is a diary entry or financial bookkeeping. You will structure your answer in valid JSON, if there are any quote marks in the content escape them as \".”\n“If the following text contains multiple journal entries, extract each one into an array of valid JSON dictionaries. Each dictionary represents one of the entries, extract the date and\nthe date again in the format yyyy-mm-dd and the city or state it was written in and other geographical locations mentioned that entry and people mentioned that entry and the complete\nfull text of the entry and a one sentence summary of the text, using the JSON keys dateText, dateFormated, cityOrState, geographicalLocations, people, fullText, summaryText: {FULL_TEXT_HERE}“\nThinking about this project, could you think of a similar collection that you might be able to experiment with to parse data similarly? How might you like to re-write the prompt for your own project?\n\n\nTry to use it to create social media posts\nThere is a new network called CHOSN for those working in Galleries-Libr aries-Archives-Museums (GLAM) and cultural heritage organisations as research support and research-active staff. This network is a community of practice for research support and research-active staff who work in GLAM organisations interested in developing and sharing open scholarship knowledge and skills, organising events, and supporting each other in this area. Can you write social media post for 140 character to announce this network and call people to join in?\n\n\n\nPROMPT: Act as a librarian advising a history student in the UK doing research into the third plague pandemic in India during the early 20th century. What archival resources could they use?\nRESPONSE: Certainly! If you're a history student in the UK researching the Third Plague Pandemic in India during the early 20th century, there are several archival resources you can explore to enhance your research. These archives will provide you with primary sources, documents, and historical records that can help you gain a deeper understanding of this important historical event. Here are some key archival resources to consider:\n1. **The National Archives (TNA) of the United Kingdom**:\n- TNA holds records related to British colonial administration in India during the early 20th century. Look for documents related to public health, sanitation, and official correspondence about the plague.\n2. **The India Office Records**:\n- These records are part of the British Library's holdings and contain a wealth of information on India during the colonial period. You can find reports, letters, and administrative documents related to the Third Plague Pandemic.\n3. **The British Library**:\n- The British Library has a substantial collection of materials related to India, including newspapers, periodicals, and publications from that era. You can find newspaper articles, books, and reports that discuss the plague's impact in India.\n4. **The Wellcome Collection**:\n- The Wellcome Collection in London has an extensive library and archive of materials related to the history of medicine. You may find documents, photographs, and medical reports pertaining to the plague in India.\n5. **Local Archives in India**:\n- Depending on your specific focus within India, you should also explore local archives and libraries. For example, the National Archives of India in Delhi and state archives may have valuable records.\n6. **Digital Collections**:\n- Many institutions, including the British Library and the Wellcome Collection, have digitized collections that you can access online. These digital resources can be very helpful for remote research.\n7. **University Libraries**:\n- Don't forget to check with your university's library. They may have subscriptions to digital archives and databases that can provide access to primary source materials and scholarly articles related to the Third Plague Pandemic in India.\n8. **Academic Journals**:\n- Look for scholarly articles in history and medical history journals. JSTOR and other academic databases can be valuable for finding secondary sources and research papers.\n9. **Interlibrary Loan Services**:\n- If you find a source or book that's not available in your university's library, you can request it through interlibrary loan services. This expands your access to materials from other institutions.\n10. **Archival Finding Aids**:\n- Be sure to use finding aids and catalog search tools provided by these institutions to locate specific documents and records related to the Third Plague Pandemic.\nRemember to take thorough notes, document your sources meticulously, and consult with your professors or advisors for guidance throughout your research process. Good luck with your research into this important historical topic!\n\n\n\nPROMPT: Act as an archivist producing a catalogue record for an archival document. What subject, place and name authorities or terms would you choose for the following text? [gave it c50% of the full text transcription of IO R/F/4/1754/71645]\nRESPONSE: Here's a suggested catalog record for the provided archival document, along with subject, place, and name authorities/terms:\nTitle: Development of Hemp Cultivation for Cordage Manufacturing\nAuthor: [Author's Name if available]\nDate: [Date of the Document, if available]\nDescription:\nThis archival document explores the historical development of hemp cultivation for cordage (rope) production, emphasizing its critical importance for mechanical purposes and ship rigging during the 19th century. It discusses the transition from skin and leather ropes to vegetable fiber, particularly hemp, and the widespread cultivation and commerce of hemp in various nations. The document highlights the vital role of hemp during wartime and its impact on British shipping during supply disruptions. Additionally, it underscores the attention given to hemp cultivation in India and its various applications, focusing on the Cannabis Sativa plant.\nSubjects:\nCordage Industry\nHemp Cultivation\nRope Manufacturing\nShip Rigging\nHemp Fiber\nAgriculture in India\nColonial Agriculture\nInternational Commerce\nWar Supply Chains\nMechanical Engineering\nFiber Plants\nPlaces:\nUnited Kingdom\nIndia\nNorth America\nRussia\nArabia\nPersia\nChina\nEgypt\nTurkey\nEurope\nAsia\nNames:\nAlexandre Yersin (if mentioned as the author or contributor)\nDr. Roxburgh (for his contributions to hemp cultivation in India)\nNotes:\nThis document provides historical insights into the cultivation of hemp for cordage and its significance in various regions during the 19th century, with a focus on its mechanical properties and wartime importance.\nPlease note that the specific author and date of the document were not provided in the text you provided. If this information is available, it should be included in the catalog record. Additionally, you may need to consult relevant authority files or controlled vocabularies to ensure accuracy in subject, place, and name authorities.\nCOMMENT: The inclusion of Yersin as a suggested authority is interesting / worrying, as he had cropped up in an answer to a previous question, and I had told it to disregard all of the previous conversation data before posting the cataloguing prompt…\nIn terms of indexing, it included a lot of incidental references in the text which a cataloguer would not include as subject or place index terms [should flag at this point that I did not write the BL’s catalogue entry for this]]\nI should really give it the full text before judging the description…\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n40 Best ChatGPT Prompts You Simply Have To Try in 2023 (tech.co)\nA Tech Librarian Explains How to Build AI Literacy - Choice 360\nChatGPT: Implications for academic libraries | Cox | College & Research Libraries News (acrl.org)\nUsing GPT on Library Collections (Matt Miller)\nhttps://programminghistorian.org/en/lessons/interrogating-national-narrative-gpt\nWelcome | Learn Prompting: Your Guide to Communicating with AI"
  },
  {
    "objectID": "llms.html#introduction",
    "href": "llms.html#introduction",
    "title": "Understanding Large Language Models",
    "section": "",
    "text": "This Topic Guide, based on a Hack & Yack delivered as part of the British Library’s Digital Scholarship Training Programme, offers a brief introduction to Large Language models (LLMS) by way of ChatGPT, as a means of demystifying both quickly. Through hands-on activities and case studies, we’ll explore potential challenges and opportunities for the use of LLMs and ChatGPT in current and future library services.\n\n\nA large language model (LLM) is a type of machine learning model that can perform natural language processing tasks such as generating and classifying text, answering questions, and translating text.\nIf your eyes just crossed reading that sentence, no wonder, there’s a lot of terminology and jargon to unpack there in that one little sentence. Let’s go back a few steps and take it a little slower!\nIt helps to first understand a little bit about what machine learning is. Machine learning (ML) is a core technology that underpins a lot of work in artificial intelligence work today. Artificial intelligence is actually a broad field that encompasses the development of systems and machines capable of performing tasks that typically require human intelligence, such as reasoning, problem-solving, learning, and perception, and…chatting!\nNatural Language Processing (NLP) is a specialised area within artificial intelligence (AI) that looks specifically at the challenges of processing and understanding human language (another is Computer Vision (CV) which is, on the other hand, concerned with helping computers process and understand imagery in the vein of human vision). NLP plays a vital role in enhancing the capabilities of AI systems by working to make them more capable of natural and effective interaction with humans.\nNLP involves the development of algorithms, models, and systems for analysing, understanding and extracting meaningful information from textual data representing human language. The field relies heavily on the use of machine learning to make sense of our complex textual data, which might come from literature, historical documents, articles, twitter, wikipedia, you name it!\nMachine learning involves the development of algorithms and models that allow computers to learn patterns and relationships from data and make predictions on new data. Instead of being explicitly programmed for specific tasks, ML algorithms use data to learn and improve their performance over time.\nA machine learning algorithm is designed to recognize patterns, relationships, and trends in data and will adjust their internal parameters based on examples to improve their performance over time.\nA machine learning model represents what was learned by a machine learning algorithm. The model that’s created in the process and saved after running a machine learning algorithm on training data and represents the rules, numbers, and any other algorithm-specific data structures required to make predictions on new data.\nSo back to our definition:\nA large language model (LLM) is a type of machine learning model that can perform natural language processing tasks such as generating and classifying text, answering questions, and translating text.\nLanguage models are a type of machine learning model designed to predict the likelihood of a sequence of text, which means that they can be set up to predict the most likely way to continue a conversation. The models behind ChatGPT are large, complex neural networks that have been exposed to an enormous amount of text from books, articles, websites, and more. These models have learned something about patterns in grammar and word meaning, including the way that meaning arises contextually across multiple sentences and multiple turns in a conversation. When you ask ChatGPT a question, you are presenting the model with new information it tries to make a prediction on, in this case, it tries to generate a response that matches the pattern of conversation. Large language models are trained on massive amounts of text data and are essentially the backbone of NLP today. There are and have been for many years, large language models out there actually but ChatGPT has currently caught the popular imagination because of its publicly available interface and remarkable performance.\n\n\n\nChatGPT is a platform providing an interface specifically to the large language models developed by OpenAI. The GPT stands for Generative Pre-Trained Transformers which is just a fancy way of saying that the models you are chatting with have already been trained on a lot of data.\nIt's a chatbot essentially designed to generate human-like text responses based on the input it receives. Or some say to think of it as a fancy predictive text generator. You ask questions or give prompts, and it provides responses in natural language, or rather, estimates what should come next in a conversation.\n\n\n\nGoogle Search Box: Unlike Google, ChatGPT doesn't search the internet for information. Instead, it generates responses based on a massive dataset it was trained on. This training dataset includes large segments of text sampled from the internet at a specific point in time, and so can reflect language describing content on the internet, but it doesn't have real-time access to the internet. When ChatGPT answers a question, it isn’t actually looking up information and then composing that information into a response; it's just making an estimation of a response based on patterns it has seen. So, when you ask it factual questions, especially ones with common answers or phrases, it might give you an answer that sounds right but remember this is because it’s mimicking what it has seen in its training data. Think of it perhaps as a very smart parrot, sometimes 'repeating' things it has seen before.\nHuman Mind: ChatGPT is not a human; it's a machine learning model. It doesn't understand or reason like a human. It generates evidently linguistic responses based on patterns it learned from text data.\n\n\n\n\n\nLanguage Modelling: So ChatGPT models are members of this class of models we’re talking about: “large language models” (LLMs). A machine learning model represents what was learned by a machine learning algorithm. The model is created and saved after running a machine learning algorithm on training data and represents the rules, numbers, and any other algorithm-specific data structures required to make predictions on new data. Language models are designed to predict the likelihood of a sequence of text, which means that they can be set up to predict the most likely way to continue a conversation. The models behind ChatGPT are large, complex neural networks that have been exposed to an enormous amount of text from books, articles, websites, and more. These models have learned something about patterns in grammar and word meaning, including the way that meaning arises contextually across multiple sentences and multiple turns in a conversation. When you ask ChatGPT a question, it tries to generate a response that matches these patterns.\nContextual Understanding: ChatGPT also looks at the context of the question you ask, including what’s happened so far in your conversation and any instructions or details you offer about how it should respond. It tries to understand the context and generate a response that is contextually relevant, which can make its answers seem quite accurate.\nExisting Knowledge: It can recall and blend information it has observed in its training data. So, when you ask a factual question, it can sometimes generate a response that seems factual because it has encountered similar information during training. But, it can also make mistakes or provide information that is outdated or biassed because it doesn't have the ability to verify the accuracy of what it says, and it is influenced by any views inherent in its training data, whether they are right or wrong. It's like the parrot repeating something it heard: it can't check if what it's saying is true or up-to-date. That's why it's important to double-check information output by ChatGPT with reliable sources, especially when using ChatGPT for research or critical tasks.\nUser Feedback Loop: ChatGPT models like the latest GPT-4 (openai.com) have been tuned and improved over time with user feedback, as part of a model training process known as “reinforcement learning”. So for example, when users request things like python code, and try it out, users provide feedback on whether or not it worked. This feedback helps the model get better at generating code that is more likely to work.\n\n\n\n\n\nIdea Generation: ChatGPT can help brainstorm ideas for projects, essays, or creative endeavours. For example, you can ask it for ideas on new business ventures, book plots, or marketing campaigns.\nThesaurus and Rephrasing: It's excellent for finding synonyms, rephrasing sentences, or improving the clarity of your writing. You can ask it to provide alternative words or rewrite a paragraph for better readability.\nCreative Writing: ChatGPT can assist with creative writing tasks, including writing short stories, poems, or generating dialogues for characters.\nSome Learning and Explanation: It can provide explanations and answers to questions on a wide range of very general topics, making it useful for learning new concepts or understanding complex ideas. But again, always best to double check against other trusted resources.\nLanguage Translation: ChatGPT can offer some basic translation assistance, such as translating phrases or short sentences between languages.\nGenerating code snippets: It may not produce highly complex or critical code reliably but you can use it as a starting point for some common coding tasks.\n\n\n\nQuerying structured data: ChatGPT can provide outputs in the form of data structures including for instance SQL queries and JSON. So for instance if we have an SQL database with information about the content of a corpus, we can prompt ChatGPT to output queries that would apply to that database. We can then begin to imagine an interface where a non-expert user could make such a query using their own natural language, and ChatGPT could provide a connection with the structured data. This is sometimes referred to as “function calling” in the ChatGPT literature."
  },
  {
    "objectID": "llms.html#relevance-to-the-library-sector-large-language-models-llm-and-chatgpt-uses-in-libraries-today",
    "href": "llms.html#relevance-to-the-library-sector-large-language-models-llm-and-chatgpt-uses-in-libraries-today",
    "title": "Understanding Large Language Models",
    "section": "",
    "text": "[Need to work on this section with written examples/more narrative around opportunities and challenges]\n\nA Tech Librarian Explains How to Build AI Literacy - Choice 360\nChatGPT: Implications for academic libraries | Cox | College & Research Libraries News (acrl.org)\nUsing GPT on Library Collections (Matt Miller)\nhttps://programminghistorian.org/en/lessons/interrogating-national-narrative-gpt"
  },
  {
    "objectID": "llms.html#hands-on-activity-and-other-self-guided-tutorials",
    "href": "llms.html#hands-on-activity-and-other-self-guided-tutorials",
    "title": "Understanding Large Language Models",
    "section": "",
    "text": "The following activity was delivered to British Library staff as part of a monthly Hack & Yack.\n\n\nFor this activity we’ll primarily use the freely available ChatGPT (openai.com) interface. For this you’ll need to have a free google account.\n\n\n\nTo get a useful response from ChatGPT, “prompting” is key. If you only ask a simple question, you may not be happy with the results and decide to dismiss the technology too quickly, but today’s purpose is to have a deeper play in order to develop our critical thinking and information evaluation skills, allowing us to make informed decisions about utilising tools like ChatGPT in our endeavours.\nSome best practices for writing a good prompt (helpful hints/tips gleaned from the suggested readings in this guide):\n\nGive the context. The more you explain the ins and outs of what you want ChatGPT to do, the more relevant your answer will be. For example, “You are an expert in [fill in the blank for your topic].”\nBe very specific and concrete about what you want it to do (and equally, what you don’t want it to do). For instance you may want to specify word count, how many items you’d like in a list, tone of voice, etc.\nGive clear instructions on what the output should look like, and be simple and concise in your language.\nProvide examples. Much like a human, ChatGPT often understands best when you provide an example for it to work with, especially if you want it to produce something that closely resembles something you’ve seen online.\nAsk ChatGPT to “act like” someone: Sometimes, it can help to start your prompt by asking ChatGPT to “act like” a certain type of person that would be particularly well-placed to respond to the query you're posing.\n\nIf you’re not satisfied with any part of the answer, you can keep building on it, asking ChatGPT to revise it in any way you like as it will continue on from previous enquiries in a session. (If you’d rather it not do that you can add “Please ignore all previous instructions” to start a prompt fresh). To learn more about prompting, there is a free online course: Learn Prompting.\n\n\n\n\nHave a play generating responses to some of the below questions (or come up with your own)!\nCritically evaluate the responses you receive from ChatGPT.\n\nIs the information/response credible?\nAre there any biases in the responses?\nDoes the information align with what you know from other sources?\n\nConsider your findings, the strengths and weaknesses, ethical considerations and challenges of using AI tools such as this.\n\n\n\n\nTry this….\n**Example Prompts\nFurther considerations/Notes\n\n\n\n\nAsk ChatGPT to create a title for a new exhibition\n\n\n\n\nAsk ChatGPT to create an exhibition label for items in an exhibition\n“Write an exhibition label for this archived website http://moorfootru nners.blogspot.co.uk/”\n\n\n\nAsk ChatGPT to create a blog post on a topic for which you are very familiar\n\n\n\n\nAsk ChatGPT to help you come up with ideas for teaching\nTry something like this:\n“You are an academic librarian focusing on instruction. Please make an outline of important topics to cover for a classroom lecture on ChatGPT. This will be part of a series of instruction sessions about information literacy. You have already worked with this class on the basic concepts of information literacy. Create the outline as a bulleted list and follow it with a classroom activity based on one of the topics you’ve discussed about ChatGPT.”\nFrom: A Tech Librarian Explains How to Build AI Literacy - Choice 36 0\nWhen you get the results, you can then ask it to give you an additional activity or set of activities on the same topic.\nHave a play around with different training subject areas.\n\n\nAsk ChatGPT to write a bio for yourself, providing it with details for instance as a list of facts about you\n\n\n\n\nAsk ChatGPT to Act as a Translator\nTry something like this:\n“I want you to act as an English translator, spelling corrector and improver. I will speak to you in any language and you will detect the language, translate it and answer in the corrected and improved version of my text, in English. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, upper level English words and sentences. Keep the meaning same, but make them more literary. I want you to only reply the correction, the improvements and nothing else, do not write explanations. My first sentence is”istanbulu cok seviyom burada olmak cok guzel”\nFrom: Awesome ChatGPT Prompts | This repo includes ChatGPT prompt curation to use ChatGPT better. \n\n\n\nAsk ChatGPT to create an outline for a PowerPoint presentation\n\n\n\n\nAsk ChatGPT to extract metadata from a provided text\n\n\n\n\nAsk ChatGPT to write a query for a suppositional SQL database that you describe\n“We have an SQL database with the following tables: 'books' and 'authors'. The 'books' table has columns 'title', 'date', and 'topic'. The 'authors' table has columns 'name', 'birth_date', 'death_date', and 'gender'. I'm going to write some questions about things in this database, and I would like you to respond with SQL queries that would find the information I'm asking about.”\nRESPONSE: “Of course! Feel free to ask any questions you have about the database, and I'll provide you with SQL queries to retrieve the information you need. Please go ahead and ask your questions.”\nINPUT: “I'd like to find books about the second world war written by women born after the war ended.”\nRESPONSE: “To find books about the Second World War written by women born after the war ended, you can use the following SQL query:”\nSELECT b.title, b.date, a.name\nFROM books b\nJOIN authors a ON b.author_id = a.author_id\nWHERE b.topic = 'Second World War'\nAND YEAR(a.birth_date) &gt; 1945\nAND a.gender = 'female';\n\n\n\nHave a look at this project Matt Miller did experimenting with [Using GPT on Library Collections (thisismattmill er.com)]{.underlin e}\n“You are a helpful assistant that is summarizing and extracting data from a journal written by Susan B. Anthony in {RECORD_DATE_HERE}. You only answer using the text\ngiven to you. You do not make-up additional information, the answer has to be contained in the text provided to you. Each page is a diary entry or financial bookkeeping. You will structure your answer in valid JSON, if there are any quote marks in the content escape them as \".”\n“If the following text contains multiple journal entries, extract each one into an array of valid JSON dictionaries. Each dictionary represents one of the entries, extract the date and\nthe date again in the format yyyy-mm-dd and the city or state it was written in and other geographical locations mentioned that entry and people mentioned that entry and the complete\nfull text of the entry and a one sentence summary of the text, using the JSON keys dateText, dateFormated, cityOrState, geographicalLocations, people, fullText, summaryText: {FULL_TEXT_HERE}“\nThinking about this project, could you think of a similar collection that you might be able to experiment with to parse data similarly? How might you like to re-write the prompt for your own project?\n\n\nTry to use it to create social media posts\nThere is a new network called CHOSN for those working in Galleries-Libr aries-Archives-Museums (GLAM) and cultural heritage organisations as research support and research-active staff. This network is a community of practice for research support and research-active staff who work in GLAM organisations interested in developing and sharing open scholarship knowledge and skills, organising events, and supporting each other in this area. Can you write social media post for 140 character to announce this network and call people to join in?\n\n\n\nPROMPT: Act as a librarian advising a history student in the UK doing research into the third plague pandemic in India during the early 20th century. What archival resources could they use?\nRESPONSE: Certainly! If you're a history student in the UK researching the Third Plague Pandemic in India during the early 20th century, there are several archival resources you can explore to enhance your research. These archives will provide you with primary sources, documents, and historical records that can help you gain a deeper understanding of this important historical event. Here are some key archival resources to consider:\n1. **The National Archives (TNA) of the United Kingdom**:\n- TNA holds records related to British colonial administration in India during the early 20th century. Look for documents related to public health, sanitation, and official correspondence about the plague.\n2. **The India Office Records**:\n- These records are part of the British Library's holdings and contain a wealth of information on India during the colonial period. You can find reports, letters, and administrative documents related to the Third Plague Pandemic.\n3. **The British Library**:\n- The British Library has a substantial collection of materials related to India, including newspapers, periodicals, and publications from that era. You can find newspaper articles, books, and reports that discuss the plague's impact in India.\n4. **The Wellcome Collection**:\n- The Wellcome Collection in London has an extensive library and archive of materials related to the history of medicine. You may find documents, photographs, and medical reports pertaining to the plague in India.\n5. **Local Archives in India**:\n- Depending on your specific focus within India, you should also explore local archives and libraries. For example, the National Archives of India in Delhi and state archives may have valuable records.\n6. **Digital Collections**:\n- Many institutions, including the British Library and the Wellcome Collection, have digitized collections that you can access online. These digital resources can be very helpful for remote research.\n7. **University Libraries**:\n- Don't forget to check with your university's library. They may have subscriptions to digital archives and databases that can provide access to primary source materials and scholarly articles related to the Third Plague Pandemic in India.\n8. **Academic Journals**:\n- Look for scholarly articles in history and medical history journals. JSTOR and other academic databases can be valuable for finding secondary sources and research papers.\n9. **Interlibrary Loan Services**:\n- If you find a source or book that's not available in your university's library, you can request it through interlibrary loan services. This expands your access to materials from other institutions.\n10. **Archival Finding Aids**:\n- Be sure to use finding aids and catalog search tools provided by these institutions to locate specific documents and records related to the Third Plague Pandemic.\nRemember to take thorough notes, document your sources meticulously, and consult with your professors or advisors for guidance throughout your research process. Good luck with your research into this important historical topic!\n\n\n\nPROMPT: Act as an archivist producing a catalogue record for an archival document. What subject, place and name authorities or terms would you choose for the following text? [gave it c50% of the full text transcription of IO R/F/4/1754/71645]\nRESPONSE: Here's a suggested catalog record for the provided archival document, along with subject, place, and name authorities/terms:\nTitle: Development of Hemp Cultivation for Cordage Manufacturing\nAuthor: [Author's Name if available]\nDate: [Date of the Document, if available]\nDescription:\nThis archival document explores the historical development of hemp cultivation for cordage (rope) production, emphasizing its critical importance for mechanical purposes and ship rigging during the 19th century. It discusses the transition from skin and leather ropes to vegetable fiber, particularly hemp, and the widespread cultivation and commerce of hemp in various nations. The document highlights the vital role of hemp during wartime and its impact on British shipping during supply disruptions. Additionally, it underscores the attention given to hemp cultivation in India and its various applications, focusing on the Cannabis Sativa plant.\nSubjects:\nCordage Industry\nHemp Cultivation\nRope Manufacturing\nShip Rigging\nHemp Fiber\nAgriculture in India\nColonial Agriculture\nInternational Commerce\nWar Supply Chains\nMechanical Engineering\nFiber Plants\nPlaces:\nUnited Kingdom\nIndia\nNorth America\nRussia\nArabia\nPersia\nChina\nEgypt\nTurkey\nEurope\nAsia\nNames:\nAlexandre Yersin (if mentioned as the author or contributor)\nDr. Roxburgh (for his contributions to hemp cultivation in India)\nNotes:\nThis document provides historical insights into the cultivation of hemp for cordage and its significance in various regions during the 19th century, with a focus on its mechanical properties and wartime importance.\nPlease note that the specific author and date of the document were not provided in the text you provided. If this information is available, it should be included in the catalog record. Additionally, you may need to consult relevant authority files or controlled vocabularies to ensure accuracy in subject, place, and name authorities.\nCOMMENT: The inclusion of Yersin as a suggested authority is interesting / worrying, as he had cropped up in an answer to a previous question, and I had told it to disregard all of the previous conversation data before posting the cataloguing prompt…\nIn terms of indexing, it included a lot of incidental references in the text which a cataloguer would not include as subject or place index terms [should flag at this point that I did not write the BL’s catalogue entry for this]]\nI should really give it the full text before judging the description…"
  },
  {
    "objectID": "llms.html#recommended-reading-viewing",
    "href": "llms.html#recommended-reading-viewing",
    "title": "Understanding Large Language Models",
    "section": "",
    "text": "40 Best ChatGPT Prompts You Simply Have To Try in 2023 (tech.co)\nA Tech Librarian Explains How to Build AI Literacy - Choice 360\nChatGPT: Implications for academic libraries | Cox | College & Research Libraries News (acrl.org)\nUsing GPT on Library Collections (Matt Miller)\nhttps://programminghistorian.org/en/lessons/interrogating-national-narrative-gpt\nWelcome | Learn Prompting: Your Guide to Communicating with AI"
  },
  {
    "objectID": "atr.html",
    "href": "atr.html",
    "title": "Automatic Text Recognition (OCR/HTR)",
    "section": "",
    "text": "Cultural heritage organisations have been digitising their historical collections for several decades, outputting large-scale sets of digitised collection items - printed books, newspapers, manuscripts, maps, and many other content types as simple JPG, PNG, or TIFF images. Though these collections are made available for users to read online, there is often an important layer of accessibility that is missing as the text appearing in these images is not always made searchable, editable, or analysable.\nAutomatic Text Recognition (ATR) refers to the process of using software to convert images of text, such as scanned or photographed documents, photos, or printed pages, into machine-readable text. ATR is primarily associated with Optical Character Recognition (OCR) (for print materials) and Handwritten Text Recognition (HTR) technologies (for handwritten materials) that enable computers to identify and extract text from various sources. These technologies are critical for digitising historical and cultural documents, making them searchable, accessible, and preservable for future generations.\nThough ATR technologies have been around in some form or another for nearly as long as we’ve been digitising, results can be patchy for cultural heritage collections. This may be down to costs as these technologies are typically considered an add-on to the basic photographic or scanning services and institutions or projects don’t have the funds available to cover that aspect of digitisation. Or the traditional OCR technology at any given time simply isn’t developed enough to provide very accurate results to handle the anomalies of, for instance, quite worn or warped manuscript pages. Or in the case of handwritten texts, particularly low-resource languages, the existing technology simply cannot cope and text outputs are illegible. The advent of machine learning technologies applied to the challenge of Automatic Text Recognition of handwritten or print materials, and with it, the ability to train a software to recognise specific text based on what it has already seen, however, provides huge opportunities to transform accessibility to the text contained within all manner of historical digitised images.\nSo what is the difference between the decades-old OCR technology and the more recent, AI/Machine Learning-based software? Traditional OCR systems rely on a set of predefined rules and templates to recognise characters. These rules are often based on the geometric properties of the text, such as the shapes and patterns of characters. On the other hand, Machine Learning-based OCR, or in other words, Automatic Text Recognition that leverages Artificial Intelligence, uses neural networks to learn to recognise characters from large datasets. These systems can be trained to automatically learn to identify the features that distinguish different characters and predict with some probability what that character could be. AI-OCR can handle a wide variety of fonts, sizes, and styles, and is robust to noisy, distorted, or low-quality images. The models can generalise well to different types of documents and text layouts; and they can continuously improve by retraining on new data, which allows them to adapt to new types of text and writing styles over time.\nWhen diving deeper into AI-OCR, you may encounter the term ‘Ground Truth’. Ground Truth refers to the accurate, manually created and verified data used as a standard or benchmark to both train and evaluate the performance of OCR/HTR systems. Ground truth data consists of the correct transcription of a document, including precise details about characters, words, and layout. It is used to ‘teach’ software how to recognise and transcribe text, as well as measure the accuracy of OCR/HTR outputs by comparing the machine-recognised text against this gold-standard reference.\nAutomatic Text Recognition typically involves multiple stages or elements, which include image pre-processing, binarisation, layout analysis, and text recognition.\n\nImage Pre-processing: Pre-processing is the first step and focuses on enhancing the quality of the input image to improve recognition accuracy. This may include tasks such as noise reduction, skew correction (to align slanted images), and contrast adjustment. These operations are crucial when dealing with old or degraded documents, where imperfections in the image can hinder the subsequent stages.\nBinarisation: Binarisation converts a grayscale or colour image into a binary image, typically using black for the text and white for the background. This simplifies the image, making it easier for the OCR/HTR system to distinguish between the text and non-text elements. This step is especially important for historical documents, where stains, fading, or other degradation can confuse the OCR/HTR engine.\n\n Examples of binarisation and its effects on legibility, created by Peter Smith who worked to improve Chinese HTR processes\n\nLayout Analysis: In layout analysis, the system identifies the structure of the document, distinguishing between various elements such as paragraphs, columns, headings, footnotes, and images. It is essential for documents with complex formatting (e.g. newspapers or tables) to ensure that the text is correctly segmented and processed. This step may also involve detecting text regions in multi-layout documents or distinguishing between handwritten and printed text.\nText Recognition: The core of the OCR/HTR process is text recognition, where the system identifies individual characters, words, and sentences within the segmented text regions. Modern OCR/HTR engines use pattern recognition techniques or machine learning algorithms, such as neural networks, to improve accuracy. Some systems also perform language modelling, where the recognised text is checked against a dictionary or corpus to ensure contextual correctness, particularly useful for older languages or scripts.\nPost-Processing: OCR/HTR often produces errors, especially when dealing with degraded, old, or complex manuscripts. To improve accuracy, post-processing correction is crucial. One effective method for refining OCR/HTR outputs is crowdsourcing text correction, where volunteers, often through online platforms, manually review and correct transcribed text. This method leverages the knowledge and dedication of the public to handle the nuances of historical documents that automated systems struggle with, such as obscure spellings or unusual handwriting styles. Recent experiments in automating text recognition have leveraged Large Language Models (LLMs) to enhance the accuracy of OCR/HTR systems. LLMs, such as GPT-based models, are particularly adept at understanding context and handling ambiguities in textual data, which makes them valuable for recognising and correcting errors in historical documents. LLMs can also be fine-tuned to specific historical corpora, allowing them to better interpret unique vocabulary, syntax, or stylistic variations. And, it should be mentioned that once you have perfectly post-processed OCR/HTR results, you can use those as Ground Truth to retrain models and improve them!",
    "crumbs": [
      "TOPIC GUIDES",
      "Automatic Text Recognition (OCR/HTR)"
    ]
  },
  {
    "objectID": "atr.html#introduction",
    "href": "atr.html#introduction",
    "title": "Automatic Text Recognition (OCR/HTR)",
    "section": "",
    "text": "Cultural heritage organisations have been digitising their historical collections for several decades, outputting large-scale sets of digitised collection items - printed books, newspapers, manuscripts, maps, and many other content types as simple JPG, PNG, or TIFF images. Though these collections are made available for users to read online, there is often an important layer of accessibility that is missing as the text appearing in these images is not always made searchable, editable, or analysable.\nAutomatic Text Recognition (ATR) refers to the process of using software to convert images of text, such as scanned or photographed documents, photos, or printed pages, into machine-readable text. ATR is primarily associated with Optical Character Recognition (OCR) (for print materials) and Handwritten Text Recognition (HTR) technologies (for handwritten materials) that enable computers to identify and extract text from various sources. These technologies are critical for digitising historical and cultural documents, making them searchable, accessible, and preservable for future generations.\nThough ATR technologies have been around in some form or another for nearly as long as we’ve been digitising, results can be patchy for cultural heritage collections. This may be down to costs as these technologies are typically considered an add-on to the basic photographic or scanning services and institutions or projects don’t have the funds available to cover that aspect of digitisation. Or the traditional OCR technology at any given time simply isn’t developed enough to provide very accurate results to handle the anomalies of, for instance, quite worn or warped manuscript pages. Or in the case of handwritten texts, particularly low-resource languages, the existing technology simply cannot cope and text outputs are illegible. The advent of machine learning technologies applied to the challenge of Automatic Text Recognition of handwritten or print materials, and with it, the ability to train a software to recognise specific text based on what it has already seen, however, provides huge opportunities to transform accessibility to the text contained within all manner of historical digitised images.\nSo what is the difference between the decades-old OCR technology and the more recent, AI/Machine Learning-based software? Traditional OCR systems rely on a set of predefined rules and templates to recognise characters. These rules are often based on the geometric properties of the text, such as the shapes and patterns of characters. On the other hand, Machine Learning-based OCR, or in other words, Automatic Text Recognition that leverages Artificial Intelligence, uses neural networks to learn to recognise characters from large datasets. These systems can be trained to automatically learn to identify the features that distinguish different characters and predict with some probability what that character could be. AI-OCR can handle a wide variety of fonts, sizes, and styles, and is robust to noisy, distorted, or low-quality images. The models can generalise well to different types of documents and text layouts; and they can continuously improve by retraining on new data, which allows them to adapt to new types of text and writing styles over time.\nWhen diving deeper into AI-OCR, you may encounter the term ‘Ground Truth’. Ground Truth refers to the accurate, manually created and verified data used as a standard or benchmark to both train and evaluate the performance of OCR/HTR systems. Ground truth data consists of the correct transcription of a document, including precise details about characters, words, and layout. It is used to ‘teach’ software how to recognise and transcribe text, as well as measure the accuracy of OCR/HTR outputs by comparing the machine-recognised text against this gold-standard reference.\nAutomatic Text Recognition typically involves multiple stages or elements, which include image pre-processing, binarisation, layout analysis, and text recognition.\n\nImage Pre-processing: Pre-processing is the first step and focuses on enhancing the quality of the input image to improve recognition accuracy. This may include tasks such as noise reduction, skew correction (to align slanted images), and contrast adjustment. These operations are crucial when dealing with old or degraded documents, where imperfections in the image can hinder the subsequent stages.\nBinarisation: Binarisation converts a grayscale or colour image into a binary image, typically using black for the text and white for the background. This simplifies the image, making it easier for the OCR/HTR system to distinguish between the text and non-text elements. This step is especially important for historical documents, where stains, fading, or other degradation can confuse the OCR/HTR engine.\n\n Examples of binarisation and its effects on legibility, created by Peter Smith who worked to improve Chinese HTR processes\n\nLayout Analysis: In layout analysis, the system identifies the structure of the document, distinguishing between various elements such as paragraphs, columns, headings, footnotes, and images. It is essential for documents with complex formatting (e.g. newspapers or tables) to ensure that the text is correctly segmented and processed. This step may also involve detecting text regions in multi-layout documents or distinguishing between handwritten and printed text.\nText Recognition: The core of the OCR/HTR process is text recognition, where the system identifies individual characters, words, and sentences within the segmented text regions. Modern OCR/HTR engines use pattern recognition techniques or machine learning algorithms, such as neural networks, to improve accuracy. Some systems also perform language modelling, where the recognised text is checked against a dictionary or corpus to ensure contextual correctness, particularly useful for older languages or scripts.\nPost-Processing: OCR/HTR often produces errors, especially when dealing with degraded, old, or complex manuscripts. To improve accuracy, post-processing correction is crucial. One effective method for refining OCR/HTR outputs is crowdsourcing text correction, where volunteers, often through online platforms, manually review and correct transcribed text. This method leverages the knowledge and dedication of the public to handle the nuances of historical documents that automated systems struggle with, such as obscure spellings or unusual handwriting styles. Recent experiments in automating text recognition have leveraged Large Language Models (LLMs) to enhance the accuracy of OCR/HTR systems. LLMs, such as GPT-based models, are particularly adept at understanding context and handling ambiguities in textual data, which makes them valuable for recognising and correcting errors in historical documents. LLMs can also be fine-tuned to specific historical corpora, allowing them to better interpret unique vocabulary, syntax, or stylistic variations. And, it should be mentioned that once you have perfectly post-processed OCR/HTR results, you can use those as Ground Truth to retrain models and improve them!",
    "crumbs": [
      "TOPIC GUIDES",
      "Automatic Text Recognition (OCR/HTR)"
    ]
  },
  {
    "objectID": "atr.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "href": "atr.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "title": "Automatic Text Recognition (OCR/HTR)",
    "section": "Relevance to the Library Sector (Case Studies/Use Cases)",
    "text": "Relevance to the Library Sector (Case Studies/Use Cases)\nKeeping up with, and even contributing to, developments in Automatic Text Recognition technology is vital for heritage organisations and especially for the library sector, where large volumes of historical and cultural documents are preserved. ATR technologies provide several key benefits:\n\nAccessibility: ATR technologies are essential for libraries working to make their text content available for users. Once digitised and converted into searchable text, documents become accessible to a global audience. Researchers and the general public can search and access texts remotely, making previously hidden information available. Creating searchable documents allows users to quickly locate specific terms or phrases within vast collections. This enhances the research process and saves time.\nContent Enrichment: ATR can help enrich library records by enhancing their metadata; therefore assisting libraries in delivering a better service to their users. Different entities could be extracted from the text, such as author or place of publication, as well as subjects and descriptions. These could be used to enhance catalogue records for the benefit of library users.\nDigital Research: By converting historical texts into machine-readable formats, ATR technologies support digital humanities projects, where large-scale analysis, such as text mining or linguistic research, can uncover new insights into history, culture, and language development. The ability to extract text from digitised items is fundamental for any downstream tasks and enables unlocking content for large-scale analysis, e.g. text mining, Natural language processing (NLP), Named Entity Recognition (NER), sentiment analysis or topic modelling.​\n\n\nCase Studies\nIn collaboration with PRImA Research Lab, the British Library ran several OCR/HTR competitions with the aim of encouraging the development of state-of-the-art in text recognition software, facilitating dialogue around the challenges and opportunities of ATR, and creating openly licensed ground truth datasets. Competitions around early Bengali books and Quarterly Lists were run as part of the Two Centuries of Indian Print project, and the project used Transkribus to create OCR transcriptions for the Bengali books, in collaboration with the School of Cultural Texts and Records at Jadavpur University. Additional competitions were focused on finding solutions to automatically transcribe historical Arabic scientific manuscripts, using materials digitised by the Library and published on the Qatar Digital Library (QDL).\n Screenshot from Transkribus, used as the ATR engine in the Two Centuries of Indian Print project\nThe Open Islamicate Texts Initiative (OpenITI) is a collaborative project involving researchers from Aga Khan University’s Institute for the Study of Muslim Civilisations in London, the Roshan Institute for Persian Studies at the University of Maryland, College Park, and Universität Hamburg. Its goal is to establish the digital infrastructure needed for the study of Islamicate cultures. OpenITI focuses on building digital resources for Islamicate studies by enhancing optical character recognition (OCR) and handwritten text recognition (HTR) for Arabic-script texts, creating standardised OCR and HTR outputs and text encoding, and developing platforms for collaborative work on Islamicate text corpora and digital editions.\nThe Legacies of Curatorial Voice in the Descriptions of Incunabula Collections at the British Library project was part of Digital Curator Dr Rossitza Atanassova’s AHRC-RLUK funded Professional Practice Fellowship Project (2022–23). It aimed to explore innovative methods for working with digitised catalogues, enhancing the discoverability and usability of the collections they document. The research centred on the Catalogue of Books Printed in the 15th Century Now at the British Museum (BMC), published between 1908 and 2007, which describes over 12,700 volumes in the British Library’s incunabula collection. It used Transkribus as the ATR software and also as a search and publishing web platform. The project could then apply computational techniques and corpus analysis of the catalogue data thanks to the availability of OCRed text and provides fresh insights into this resource!",
    "crumbs": [
      "TOPIC GUIDES",
      "Automatic Text Recognition (OCR/HTR)"
    ]
  },
  {
    "objectID": "atr.html#hands-on-activity-and-other-self-guided-tutorials",
    "href": "atr.html#hands-on-activity-and-other-self-guided-tutorials",
    "title": "Automatic Text Recognition (OCR/HTR)",
    "section": "Hands-on activity and other self-guided tutorial(s)",
    "text": "Hands-on activity and other self-guided tutorial(s)\nHere are some excellent resources to get you started:\nAutomatic Text Recognition: Harmonising ATR workflows: This DARIAH-EU-supported resource is a great place to start. This website features a set of video tutorials on ATR in English, French and German, and also includes really useful blog posts, articles and links.\nCheck out the Transkribus YouTube channel for a set of beginner-friendly tutorial videos, learning how to get started with Transkribus to effectively digitise and preserve historical documents.\nIf you’re interested in eScriptorium, have a look at their thorough documentation and tutorials on YouTube created by the OpenITI project. These are split into five parts: Part I, Part II, Part III, Part IV, and Part V.\nThis step-by-step guide will teach you how to use the Tesseract open-source software, and it also recommends some software that helps prepare documents for Tesseract use.\nFor more advanced practitioners, there’s an introductory course by Dr William Mattingly teaching you how to automate OCR in Python. It includes using OpenCV (an open-source library specialising in computer vision and machine learning tasks) and Pytesseract, an OCR tool in Python. Helpfully, this course functions alongside a YouTube series of tutorials on OCR in Python.\nAnother one for the more confident practitioners is this Programming Historian OCR with Google Vision API and Tesseract tutorial by Isabelle Gribomont, published in March 2023.\nThis Programming Historian OCR and Machine Translation course by Andrew Akhlaghi (published in January 2021) uses Tesseract for OCR and takes the results to another level - translation.",
    "crumbs": [
      "TOPIC GUIDES",
      "Automatic Text Recognition (OCR/HTR)"
    ]
  },
  {
    "objectID": "atr.html#recommended-readingviewing",
    "href": "atr.html#recommended-readingviewing",
    "title": "Automatic Text Recognition (OCR/HTR)",
    "section": "Recommended Reading/Viewing",
    "text": "Recommended Reading/Viewing\nThis is a great blog post by Chris Woodform, simply entitled Optical character recognition (OCR). It’s a good place to start! It explains what OCR is and how it works, and even looks at the history of this technology.\nAwesome OCR is a resource created by Konstantin Baierer from the OCR-D project. It hasn’t been updated for a while, however, it includes really useful and comprehensive lists of software tools, libraries and literature. It also includes a list of ground truth datasets, so well worth taking a look.\nThe IMPACT Centre of Competence  is a useful OCR resource. In their words, IMPACT is a ‘not for profit organisation with the mission to make the digitisation of text “better, faster, cheaper” and to further advance the state-of-the-art in the field of document imaging, language technology and the processing of historical text.’ You can find datasets, training materials, blogs and more!\n\n\n\nAn Introduction to Ground Truth Production with the IMPACT Project\n\n\nAn excellent guide to newspaper OCR and data analysis is this Short Guide to Historical Newspaper Data, Using R by Yann Ryan.\nMany excellent data analysis tools such as NLP can also be found on this GitHub page, which collated materials used for the Text to Tech workshop at the Digital Humanities Oxford Summer School, by Kaspar von Beelen, Mariona Coll Ardanuy and Federico Nanni (and this is another brilliant introduction into NLP!).\nThere are many papers on OCR/HTR but here’s a small selection:\n\nKhan, R., Gupta, N., Sinhababu, A., & Chakravarty, R. (2023). Impact of Conversational and Generative AI Systems on Libraries: A Use Case Large Language Model (LLM). Science & Technology Libraries, 1–15. https://doi.org/10.1080/0194262X.2023.2254814\nNeudecker, C., Baierer, K., Federbusch, M., Boenig, M., Würzner, K. M., Hartmann, V., & Herrmann, E. (2019). OCR-D: An end-to-end open source OCR framework for historical printed documents. In Proceedings of the 3rd international conference on digital access to textual cultural heritage, 53-58. https://dl.acm.org/doi/10.1145/3322905.3322917\nNguyen, T.T.H., Jatowt, A., Coustaty, M., & Doucet, A. (2021). Survey of Post-OCR Processing Approaches. ACM Computing Surveys (CSUR), 54(6), 1-37. https://doi.org/10.1145/3453476\nSmith, D.A. & Cordell, R. (2018). A Research Agenda for Historical and Multilingual Optical Character Recognition.\nVan Strien, D., Beelen, K., Ardanuy, M., Hosseini, K., McGillivray, B., & Colavizza, G. (2020). Assessing the impact of OCR quality on downstream NLP tasks. SCITEPRESS - Science and Technology Publications. https://doi.org/10.17863/CAM.52068\n\nSome journals to look out for include, for example, the International Journal on Document Analysis and Recognition (IJDAR), Pattern Recognition, or the IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI).\nThe team behind the Hypotheses ‘Automatic Text Recognition: Harmonising ATR workflows’ resource created this insightful road map to help you get started with Automatic Text Recognition. The road map is divided into three sections, and asks you to consider the following questions:\nI - General Information\n\nWhat type of texts/text collections do you work with?\nHow can you integrate Automated Text Recognition in your workflow?\n\nII - Technical information\n\nWhy do you want to use ATR?\nWhat is your objective?\nDo you have technical and financial resources?\n\nIII - Setting up ATR in your project\n\nChoose your tool\nIs there transcription data that can be reused (e.g. training data)?\nIs there an appropriate generic model?\nWhat are your transcription rules?\nDo you plan to share your ATR training data? What are your ATR predictions?\nWhere can you share data? In which format?\n\nThis document also includes links to tutorials and documentation, a selection of articles, ATR tools and where to find ATR ground truth datasets.\nWhen it comes to ground truth datasets, a good place to look is the HTR-United resource, which includes training datasets used for both transcription or segmentation models, for different periods and styles of writing.\nOCR-D is a good place to visit too, and it has a ground truth repository available here.",
    "crumbs": [
      "TOPIC GUIDES",
      "Automatic Text Recognition (OCR/HTR)"
    ]
  },
  {
    "objectID": "atr.html#finding-communities-of-practice",
    "href": "atr.html#finding-communities-of-practice",
    "title": "Automatic Text Recognition (OCR/HTR)",
    "section": "Finding Communities of Practice",
    "text": "Finding Communities of Practice\nSome tools and platforms have solid communities around them which you can get in touch with - or be a part of. Transkribus, for example, has an active Facebook page and a user group, where Transkribus users can ask questions and get support from the Transkribus team and from each other.\nSeveral conference series discuss advances in OCR/HTR, and would be a good place to meet colleagues and hear about interesting ATR projects. For example, the International Conference on Document Analysis and Recognition (ICDAR) and the International Conference on Frontiers in Handwriting Recognition (ICFHR) have been well established. Alternatively, many Digital Humanities conferences will have papers on this topic, e.g. the ADHO DH conference serie or AI4LAM Fantastic Futures conferences.",
    "crumbs": [
      "TOPIC GUIDES",
      "Automatic Text Recognition (OCR/HTR)"
    ]
  },
  {
    "objectID": "contributing.html",
    "href": "contributing.html",
    "title": "CONTRIBUTE TO OUR PROJECT",
    "section": "",
    "text": "We are currently working on producing the first complete edition of this resource for launch at the 54th LIBER Annual Conference 2025 in 2-4 July 2025 in Lausanne, Switzerland. Topic Guides are currently being produced through a series of in-person and online writing sprints of LIBER working group members and by direct invitation. When complete, the first edition will be deposited in the British Library Research Repository, captured in the UK Web Archive, and a DOI provided for both the overall resources and individual guides.\nThe first edition Topic Guide wishlist draws heavily on the existing skills framework and topics covered in the British Library’s Digital Scholarship Training Programme, as well as those recommended by attendees of development workshops hosted by LIBER working groups throughout 2023/2024.\nFeel free to contact Nora McGregor if you’re keen to learn more and contribute!\n\n\n\nContribute to an existing, or create a new Topic Guide (individually or in collaboration with others). Choose from our current wishlist or propose a new one. Join an upcoming writing sprint or get in touch with us directly to discuss digitalresearch@bl.uk your idea and we’ll help you get started right away!\n\n\nNOTE: Our current wishlist for future editions includes but is not limited to topics such as:\n\nClimate Change and Sustainability\nCultural Competency & Ethics in Digital Methods\nDemystifying Computational Environments for Digital Scholarship\nDigital Scholarship/Data Science Project Management, Evaluation and Impact Assessment\nDigital Storytelling\nFoundation models: When and why to use LLMs or SLMs\nResearch Data Management\nWikimedia\n\n\n\nSuggest edits to an existing Topic Guide or any of the General Resources pages by opening a new Issue or adding to the discussion on existing Issues on the project Github. If you’re new to GitHub don’t worry, we have a Topic Guide for that: GitHub: How to navigate and contribute to Git-based projects!\nJoin one of the LIBER Working Groups Digital Scholarship and Digital Cultural Heritage WG or Data Science in Libraries (open to all staff of LIBER member institutions) to keep up with the developments and ongoing maintenance of this project!\n\n\n\n\nWe held four online Topic Guide Sprints in 2024.\n\nTuesday 14 May 2024\nTuesday 03 June 2024\nTuesday 08 October 2024\nTuesday 05 November 2024\n\nTo be notified of future sprints check back here for dates/times or join one of our working groups and we’ll email out the details!\n\n\n\nPlease have a quick read through the Welcome and Topic Guide pages to familiarise yourself with this resource and its purpose.\nWhen you Register you’ll see a list of our latest Topic Guides on our wishlist. Please check off any and all Topic Guides you would be happy to work on during the day of the sprint. On the day each attendee will focus on writing just one Topic Guide however. The information you provide before the sprint will help us organise this ahead of time so that as many Topic Guides as possible have at least one dedicated author.\n\nPlease have a quick read through the Author Guidance and Style Guide section.\nWe’ll be in touch after we receive your registration to send you more details and useful information ahead of the sprint so look out for our email! If you are sent a copy of the Topic Guide Template (Google Doc) that corresponds to your topic of choice ahead of time, add your name to the header, and feel free to add notes or even make a start on drafting your guide before the sprint day if you’re keen!\n\n\n\n\nA two hour writing sprint will generally follow this format:\n\nWelcome and participant introductions (10 minutes)\n\nOverview of the project & explanation of how the day will run (15 minutes)\n\nAllocation and confirmation of individual Topic Guide Authorship for the day (15 minutes): As a group we’ll go over the wishlist and all participants will be given access to their particular Topic Guide google doc template they’ll be using during and after the sprint.\nWriting Phase (60 minutes): You’ll have an hour to begin writing your respective guide in your Google Doc template. If more than one participant are working together on a topic we can provide breakout rooms so that you can discuss amongst yourselves how to break up the work, and share ideas as you go along. You can have your camera/mic on or off during this time and co-chairs will be on hand to answer any questions or give advice on topics.\nWrapping Up & Logging progress through Github Issues (15 minutes): We have provided an Issue Template which is pre-formatted as a Topic Guide submission checklist and will walk participants through the process of opening a new issue for your draft submission. Please fill in the issue template and provide the necessary information relating to where your draft submission is currently at. Once the issue is saved, it can continue to serve as a space to continue discussion of the ongoing status of your submission and log updates where necessary, including notifying us of when it is fully ready for final review by maintainers.\nClosing Remarks & Next Steps (5 minutes)\n\n\n\n\nDuring the sprint, you’ve drafted your Topic Guide in a Google Doc. This Google Doc can continue to serve as a ‘living document’ following the sprint until you feel the content is ready to be published. Throughout this process, we will use your Github issue to maintain an overview of the docs in terms of their status and action points so please keep this updated. Each Topic Guide will be allocated a specific Maintainer contact (one of the co-chairs) who will be in touch and work with you to see the process through to completion. You may request placing your Google Doc under restricted access if you wish. We will not do this by default, but we respect that some contributors would like to keep drafts private until fully ready for submission.\nWhen your Topic Guide is ready for our review in Google Docs, please let us know by logging an update over on Github as a comment on the Issue stating this. You can also tag the maintainers so they receive a notification as well. Maintainers will generally work with you on the final edits necessary for the submission through track changes and comments within the Google Doc itself. Once these have all been resolved maintainers will log a status update in the GitHub issue.\n\n\n\n\nWe view this resource as capturing a snapshot in time and will endeavour to fully review all content a minimum of once annually to check for link rot, and content relevancy. The project team editors are committed to making quick fixes when raised throughout the year, while formal sprints and reviews coinciding with LIBER Annual Summer Conference and Winter events will be used for soliciting new content and undertaking more complex updates to the resource each year and creating new editions as necessary.\nJoin one of the LIBER Working Groups Digital Scholarship and Digital Cultural Heritage WG or Data Science in Libraries (open to all staff of LIBER member institutions) to keep up with the developments and ongoing maintenance of this project!"
  },
  {
    "objectID": "contributing.html#ways-to-contribute-to-this-project",
    "href": "contributing.html#ways-to-contribute-to-this-project",
    "title": "CONTRIBUTE TO OUR PROJECT",
    "section": "",
    "text": "Contribute to an existing, or create a new Topic Guide (individually or in collaboration with others). Choose from our current wishlist or propose a new one. Join an upcoming writing sprint or get in touch with us directly to discuss digitalresearch@bl.uk your idea and we’ll help you get started right away!\n\n\nNOTE: Our current wishlist for future editions includes but is not limited to topics such as:\n\nClimate Change and Sustainability\nCultural Competency & Ethics in Digital Methods\nDemystifying Computational Environments for Digital Scholarship\nDigital Scholarship/Data Science Project Management, Evaluation and Impact Assessment\nDigital Storytelling\nFoundation models: When and why to use LLMs or SLMs\nResearch Data Management\nWikimedia\n\n\n\nSuggest edits to an existing Topic Guide or any of the General Resources pages by opening a new Issue or adding to the discussion on existing Issues on the project Github. If you’re new to GitHub don’t worry, we have a Topic Guide for that: GitHub: How to navigate and contribute to Git-based projects!\nJoin one of the LIBER Working Groups Digital Scholarship and Digital Cultural Heritage WG or Data Science in Libraries (open to all staff of LIBER member institutions) to keep up with the developments and ongoing maintenance of this project!"
  },
  {
    "objectID": "contributing.html#join-a-writing-sprint",
    "href": "contributing.html#join-a-writing-sprint",
    "title": "CONTRIBUTE TO OUR PROJECT",
    "section": "",
    "text": "We held four online Topic Guide Sprints in 2024.\n\nTuesday 14 May 2024\nTuesday 03 June 2024\nTuesday 08 October 2024\nTuesday 05 November 2024\n\nTo be notified of future sprints check back here for dates/times or join one of our working groups and we’ll email out the details!\n\n\n\nPlease have a quick read through the Welcome and Topic Guide pages to familiarise yourself with this resource and its purpose.\nWhen you Register you’ll see a list of our latest Topic Guides on our wishlist. Please check off any and all Topic Guides you would be happy to work on during the day of the sprint. On the day each attendee will focus on writing just one Topic Guide however. The information you provide before the sprint will help us organise this ahead of time so that as many Topic Guides as possible have at least one dedicated author.\n\nPlease have a quick read through the Author Guidance and Style Guide section.\nWe’ll be in touch after we receive your registration to send you more details and useful information ahead of the sprint so look out for our email! If you are sent a copy of the Topic Guide Template (Google Doc) that corresponds to your topic of choice ahead of time, add your name to the header, and feel free to add notes or even make a start on drafting your guide before the sprint day if you’re keen!\n\n\n\n\nA two hour writing sprint will generally follow this format:\n\nWelcome and participant introductions (10 minutes)\n\nOverview of the project & explanation of how the day will run (15 minutes)\n\nAllocation and confirmation of individual Topic Guide Authorship for the day (15 minutes): As a group we’ll go over the wishlist and all participants will be given access to their particular Topic Guide google doc template they’ll be using during and after the sprint.\nWriting Phase (60 minutes): You’ll have an hour to begin writing your respective guide in your Google Doc template. If more than one participant are working together on a topic we can provide breakout rooms so that you can discuss amongst yourselves how to break up the work, and share ideas as you go along. You can have your camera/mic on or off during this time and co-chairs will be on hand to answer any questions or give advice on topics.\nWrapping Up & Logging progress through Github Issues (15 minutes): We have provided an Issue Template which is pre-formatted as a Topic Guide submission checklist and will walk participants through the process of opening a new issue for your draft submission. Please fill in the issue template and provide the necessary information relating to where your draft submission is currently at. Once the issue is saved, it can continue to serve as a space to continue discussion of the ongoing status of your submission and log updates where necessary, including notifying us of when it is fully ready for final review by maintainers.\nClosing Remarks & Next Steps (5 minutes)\n\n\n\n\nDuring the sprint, you’ve drafted your Topic Guide in a Google Doc. This Google Doc can continue to serve as a ‘living document’ following the sprint until you feel the content is ready to be published. Throughout this process, we will use your Github issue to maintain an overview of the docs in terms of their status and action points so please keep this updated. Each Topic Guide will be allocated a specific Maintainer contact (one of the co-chairs) who will be in touch and work with you to see the process through to completion. You may request placing your Google Doc under restricted access if you wish. We will not do this by default, but we respect that some contributors would like to keep drafts private until fully ready for submission.\nWhen your Topic Guide is ready for our review in Google Docs, please let us know by logging an update over on Github as a comment on the Issue stating this. You can also tag the maintainers so they receive a notification as well. Maintainers will generally work with you on the final edits necessary for the submission through track changes and comments within the Google Doc itself. Once these have all been resolved maintainers will log a status update in the GitHub issue."
  },
  {
    "objectID": "contributing.html#ongoing-maintenance-and-review",
    "href": "contributing.html#ongoing-maintenance-and-review",
    "title": "CONTRIBUTE TO OUR PROJECT",
    "section": "",
    "text": "We view this resource as capturing a snapshot in time and will endeavour to fully review all content a minimum of once annually to check for link rot, and content relevancy. The project team editors are committed to making quick fixes when raised throughout the year, while formal sprints and reviews coinciding with LIBER Annual Summer Conference and Winter events will be used for soliciting new content and undertaking more complex updates to the resource each year and creating new editions as necessary.\nJoin one of the LIBER Working Groups Digital Scholarship and Digital Cultural Heritage WG or Data Science in Libraries (open to all staff of LIBER member institutions) to keep up with the developments and ongoing maintenance of this project!"
  },
  {
    "objectID": "computer-vision.html",
    "href": "computer-vision.html",
    "title": "Computer Vision",
    "section": "",
    "text": "Computer Vision is a field of Artificial Intelligence (AI) that uses Deep Learning models to teach machines to see and interpret images and videos similar to how the human visual system does. At its core, Computer Vision involves functions like process, detection, and analysis of visual data. It uses algorithms to extract meaningful information from images and enables machines to identify objects, recognise patterns, and make decisions based on what they see. It is behind a lot of today’s technology like facial recognition, object detection, or Video Assistant Referees at football matches.\nDeep Learning uses neural networks to model complex patterns within data. These networks, much like the human brain, consist of interconnected layers of artificial neurons. During training, these models process massive datasets of images, enabling them to progressively identify features and refine their predictions with increasing accuracy. For instance, a network might initially learn to detect edges and shapes. As training progresses, it learns to identify more complex features such as curves, textures, and ultimately, the entire object itself. This continual process of feature extraction and refinement enables Deep Learning models to achieve remarkable accuracy.\nConvolutional Neural Networks (CNN) have become a cornerstone of image recognition as these neural networks are particularly well-suited for processing grid-like data, such as images. CNNs use convolutional layers that extract local features from the input image (edges, corners, etc.), which are then combined to form more complex representations in subsequent layers, allowing the network to learn hierarchical representations of the image content.\n Image retrieved from https://www.pinecone.io/learn/series/image-search/cnn/#What-Makes-a-CNN.\n\n\n\nImage processing - Preparation of input images to enhance them, e.g., noise reduction, sharpening, filtering, extraction of colour, etc.\nObject detection - Identifying specific objects within an image or video (e.g. R-CNN, SSD).\nScene understanding - Analysing the overall context of an image.\nObject classification - Assigning specific objects to a category or class (e.g. AlexNet, VGG).\nImage segmentation - Dividing an image into distinct regions or objects (e.g. U-Net, Mask R-CNN).\nMotion analysis - Tracking the movement of objects within a video (e.g. optical flow).\n\n\n\n\n\nBiases in training data - For example, facial recognition systems trained predominantly on lighter-skinned people struggle to accurately recognise darker-skinned people.\nPrivacy and ethics - The usage of visual and biometric data raises questions regarding privacy and ethics, especially when dealing with black-box models.\nGeneralisation - Models struggle to generalise objects or environments they were not trained on.\nOcclusions - Often objects in an image are partially blocked by other objects, making it difficult for algorithms to correctly identify them. Advanced models, like Mask R-CNN, can help with missing details, but it requires large amounts of training data with occlusion examples.\nFine-graining - Distinguishing between classes or very similar categories is difficult. For instance, it’s relatively easy to differentiate between a cat and a dog, but it is challenging to distinguish dog breeds.\nLighting - Changes in lighting conditions can alter the appearance of objects in an image.\nResource needs - Training and running Deep Learning models require a lot of computational resources.\n\n\n\n\nComputer Vision addresses the challenges posed by vast and diverse collections, enabling libraries to improve services and access to knowledge.\n\nImage Classification and Cataloging - Libraries manage large digital libraries containing very different material. Computer Vision and automated cataloging automate the classification of the collections, thus reducing the manual labor required and improving discoverability.\nObject Detection and Description - Models can automatically detect features and items in the material, this is useful for creating detailed metadata in large collections. Libraries can also use object detection to improve accessibility, by generating descriptive metadata for images and videos.\nAutomatic Optical Character Recognition (OCR) and Handwritten Text Recognition (HTR) - OCR/HTR helps libraries to make printed texts and handwritten documents digital. Thus, libraries use OCR/HTR to create searchable digital collections of books, manuscripts, newspapers, etc. OCR/HTR also supports accessibility, enabling text-to-speech conversions for visually impaired users.\nVisual Search and Content-Based Retrieval - Computer Vision improves search functionality in digital libraries through visual search. This allows users to upload an image and retrieve visually similar items from the collection. Content-based image retrieval also supports researchers by enabling them to find works that are similar.",
    "crumbs": [
      "TOPIC GUIDES",
      "Computer Vision"
    ]
  },
  {
    "objectID": "computer-vision.html#introduction",
    "href": "computer-vision.html#introduction",
    "title": "Computer Vision",
    "section": "",
    "text": "Computer Vision is a field of Artificial Intelligence (AI) that uses Deep Learning models to teach machines to see and interpret images and videos similar to how the human visual system does. At its core, Computer Vision involves functions like process, detection, and analysis of visual data. It uses algorithms to extract meaningful information from images and enables machines to identify objects, recognise patterns, and make decisions based on what they see. It is behind a lot of today’s technology like facial recognition, object detection, or Video Assistant Referees at football matches.\nDeep Learning uses neural networks to model complex patterns within data. These networks, much like the human brain, consist of interconnected layers of artificial neurons. During training, these models process massive datasets of images, enabling them to progressively identify features and refine their predictions with increasing accuracy. For instance, a network might initially learn to detect edges and shapes. As training progresses, it learns to identify more complex features such as curves, textures, and ultimately, the entire object itself. This continual process of feature extraction and refinement enables Deep Learning models to achieve remarkable accuracy.\nConvolutional Neural Networks (CNN) have become a cornerstone of image recognition as these neural networks are particularly well-suited for processing grid-like data, such as images. CNNs use convolutional layers that extract local features from the input image (edges, corners, etc.), which are then combined to form more complex representations in subsequent layers, allowing the network to learn hierarchical representations of the image content.\n Image retrieved from https://www.pinecone.io/learn/series/image-search/cnn/#What-Makes-a-CNN.\n\n\n\nImage processing - Preparation of input images to enhance them, e.g., noise reduction, sharpening, filtering, extraction of colour, etc.\nObject detection - Identifying specific objects within an image or video (e.g. R-CNN, SSD).\nScene understanding - Analysing the overall context of an image.\nObject classification - Assigning specific objects to a category or class (e.g. AlexNet, VGG).\nImage segmentation - Dividing an image into distinct regions or objects (e.g. U-Net, Mask R-CNN).\nMotion analysis - Tracking the movement of objects within a video (e.g. optical flow).\n\n\n\n\n\nBiases in training data - For example, facial recognition systems trained predominantly on lighter-skinned people struggle to accurately recognise darker-skinned people.\nPrivacy and ethics - The usage of visual and biometric data raises questions regarding privacy and ethics, especially when dealing with black-box models.\nGeneralisation - Models struggle to generalise objects or environments they were not trained on.\nOcclusions - Often objects in an image are partially blocked by other objects, making it difficult for algorithms to correctly identify them. Advanced models, like Mask R-CNN, can help with missing details, but it requires large amounts of training data with occlusion examples.\nFine-graining - Distinguishing between classes or very similar categories is difficult. For instance, it’s relatively easy to differentiate between a cat and a dog, but it is challenging to distinguish dog breeds.\nLighting - Changes in lighting conditions can alter the appearance of objects in an image.\nResource needs - Training and running Deep Learning models require a lot of computational resources.\n\n\n\n\nComputer Vision addresses the challenges posed by vast and diverse collections, enabling libraries to improve services and access to knowledge.\n\nImage Classification and Cataloging - Libraries manage large digital libraries containing very different material. Computer Vision and automated cataloging automate the classification of the collections, thus reducing the manual labor required and improving discoverability.\nObject Detection and Description - Models can automatically detect features and items in the material, this is useful for creating detailed metadata in large collections. Libraries can also use object detection to improve accessibility, by generating descriptive metadata for images and videos.\nAutomatic Optical Character Recognition (OCR) and Handwritten Text Recognition (HTR) - OCR/HTR helps libraries to make printed texts and handwritten documents digital. Thus, libraries use OCR/HTR to create searchable digital collections of books, manuscripts, newspapers, etc. OCR/HTR also supports accessibility, enabling text-to-speech conversions for visually impaired users.\nVisual Search and Content-Based Retrieval - Computer Vision improves search functionality in digital libraries through visual search. This allows users to upload an image and retrieve visually similar items from the collection. Content-based image retrieval also supports researchers by enabling them to find works that are similar.",
    "crumbs": [
      "TOPIC GUIDES",
      "Computer Vision"
    ]
  },
  {
    "objectID": "computer-vision.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "href": "computer-vision.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "title": "Computer Vision",
    "section": "Relevance to the Library Sector (Case Studies/Use Cases)",
    "text": "Relevance to the Library Sector (Case Studies/Use Cases)\nHaving explored the foundational concepts of Computer Vision, let’s now delve into how it is being applied in the library sector. We will take a look at some key applications within areas like collection enrichment, access and delivery, and accessibility.\n\nEnrichment of collections\nComputer Vision is transforming the enrichment of library collections by automating the classification and annotation of visual materials. With the help of object detection and image recognition, it identifies objects, patterns, and relationships within images, enabling the creation of richer metadata and contextual information. This not only improves discoverability, allowing users to locate materials more easily, but also allows for deeper insights into the historical, artistic, or cultural significance of the materials.\nA case study conducted by the University of Calgary’s Libraries and Cultural Resources explored the use of Sheeko, a metadata generation software, to create descriptive metadata from images using pre-trained models. The study concluded that, with moderate human intervention, both the descriptions and titles generated by the pre-trained models were usable. Similarly, Saint George on a Bike which was a project led by Europeana, aimed to improve the classification and metadata of cultural heritage objects, by using CNNs for object detection to identify and create semantic context for the images. These examples demonstrate the potential of combining automated AI-powered tools with human expertise to improve metadata creation, while enriching cultural heritage collections and making them more accessible and meaningful for diverse audiences. \n\n\nAccess and delivery\nSimilarly, Computer Vision is improving access, delivery, and research within library collections by enabling more intuitive and sophisticated ways to explore and analyse visual data. Advances in image recognition and retrieval allow users to discover connections, find similar materials, and engage with collections in entirely new ways, improving both the efficiency and depth of exploration.\nFor instance, imgs.ai is a text-based visual search engine designed for digital collections. It uses approximate k-NN algorithms and integrates the OpenAI CLIP model to link textual queries with visually similar content, offering new ways to navigate collections. Similarly, MAKEN, a service developed by the National Library of Norway, uses object detection to identify and retrieve similar images from the library’s digital collection. Thus providing users with yet another possibility of engaging with visual material. These examples show how Computer Vision is making it easier to access digital collections, helping users to find connections, and discover materials quickly and effortlessly.\n PixPlot is a project by the digital humanities lab of Yale University Library, it uses CNNs to cluster similar images.\n\n\nAccessibility\nComputer Vision significantly improves accessibility in libraries by working alongside technologies like OCR and HTR. OCR/HTR convert printed and handwritten texts into machine-readable formats, enabling text-to-speech applications for users with visual impairments. Read more about OCR and HTR from Automatic Text Recognition (OCR/HTR) topic guide.\nBeyond text, Computer Vision enables creation of descriptive metadata for visual materials, such as photographs, maps, or videos, thus providing richer contextual information that benefits users with cognitive or visual disabilities. For instance, a visually impaired user might hear a description of a painting that includes details about the objects and people depicted. This richer contextual information ensures that libraries remain inclusive spaces where all users can access and engage with collections in a meaningful way.\n\n\nSemantic segmentation of maps\nSemantic segmentation in an exciting frontier where Computer Vision can be of use for identifying and categorising distinct elements within maps, such as roads, buildings, water bodies, and land use regions. By using CNNs and U-Net architectures, models partition maps into meaningful segments, allowing for detailed analysis and improved usability. This supports historical research, geographic analysis, and so on, by extracting structured data from cartographic sources.\nFor example, JADIS, developed by the National Library of France, it is a tool designed for semantically segmented, georeferenced, and geocoded maps of Paris.  Similarly, MapReader, an outcome of the Living with the Machines project, offers a Computer Vision pipeline for analysing large collections of historical maps.",
    "crumbs": [
      "TOPIC GUIDES",
      "Computer Vision"
    ]
  },
  {
    "objectID": "computer-vision.html#hands-on-activity-and-other-self-guided-tutorials",
    "href": "computer-vision.html#hands-on-activity-and-other-self-guided-tutorials",
    "title": "Computer Vision",
    "section": "Hands-on activity and other self-guided tutorial(s)",
    "text": "Hands-on activity and other self-guided tutorial(s)\nFor those new to the field, Google Colab Notebooks offer a good starting point with plenty of notebooks on Computer Vision, one great example being this collection. The TensorFlow Playground allows users to experiment with neural network architectures in an interactive way, offering insight into the understanding of how those work. GLAM Workbench is a hands-on guide that focuses on applying Computer Vision to GLAM collections, mainly from New Zealand and Australia. It explores how digitised images can be analysed to identify patterns and improve the accessibility of digital heritage. For practical coding experience, versatile tutorials are found at OpenCV and RealPython. If a more humanities oriented point of view is desired, then Computer Vision related tutorials can also be found at the Programming Historian.",
    "crumbs": [
      "TOPIC GUIDES",
      "Computer Vision"
    ]
  },
  {
    "objectID": "computer-vision.html#recommended-readingviewing",
    "href": "computer-vision.html#recommended-readingviewing",
    "title": "Computer Vision",
    "section": "Recommended Reading/Viewing",
    "text": "Recommended Reading/Viewing\nFor those looking to get a deeper understanding of Computer Vision, some key resources include:\n\nArnold, T., Tilton, L. (2023). Distant viewing: Computational Exploration of Digital Images. The MIT Press. https://doi.org/10.7551/mitpress/14046.001.0001\nKrizhevsky, A., Sutskever, I., Hinton, G. (2012). ImageNet Classification with Deep Convolutional Neural Networks. Advances in Neural Information Processing Systems 25 (NIPS 2012). Retrieved from https://papers.nips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf\nSzeliski, T. (2022). Computer Vision: Algorithms and Applications. Springer. https://doi.org/10.1007/978-3-030-34372-9\nStanford University’s course CS231n Convolutional Neural Networks for Visual Recognition 2016 and 2017 lectures are up on YouTube.",
    "crumbs": [
      "TOPIC GUIDES",
      "Computer Vision"
    ]
  },
  {
    "objectID": "computer-vision.html#finding-communities-of-practice",
    "href": "computer-vision.html#finding-communities-of-practice",
    "title": "Computer Vision",
    "section": "Finding Communities of Practice",
    "text": "Finding Communities of Practice\nThere are AI4LAM, CENL network group ‘AI in libraries’ and IFLA Artificial Intelligence Special Interest Group communities, while in the IIIF community there is AI/ML community group. There are also conferences like Fantastic Futures.\nTop universities, for example Harvard, Stanford and Helsinki, offer, sometimes free, online courses. Also sites like Coursera, FutureLearn, and Udemy are worth a look. Open-source tools like OpenCV and TensorFlow mentioned above, but also PyTorch are handy.\nOne can join Slack workspaces of AI4LAM or IIIF.",
    "crumbs": [
      "TOPIC GUIDES",
      "Computer Vision"
    ]
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "CONTACT",
    "section": "",
    "text": "CONTACT\nIf you’d like to ask a question of the project team you can please send an email to Nora McGregor, nora.mcgregor@bl.uk or any of Co-Chairs and select Members of the collaborating WGs listed here who act as the core project delivery team and editors of this resource.\nJodie Double, Editor DSDCH\nPéter Király, Editor DSLib\nNora McGregor, Editor DSDCH\nPeter Verhaar, Editor DSLib"
  },
  {
    "objectID": "digitalmapping.html",
    "href": "digitalmapping.html",
    "title": "Digital Mapping",
    "section": "",
    "text": "Cultural Heritage collections are full of object stories. Objects move through time and space and encounter multiple people and other objects. Additionally, as explained in the guide on data visualisation, humans are better able to see and interpret data based on visualising them with colours and shapes.\nWhen we combine these two concepts, it is therefore not surprising that one of the most common visualisations for cultural heritage collections, and library collections specifically, are maps.\nHowever, creating a map or adding objects on a map are not neutral processes: maps reproduce ways of seeing, giving specific interpretations of the world. For example, a map created according to a Mercator projection (created by Gerardus Mercator in 1569) will expand the lands above the Equator, therefore making Madagascar as big as Great Britain while it is actually twice the size. This projection reflects a view of the world that is western-centric. Despite criticism, this projection is actually the base of Web Mercator.\nWeb Mercator is a de facto standard for Web Mapping and it is used by Google Maps, Bing Maps and OpenStreetMap, therefore continuing the reinforcement of the same way of seeing the world while hiding the fact that it is a way of seeing the world.\nRecognising that every map is not neutral and it is instead a cultural artefact is particularly important when approaching the digital mapping of collections as the maps may enhance their partiality.\nAt the same time, using maps as a visualisation tool has the potential both to make libraries aware of new and unheard stories within their collections, to connect collections from multiple institutions (see for example Heritage for All) and to identify gaps that may be worth exploring.\nBecause of their ubiquity, they have the potential to be easy to explore for different audiences, keeping in mind that accessibility and usability, as much as with other visualisations and interfaces, need to be kept at the centre of their development.\nKnowing who will use the maps and for what purpose is therefore essential as much as being aware of the interpretation that the map is proposing and how this interpretation is influenced by the adoption of a specific technology and how the process of mapping happened.\nFor example, visualising indigenous knowledge in a Web Mercator-based application may be problematic as the approach to place and its visualisation may be different than the one presented on some platforms and may require a discussion with communities on how to best represent their interpretation of place and their culture.\nTo digitally map collections, there are a few options available in terms of tools and softwares:\n\nFirst of all, there are specialistic software available such as QGIS and ArcGIS where geolocated data (that is data that have coordinates) can be visualised on maps chosen by the librarian/researcher and historical maps can be associated with coordinates.\nIt is possible to visualise geolocated data on online platforms designed for digital mapping that are not specifically for the Humanities, such as Google Maps.\nThere are online tools designed to visualise humanities data in multiple ways and have an option of visualising data on a map such as Recogito, where annotated places on a text can be visualised, or Palladio that is used to visualise data as networks.\nThere are generic visualisation tools such as Tableau, that has been explored in the data visualisation guide.\nFinally, it is worth mentioning the work the IIIF community in standardising the georeferencing of maps in IIIF and creating geospatial annotations.",
    "crumbs": [
      "TOPIC GUIDES",
      "Digital Mapping"
    ]
  },
  {
    "objectID": "digitalmapping.html#introduction",
    "href": "digitalmapping.html#introduction",
    "title": "Digital Mapping",
    "section": "",
    "text": "Cultural Heritage collections are full of object stories. Objects move through time and space and encounter multiple people and other objects. Additionally, as explained in the guide on data visualisation, humans are better able to see and interpret data based on visualising them with colours and shapes.\nWhen we combine these two concepts, it is therefore not surprising that one of the most common visualisations for cultural heritage collections, and library collections specifically, are maps.\nHowever, creating a map or adding objects on a map are not neutral processes: maps reproduce ways of seeing, giving specific interpretations of the world. For example, a map created according to a Mercator projection (created by Gerardus Mercator in 1569) will expand the lands above the Equator, therefore making Madagascar as big as Great Britain while it is actually twice the size. This projection reflects a view of the world that is western-centric. Despite criticism, this projection is actually the base of Web Mercator.\nWeb Mercator is a de facto standard for Web Mapping and it is used by Google Maps, Bing Maps and OpenStreetMap, therefore continuing the reinforcement of the same way of seeing the world while hiding the fact that it is a way of seeing the world.\nRecognising that every map is not neutral and it is instead a cultural artefact is particularly important when approaching the digital mapping of collections as the maps may enhance their partiality.\nAt the same time, using maps as a visualisation tool has the potential both to make libraries aware of new and unheard stories within their collections, to connect collections from multiple institutions (see for example Heritage for All) and to identify gaps that may be worth exploring.\nBecause of their ubiquity, they have the potential to be easy to explore for different audiences, keeping in mind that accessibility and usability, as much as with other visualisations and interfaces, need to be kept at the centre of their development.\nKnowing who will use the maps and for what purpose is therefore essential as much as being aware of the interpretation that the map is proposing and how this interpretation is influenced by the adoption of a specific technology and how the process of mapping happened.\nFor example, visualising indigenous knowledge in a Web Mercator-based application may be problematic as the approach to place and its visualisation may be different than the one presented on some platforms and may require a discussion with communities on how to best represent their interpretation of place and their culture.\nTo digitally map collections, there are a few options available in terms of tools and softwares:\n\nFirst of all, there are specialistic software available such as QGIS and ArcGIS where geolocated data (that is data that have coordinates) can be visualised on maps chosen by the librarian/researcher and historical maps can be associated with coordinates.\nIt is possible to visualise geolocated data on online platforms designed for digital mapping that are not specifically for the Humanities, such as Google Maps.\nThere are online tools designed to visualise humanities data in multiple ways and have an option of visualising data on a map such as Recogito, where annotated places on a text can be visualised, or Palladio that is used to visualise data as networks.\nThere are generic visualisation tools such as Tableau, that has been explored in the data visualisation guide.\nFinally, it is worth mentioning the work the IIIF community in standardising the georeferencing of maps in IIIF and creating geospatial annotations.",
    "crumbs": [
      "TOPIC GUIDES",
      "Digital Mapping"
    ]
  },
  {
    "objectID": "digitalmapping.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "href": "digitalmapping.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "title": "Digital Mapping",
    "section": "Relevance to the Library Sector (Case Studies/Use Cases)",
    "text": "Relevance to the Library Sector (Case Studies/Use Cases)\nHaving introduced the importance of maps to visualise people, objects and relationships in cultural heritage, it is not surprising that digital mapping provides multiple potential applications and challenges for libraries. Maps can be used, as I said before, to communicate an interpretation with audiences, to let them explore collections or to analyse their collections as data, to see gaps and uncover stories.\nFor example, the project Mapping the Republic of Letters by Stanford University has used maps to visualise and let users explore the places where editions of Voltaire were published between 1712 and 1800 or to visualise the places tourists explored during the Grand Tour.\nIf the previous example illustrates how geolocated data can help study editions and letters and see the bigger picture, maps can also be used to let users explore collections, as mentioned before with Heritage for All. An example is WarSampo that lets users explore the relevant places, events, people and photographs linked to Finland during World War II using LOD, or the Holocaust refugee map developed by The Weiner Holocaust Library that includes not only documents and photographs but also recorded interviews.\nFinally, digital mapping can be used for digital storytelling, narrating stories related to places such as with Curiocity by the National Library of Singapore. The library has curated, along with the National Archives, stories related to places in Singapore, mixing maps and photographs to explore their past and present cultural significance.",
    "crumbs": [
      "TOPIC GUIDES",
      "Digital Mapping"
    ]
  },
  {
    "objectID": "digitalmapping.html#hands-on-activity-and-other-self-guided-tutorials",
    "href": "digitalmapping.html#hands-on-activity-and-other-self-guided-tutorials",
    "title": "Digital Mapping",
    "section": "Hands-on activity and other self-guided tutorial(s)",
    "text": "Hands-on activity and other self-guided tutorial(s)\nHere are some helpful tools that can used to begin digital mapping. They are divided by typology: web-based, software, and coding-based. Some are designed specifically for humanities and cultural heritage collections data while others are designed for more generic geospatial data. Most have great documentation and tutorials available.\n\nWeb-based tools\n\nPalladio is useful for testing multiple visualisations with Humanities data. It offers the option to upload .csv files, structure them and visualise them in maps, timelines and networks. There are a few tutorials for beginners available here.\nRecogito is a platform for annotating text. It is also possible to apply Name Entity Recognition, disambiguate places and visualise them on the map feature provided (see this 10 minutes tutorial).\nGoogle Maps allows saving and sharing places and trails. It is also possible to create, customise and share maps through My Maps. To understand how it works and how it differs from Google Earth Pro, there is a tutorial on Programming Historian.\nAllMaps is designed to visualise and georeference maps in IIIF.\n\n\n\nSoftwares\n\nArcGIS is based on the concept of Geographic Information System (GIS) and it provides enhanced capabilities compared to the previous web-based options, including spatial data analysis. For a brief introduction to GIS and its basic components, this guide is particularly handy along with this course by the MIT. ArcGIS requires a subscription to be used and it offers an online option as well. There are a few beginner tutorials in the documentation provided by Esri.\nQGIS is an open-source and free software that offers some of the capabilities of ArcGIS. There are beginner tutorials on Programming Historian on installing it and creating layers and a comprehensive documentation on the official website.\nGoogle Earth Pro is a free software based on Google Earth but offers enhanced capabilities for handling geospatial data and performing some basic data analysis (for the difference with Google Maps see here)\n\n\n\nCoding\nThere are multiple libraries for digital mapping, depending on the programming language used.\n\nFor Python, geopandas, basemap and matplotlib are good for static maps, while Folium, Plotly, Dash (for dashboards) and ipyleaflet are used to create interactive maps in Python and in Jupyter Notebooks.\nFor R, for static maps there is ggplot while, for interactive maps, leaflet is a good option.\nFinally, it is worth mentioning the D3 Javascript Library that is specifically designed for data visualisation and includes a lot of coded examples of maps.",
    "crumbs": [
      "TOPIC GUIDES",
      "Digital Mapping"
    ]
  },
  {
    "objectID": "digitalmapping.html#recommended-readingviewing",
    "href": "digitalmapping.html#recommended-readingviewing",
    "title": "Digital Mapping",
    "section": "Recommended Reading/Viewing",
    "text": "Recommended Reading/Viewing\nThere are a few additional readings that may be interesting to get more information or to explore additional options for digital mapping.\n\nOther library guides on digital mapping and GIS\n\nNYU Libraries. (n.d.). Mapping and timelines. Retrieved January 21, 2025, from https://guides.nyu.edu/digital-humanities/tools-and-software/mapping-and-timelines\nUC Berkeley Library. (n.d.). Digital mapping. Retrieved January 21, 2025, from https://guides.lib.berkeley.edu/dh/mapping#s-lg-box-33113349\nUBC Library. (n.d.). Getting started with GIS. Retrieved January 21, 2025, from https://guides.library.ubc.ca/gis/gettingstarted\nUniversity of Reading Library. (n.d.). Digital maps. Retrieved January 21, 2025, from https://libguides.reading.ac.uk/maps/digitalmaps\n\n\n\nAdditional tutorials\n\nQGIS and ArcGIS\n\nClifford, J., MacFadyen, J., & Macfarlane, D. (2013). Georeferencing in QGIS 2.0. Programming Historian, 2. https://doi.org/10.46430/phen0027\nColson, J. (2017). Geocoding historical data using QGIS. Programming Historian, 6. https://doi.org/10.46430/phen0066\nGeospatial Historian. (n.d.) Lessons. Retrieved January 22 2025.Lessons – Geospatial Historian\n\n\n\nProgramming in Python and R\n\nPham, K. (2017). Web mapping with Python and Leaflet. Programming Historian, 6. https://doi.org/10.46430/phen0070\nRyan, Y. (2022). Making an interactive web application with R and Shiny. Programming Historian, 11. https://doi.org/10.46430/phen0105",
    "crumbs": [
      "TOPIC GUIDES",
      "Digital Mapping"
    ]
  },
  {
    "objectID": "digitalmapping.html#finding-communities-of-practice",
    "href": "digitalmapping.html#finding-communities-of-practice",
    "title": "Digital Mapping",
    "section": "Finding Communities of Practice",
    "text": "Finding Communities of Practice\nIf you are interested in knowing more about digital mapping, there are a few communities of practice, conferences and summer schools that you may be interested to attend.\n\nThe Spatial Humanities Conference is held annually and it is specialised in geospatial technologies, geodata and the Humanities.\nThe GeoHumanities community is a special interest group part of the ADHO (Alliance of Digital Humanities Organisations).\nIIIF has an active community working on creating standards for mapping.\nThe Digital Humanities Oxford Summer School offers multiple DH courses, both theoretical and practical. Humanities Data is a good introduction to Humanities data processing and it usually includes some coursework on GIS. If there is an interest in data visualisation and programming at a more advanced level, there is a course specialised on Applied Data Analysis that explores, among others, geomapping.\nThe Cultural Heritage Data School by the University of Cambridge is dedicated to exploring cultural heritage data using digital methods and approaches. The programme changes every year and may include lectures on digital mapping.",
    "crumbs": [
      "TOPIC GUIDES",
      "Digital Mapping"
    ]
  },
  {
    "objectID": "programming.html",
    "href": "programming.html",
    "title": "Programming for Librarians: Where to begin",
    "section": "",
    "text": "Many of the tasks taking place within libraries encompass activities which can be automated. Librarians may need to do bulk downloads of resources from the web, adjust the values in a database or manipulate images. Instead of doing such tasks manually, it is evidently more efficient to develop computer code which can perform such clerical tasks repeatedly. It can be very helpful for librarians, because of this, to become proficient in a programming language. Examples of programming languages include Python, R, Java, Perl or PHP.\nProgramming can be described as the process of using computers to address specific problems. Computer programs essentially consist of a sequence of statements which explain how an activity can be automated. Programming languages generally implement a certain algorithm. An algorithm is an explicit and unambiguous description of the steps that need to be followed to arrive at a well-defined end result. The algorithm constitutes the logic of the program. The statements or commands in a programming language also need to be expressed in a format that computers can understand. They need to be expressed using a syntax, which prescribes how words, numbers of punctuation marks ought to be used\nThere are a number of different languages in which you can write computer code. While it is difficult to find reliable data about this, it feels safe to claim that Python and R are currently the most widely used languages in the library sector. When you start learning how to program, it is probably best to focus on one language initially and to develop skills in one specific programming language. It must be stressed, however, that when you develop your expertise in one concrete language, this will inevitably help you to improve your computational thinking and to broaden your understanding of how programming languages function in general. Once you have learned about the nuts and bolts of one language, it becomes much easier to gain mastery over another language.\n\n\nPython, firstly, is a free and open source, general purpose language. It is widely used to carry out data science tasks, such as cleaning, enriching, analysing and visualising data. Python makes use of a sparsee, readable and intuitive syntax, and this makes the language relatively easy to learn for beginners. Within the Python community, numerous code libraries have been shared which extend the basic functionalities of the language.\nR, is another free and open source programming language that was created originally with a specific focus: to support statistical analyses. Later it was developed towards a more general direction with the help of thousands of software packages created by the R community and today it is used to solve as many types of problems as Python or Java. R’s syntax and its most important data structures are quite different from that of Python, and it requires a different way of thinking.\nBecause of this strong data analysis background we suggest you choose R if you would like to run core data analysis tasks that require a more advanced statistical toolbox, and does not require many additional steps before and after the calculations. Python on the other hand provides somewhat less statistical functionalities, but supports much more general purpose tasks out of the box like file management, string, date and time manipulation, computer networks etc. None of these tasks are impossible with the other programming languages, but their conveniences are different. In data science related tasks they are quite close, e.g. Python’s Pandas library and R’s data frames (particularly in the Tidyverse package) have similar functionalities. Another - subjective - factor of the decision could be the aesthetics of the graphics Python and R produces: both of them have more than one plotting libraries, each are easy to recognise by their distinctive graphical style.",
    "crumbs": [
      "TOPIC GUIDES",
      "Programming for Librarians: Where to begin"
    ]
  },
  {
    "objectID": "programming.html#introduction",
    "href": "programming.html#introduction",
    "title": "Programming for Librarians: Where to begin",
    "section": "",
    "text": "Many of the tasks taking place within libraries encompass activities which can be automated. Librarians may need to do bulk downloads of resources from the web, adjust the values in a database or manipulate images. Instead of doing such tasks manually, it is evidently more efficient to develop computer code which can perform such clerical tasks repeatedly. It can be very helpful for librarians, because of this, to become proficient in a programming language. Examples of programming languages include Python, R, Java, Perl or PHP.\nProgramming can be described as the process of using computers to address specific problems. Computer programs essentially consist of a sequence of statements which explain how an activity can be automated. Programming languages generally implement a certain algorithm. An algorithm is an explicit and unambiguous description of the steps that need to be followed to arrive at a well-defined end result. The algorithm constitutes the logic of the program. The statements or commands in a programming language also need to be expressed in a format that computers can understand. They need to be expressed using a syntax, which prescribes how words, numbers of punctuation marks ought to be used\nThere are a number of different languages in which you can write computer code. While it is difficult to find reliable data about this, it feels safe to claim that Python and R are currently the most widely used languages in the library sector. When you start learning how to program, it is probably best to focus on one language initially and to develop skills in one specific programming language. It must be stressed, however, that when you develop your expertise in one concrete language, this will inevitably help you to improve your computational thinking and to broaden your understanding of how programming languages function in general. Once you have learned about the nuts and bolts of one language, it becomes much easier to gain mastery over another language.\n\n\nPython, firstly, is a free and open source, general purpose language. It is widely used to carry out data science tasks, such as cleaning, enriching, analysing and visualising data. Python makes use of a sparsee, readable and intuitive syntax, and this makes the language relatively easy to learn for beginners. Within the Python community, numerous code libraries have been shared which extend the basic functionalities of the language.\nR, is another free and open source programming language that was created originally with a specific focus: to support statistical analyses. Later it was developed towards a more general direction with the help of thousands of software packages created by the R community and today it is used to solve as many types of problems as Python or Java. R’s syntax and its most important data structures are quite different from that of Python, and it requires a different way of thinking.\nBecause of this strong data analysis background we suggest you choose R if you would like to run core data analysis tasks that require a more advanced statistical toolbox, and does not require many additional steps before and after the calculations. Python on the other hand provides somewhat less statistical functionalities, but supports much more general purpose tasks out of the box like file management, string, date and time manipulation, computer networks etc. None of these tasks are impossible with the other programming languages, but their conveniences are different. In data science related tasks they are quite close, e.g. Python’s Pandas library and R’s data frames (particularly in the Tidyverse package) have similar functionalities. Another - subjective - factor of the decision could be the aesthetics of the graphics Python and R produces: both of them have more than one plotting libraries, each are easy to recognise by their distinctive graphical style.",
    "crumbs": [
      "TOPIC GUIDES",
      "Programming for Librarians: Where to begin"
    ]
  },
  {
    "objectID": "programming.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "href": "programming.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "title": "Programming for Librarians: Where to begin",
    "section": "Relevance to the Library Sector (Case Studies/Use Cases)",
    "text": "Relevance to the Library Sector (Case Studies/Use Cases)\nProgramming languages can be used for a variety of library tasks.\n\nA common application is to convert one data format into another data format. A computer system may export descriptions in the MARCXML format, while another application may demand JSON input. Such transformations can be carried out using a computer program.\nIt is also possible to download large numbers of files using computer code.\nProgramming languages can also be used to analyse and to visualise data in a spreadsheet or in a CSV format. As such, they may help others to interpret the data or to see patterns or regularities in large datasets.\nApplications based on AI and Machine Learning are typically created using a programming language.\n\nThe British Library, The National Archives and Birkbeck University in the UK partnered on a trial of a one-year part-time postgraduate Certificate (PGCert), Computing for Cultural Heritage, as part of a £4.8 million University skills drive in 2019-2021. The 20 staff projects devised and undertaken by the students demonstrate the wide range of what programming skills can enable for those working in a library setting.\nThe code4lib journal publishes many articles with case studies on applications in library contexts.",
    "crumbs": [
      "TOPIC GUIDES",
      "Programming for Librarians: Where to begin"
    ]
  },
  {
    "objectID": "programming.html#hands-on-activity-and-other-self-guided-tutorials",
    "href": "programming.html#hands-on-activity-and-other-self-guided-tutorials",
    "title": "Programming for Librarians: Where to begin",
    "section": "Hands-on activity and other self-guided tutorial(s)",
    "text": "Hands-on activity and other self-guided tutorial(s)\nTo develop a basic understanding of the main features of Python, you can follow the Introductory course on Python that was developed at the University of Leiden.\nIt is a self-paced course which you can follow to familiarise yourself with central concepts such as variables, operators, flow control, data structures and functions. The tutorial also explains some of the code libraries which can be used more specifically for data science tasks such as data acquisition, working with APIs, data analysis and data visualisation. The tutorial includes a large number of exercises with which you hone your programming skills, together with model answers which can help you if you get stuck.\nOnce you gained a basic proficiency of the central Python concepts, you can follow the tutorial “Python for Librarians”, which was developed by the Library Carpentry.\nTo get started with R we recommend the Library Carpenty’s tutorial “Introduction to R” which teaches you how to do basic data science tasks on tabular data, such as spreadsheets or relational database tables.\nThere are a number of useful resources to improve your programming skills specifically with library related materials.\n\nTim Sherratt: GLAM Workbench (2021-). As its introduction says: “The GLAM Workbench is a collection of Jupyter notebooks to help you explore and use data from GLAM institutions (that’s galleries, libraries, archives, and museums). It includes tools, tutorials, examples, hacks, and even some pre-harvested datasets.” Sherratt focuses on Australian and New Zealand datasets, but you can reuse the code for other sources. The notebooks are written in Python. Jupyter Notebook, a web-based interactive computing platform that combines live code, equations, narrative text, visualisations, interactive dashboards and other media. You can find many tutorials and GLAM related scripts in this form.\nProgramming Historian is a set of programming tutorials (both in Python and R) focusing on particular computational problems (such as network analysis, data managements, APIs, machine learning) made mainly for historians, but several tutorials use GLAM data.",
    "crumbs": [
      "TOPIC GUIDES",
      "Programming for Librarians: Where to begin"
    ]
  },
  {
    "objectID": "programming.html#recommended-readingviewing",
    "href": "programming.html#recommended-readingviewing",
    "title": "Programming for Librarians: Where to begin",
    "section": "Recommended Reading/Viewing",
    "text": "Recommended Reading/Viewing\nPaul Vierthaler’s Hacking the Humanities Tutorials video series is quite useful for beginners.\nWe can highly recommend this recent book Hands-On Data Science for Librarians written by Sarah Lin and Dorris Scot (Boca Raton : CRC Press, 2023, ISBN 978-1-032-10999-2).\nThough not written specifically for librarians, but probably the best introduction to the topic of data science with R is R for Data Science. 2nd edition by Hadley Wickham, Mine Çetinkaya-Rundel and Garrett Grolemund (O’Reilly, 2023, ISBN 978–1-492-09740-2), and available online.",
    "crumbs": [
      "TOPIC GUIDES",
      "Programming for Librarians: Where to begin"
    ]
  },
  {
    "objectID": "programming.html#finding-communities-of-practice",
    "href": "programming.html#finding-communities-of-practice",
    "title": "Programming for Librarians: Where to begin",
    "section": "Finding Communities of Practice",
    "text": "Finding Communities of Practice\nWhen you’re first getting started in programming, being able to ask others questions when you get stuck is so important! Code4lib is a volunteer-driven collective of folks that has been around since 2003 and amongst their many resources are a large range of chat rooms for folks interested in the convergence of technology and cultural heritage. Visit Chat | Code4Lib to find the discussion you need or join their mailing list.\nYou might also want to have a look on Github, which is one of the largest source code repositories on the web, for the “code4lib” tag to denote repositories that are somewhat relevant for the library community. They are not tutorials, but during your learning process you can check if there is a software solution there already for your particular problem, and you can even try to engage with one or more tools as a contributor. Contributions are always welcome on #code4lib projects, and even if you have just begun programming you can provide important feedback about the usage of a tool, or you can improve documentation as a first step. See our page on using GitHub for more on that!",
    "crumbs": [
      "TOPIC GUIDES",
      "Programming for Librarians: Where to begin"
    ]
  },
  {
    "objectID": "updates.html",
    "href": "updates.html",
    "title": "Ongoing Maintenance and Content Review",
    "section": "",
    "text": "Ongoing Maintenance and Content Review\nThroughout 2023/2024 we are working on producing the first complete edition of this resource for launch at the LIBER Annual Conference 3-5 July 2024. That edition will be deposited in the British Library Research Repository, captured in the UK Web Archive, and a DOI provided. Topic Guides are currently being produced by direct invitation, as well as through a series of in-person and online writing sprints of working group members.\nThe first edition Topic Guide list draws heavily on the existing skills framework and topics covered in the British Library’s Digital Scholarship Training Programme, as well as those recommended by attendees of development workshops hosted by LIBER working groups throughout 2023.\nWe view this resource as capturing a snapshot in time and will endeavour to fully review all content a minimum of once annually to check for link rot, and content relevancy. The project team editors are committed to make quick fixes when raised throughout the year, while formal sprints and reviews coinciding with LIBER Annual Summer Conference and Winter events will be used for soliciting new content and undertaking more complex updates to the resource each year."
  },
  {
    "objectID": "project-overview.html",
    "href": "project-overview.html",
    "title": "ABOUT",
    "section": "",
    "text": "Digital Scholarship & Data Science Essentials for Library Professionals is a project first undertaken in 2023 as a joint collaboration between the Digital Scholarship & Digital Cultural Heritage (DSDCH) and the Data Science in Libraries (DSLib). It is an open and collaboratively curated training reference resource that aims to:"
  },
  {
    "objectID": "project-overview.html#project-history",
    "href": "project-overview.html#project-history",
    "title": "ABOUT",
    "section": "Project History",
    "text": "Project History\nThe impetus for this project has its roots in LIBER member British Library’s Digital Scholarship Training Programme, where for over a decade now, Digital Curators there have maintained bespoke learning resources on digital scholarship tools and methods for internal use as part of their staff training courses, talks reading group and Hack & Yacks. The team there has been looking for places to share these existing resources and expertise more widely with the sector in a dedicated collaborative learning space online.\nMeanwhile, both LIBER working groups noted that while the exponential expansion of digital collections, and the computational methods and tools to interact with them presented an opportunity for LIBER library professionals working within national, research, university to cultural heritage institutions, to not only support digital scholars on increasingly more complex computationally driven research, but also to apply such methods in the care and curation of heritage collections, capacity building in digital scholarship methods, including data science, was unevenly distributed across this community however.\nThough training for the sector around the use of data science and computational methods in the library context has grown considerably within the last decade, fifty-eight percent of LIBER Member respondents still noted as recently as 2019 ‘technical knowledge - such as coding or tool expertise’ as the primary deficit in their environments in Europe’s Digital Humanities Landscape: A Study From LIBER’s Digital Humanities & Digital Cultural Heritage Working Group.\nThe provision of these valuable resources remains fragmented online and across institutions at a local, national and international level. This leads to considerable inefficiency and inconsistent skills acquisition across LIBER member institutions and sustains an imbalance between the wide-spread ambitions of scholars to undertake computational research with library and heritage collections, and a paucity of institutions with capacity to enable these. Equally, it impedes research libraries and cultural institutions from benefiting from the digital transformations computational methods can offer."
  },
  {
    "objectID": "project-overview.html#core-project-team",
    "href": "project-overview.html#core-project-team",
    "title": "ABOUT",
    "section": "Core Project Team",
    "text": "Core Project Team\nThe site and content are maintained by the Co-Chairs and select Members of the collaborating WGs listed here who act as the core project delivery team and editors of this resource.\nJodie Double, Editor DSDCH\nPéter Király, Editor DSLib\nNora McGregor, Editor & Site Maintainer DSDCH\nPeter Verhaar, Editor DSLib"
  },
  {
    "objectID": "project-overview.html#community-contributors",
    "href": "project-overview.html#community-contributors",
    "title": "ABOUT",
    "section": "Community Contributors",
    "text": "Community Contributors\nEach Topic Guide is written by specific named contributors but we also welcome changes and contributions to this resource via logging issues or if you’re a more seasoned GitHub user, via pull requests to the github repository."
  },
  {
    "objectID": "project-overview.html#acknowledgements",
    "href": "project-overview.html#acknowledgements",
    "title": "ABOUT",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThe project team would like to thank all of our LIBER working group members who have contributed to this resource and supported our endeavours here. We have taken great inspiration from other incredible training initiatives such as the British Library Digital Scholarship Training Programme, DH Literacy Guidebook and The Programming Historian in the development of this resource and thank those projects for paving the way!"
  },
  {
    "objectID": "copyright.html",
    "href": "copyright.html",
    "title": "Copyright & Licensing: Current context and considerations for researchers and libraries using AI in research today",
    "section": "",
    "text": "This guide aims to provide library professionals at European research institutions, particularly those supporting or undertaking activities that combines AI tools and methods and digital cultural heritage collections and data, with a brief overview of the current copyright and licensing context for such research today. \nIf it’s been awhile since you’ve had a look at copyright rules closely, let’s take a minute to cover the basics so we have a good foundation for understanding the more complex considerations of copyright in an AI context today.\nEqually, if you feel well versed in the basics already and are keen to dive straight into the AI context, feel free to hop on down to the Relevance to the Library section.\n\n\n“Copyright is a legal term used to describe the rights that creators have over their literary and artistic works. Works covered by copyright range from books, music, paintings, sculpture, and films, to computer programs, databases, advertisements, maps, and technical drawings.” WIPO\nCopyright is a form of intellectual property intended to protect original works as they are created and recorded. As soon as an original work is created, it is protected by copyright and there is no need to formally register it. In some countries registration may increase authors’ rights for compensation in case of infringement.\nThe purpose of copyright is to protect and reward creators for the works they have produced. Copyright consists of economic rights - the right of reproduction and the right to make a work available to the public- and moral rights - the right to be identified as the author and the right to prevent mistreatment.\nTo qualify for protection the work must be original in the sense that it is an author’s own intellectual creation, i.e. it reflects the author’s personality, the author was able to express their creative abilities in the production of the work by making free and creative choices.\n\n\nCopyright protects the artistic or literary form, but not the subject matter. The work that is created is protected, but not to the ideas or theories/ concepts represented. The ideas vs expression debate is a central part of the copyright discourse when looking to build on or reuse the work or ideas of another. If you are using the work itself this is likely to involve copyright issues, but if you are looking to use the ideas rather than the work this may not involve copyright issues at all.\n\n\n\nCopyright is finite and lasts for a set duration based on the type of work and where it was created.\nIn Europe and USA this period is 70 years after the author dies. According to the international Berne Convention the minimum protection period is the life of the author plus 50 years after their death. Copies or reproductions of works where copyright expired do not get protection in EU or USA:\nWhen copyright expires it becomes Public Domain however given the differences in duration across borders a work may be Public Domain in one country yet still under copyright in another.\nFor example, Canada has a copyright duration of 50 years after death for literary works whereas in France it’s 70. In Canada the work would not require permission for certain uses but in France those same uses would still require a licence or an exception.\nAnother example is the UK. “Some works are protected in the UK until 31st December 2039, even where the author died perhaps hundreds of years ago. This is also known as the ‘2039’ rule and applies to literary, dramatic and musical works, but not artistic works other than photographs and engravings. Other rules apply for photographs, films and sound recordings.”\nWhen a work enters the Public Domain it is free to be used by anyone in any way without the permission of the owner. When copyright expires also the moral rights of the creator expire, so works can be altered and used without crediting the author. However, many countries have given public authorities, such as the Ministry of Education/ Culture the possibility to protect the ‘educational and cultural value’ of works that are in the public domain, Italy for example.\n\n\n\nOwnership is important as it determines who has control over how and when a work is used, as well as who can access and use it. Owners, also known as rights holders, have the right to control who can access the work, how they can use it, if they can make copies, how it is performed or communicated to the public. They can licence these permissions to use to a licensee or they can sell these rights completely to another party. Ownership is a requirement for licensing, for example for licensing with Creative Commons licences.\nCopyright is an intangible asset which is separate to possession of a physical work such as a painting or book and transferring physical possession does not include any transfer of copyright.\nUsing a work without permission from the copyright owner, usually in the form of a licence, is a copyright infringement, unless an exception applies.\nCopyright ownership is granted to the creator of the work in the EU automatically by copyright legislation. However, this can be changed by contract. In the UK for example, the law says the creator is the owner but if a work was created in the course of employment, the employer will own the copyright unless the employment contract says otherwise. The US has a work-for-hire clause in the copyright legislation so that copyright is born to the employer if not otherwise agreed. Even ownership is not quite straightforward and local knowledge is important.\n\n\n\nOwners of copyright works are able to apply any licensing conditions they wish to their work, however research funders may make it a condition of a grant that certain outputs arising from funded research must be released openly. Where this is the case, they will communicate their preferred licensing choice.\nThe most common licences used are Creative Commons licences. Creative Commons licences are intended to pre-approve certain uses meaning a user can make use of a work within the terms of those licence conditions. If a user wishes to make other uses they will need to contact the owner in the usual way and negotiate separate permissions. If a user breaches the Creative Commons terms they can be sued for infringement by the owner.\nCreative Commons licences do not impact on the ownership status of the work- they are simply licences. Only the copyright owner of a work has the authority to grant a Creative Commons licence.\nCreative Commons licences can be very open permitting any reuse provided the creator and the licence are cited, or they can be closer to a traditional ‘all rights reserved’ approach which might enable access to a work but any reuse is limited in nature. The licence terms are binding so any user must mention the name of the author and the work as shown in the licence, and if there are additional terms such as Non-Commercial or Share-Alike these have to be complied with.\nCreative Commons has a comprehensive website with guidance but it is highly likely that research institutions and libraries will have other additional guidance on this too.\n\n\n\n\nCopyright protected materials are central to research activity whether that is in the form of text, music, images or code. Data itself is not protected by copyright, but databases can be protected as catalogue or sui generis database, as noted above.\nResearchers will produce copyright protected works when writing articles, monographs or code. Researchers will need protection for the right to be recognised as authors and also as owners of copyright. Research ethics requires contributors to be recognised in a research output, even if they are not owners or authors in a copyright sense. Good scientific research requires contributor roles to be defined and mentioned in research outputs and CRediT – Contributor Role Taxonomy (niso.org) describes 14 roles that can be used when defining contributor roles. Contributor roles should be agreed before sending a manuscript to a publisher.\nResearchers will use works created by others- either as a fundamental part of their research methodology or during publication. Where exceptions like those for non-commercial research or non-commercial data mining do not apply, ensuring that licences are in place that allow for the uses within the research activity is essential. The use of research data and the management of data related rights should be considered and outlined within the data management plan which must also take into account how the research data are to be archived and used, as well as how the authors of the data are attributed in compliance with research ethics.\n\n\nIn order to use the copyright protected work, either permission from the owner, agreements covering the uses, or legislation allowing the use is needed.\nCopyright legislation tries to strike a balance between protecting the freedom of sciences, expression, and information, and the protection of the copyright owner. This means that while the owner of the rights can control it, there are exceptions to those rights which enable some uses without the need for the owner’s permission. These are known as exceptions, or user rights.\nCopyright exceptions include for example certain educational uses, the provision of inter library loans by libraries, text and data mining for non-commercial scientific research purposes and commercial purposes, creating accessible copies of works for those with disabilities\nCopyright laws vary by country and, while EU law is largely harmonised, there are differences between member states concerning the copyright exceptions. Understanding local national law exceptions for research and education is important.\n\n\n\nUsing archival materials can raise some unusual situations which mean the normal copyright rules don’t apply. Below are a couple of examples of unusual copyright scenarios:\nWorks of art on public display The rules around works of art on public display vary by country. In some EU countries the so-called ’Freedom of Panorama’ rules dictate what can and cannot be done with such works for commercial purposes. Italy for example controls commercial uses of works of cultural importance regardless of their copyright status.\nContractual issues\nWhile works in the public domain may be free from copyright access to them and their use may be controlled via contract law. Many museums and galleries apply terms and conditions to the use of digital surrogates which apply irrespective of the copyright status.\nDatabase Rights\nThe EU sui generis database protection and the Nordic catalogue protection intend to protect the investment in a database. A database usually does not have the original artistic or literary form that protection of a database as an original work would require but it does involve creative choices in the structure layout and data fields being collected. While the data items themselves may not have copyright the overall database will be protected by the database right. Ownership of database rights may vary by law or contract. For example in the Nordic version these rights are given to the university as employer, not to the researcher as the employee.\nUnpublished works\nThere are specific rules surrounding the copyright of works that have never been ‘communicated to the public’ or they have never been publicly accessible.\nOrphan works\nWhere the owner of the rights in a copyright work is known but cannot be traced they are classed as orphan work. Within the EU the Orphan works Licensing Scheme is a EU wide licensing mechanism that gives assurance to users of these works subject to the payment of a fee.\nOut of commerce works\nWhere a work is no longer commercially exploited by the owner, or publisher for example, there are EU rules around how a user might use these items.\nEthical authorship\nCopyright authorship and who are authors in a scientific publication differ. When listing authors and those persons who have contributed to the research and to the publication should be mentioned, contributor roles should be defined, and a tool for this is the CRediT – Contributor Role Taxonomy (niso.org).\n\n\n\n\nLicensing agreements are a central type of legal contract concerning copyright works. Use of published content within institutions will be covered by licences. Access to ebooks, e-journals, databases etc are all covered by licences. It is important to know and understand the terms under which access to content is provided so that users can use the content without risk of breaching the licence terms.\nMany of the permitted uses within licences closely mirror the copyright exceptions mentioned above, however they provide a clarity and certainty that the exceptions may not.\nIn general, licences give institutions, their staff and students, permission to use the licensed content for specific purposes. These purposes are usually limited to education and non-commercial research activities, i.e. the students, researchers and educators can use the content for their purposes but HR or financial teams that are not directly engaged in research or teaching delivery cannot.\nThe terms of the licences will vary but they frequently allow for saving or printing of parts of the licensed works. Some licences will allow users to include extracts within teaching materials or even within publications. How much can be used will also vary.\nIt is important that these purposes and licence terms are clearly understood and that the use they expect to make of the content is expressly permitted within the licence terms. For example if an institution has an active research interest in data mining, licences that seek to prevent or restrict this activity will be problematic. Where licence terms are unclear this should be raised with the provider. Where they conflict with the legal exceptions in law this should also be queried.\nInstitutions may also rely on licences provided by collective licensing societies- official bodies that represent a group of authors, publishers or rights holders. The licences may cover things like photocopying and scanning of printed works, showing broadcast television programmes or playing recorded music. Again understanding the terms, the uses and obligations is important.",
    "crumbs": [
      "TOPIC GUIDES",
      "Copyright & Licensing: Current context and considerations for researchers and libraries using AI in research today"
    ]
  },
  {
    "objectID": "copyright.html#introduction",
    "href": "copyright.html#introduction",
    "title": "Copyright & Licensing: Current context and considerations for researchers and libraries using AI in research today",
    "section": "",
    "text": "This guide aims to provide library professionals at European research institutions, particularly those supporting or undertaking activities that combines AI tools and methods and digital cultural heritage collections and data, with a brief overview of the current copyright and licensing context for such research today. \nIf it’s been awhile since you’ve had a look at copyright rules closely, let’s take a minute to cover the basics so we have a good foundation for understanding the more complex considerations of copyright in an AI context today.\nEqually, if you feel well versed in the basics already and are keen to dive straight into the AI context, feel free to hop on down to the Relevance to the Library section.\n\n\n“Copyright is a legal term used to describe the rights that creators have over their literary and artistic works. Works covered by copyright range from books, music, paintings, sculpture, and films, to computer programs, databases, advertisements, maps, and technical drawings.” WIPO\nCopyright is a form of intellectual property intended to protect original works as they are created and recorded. As soon as an original work is created, it is protected by copyright and there is no need to formally register it. In some countries registration may increase authors’ rights for compensation in case of infringement.\nThe purpose of copyright is to protect and reward creators for the works they have produced. Copyright consists of economic rights - the right of reproduction and the right to make a work available to the public- and moral rights - the right to be identified as the author and the right to prevent mistreatment.\nTo qualify for protection the work must be original in the sense that it is an author’s own intellectual creation, i.e. it reflects the author’s personality, the author was able to express their creative abilities in the production of the work by making free and creative choices.\n\n\nCopyright protects the artistic or literary form, but not the subject matter. The work that is created is protected, but not to the ideas or theories/ concepts represented. The ideas vs expression debate is a central part of the copyright discourse when looking to build on or reuse the work or ideas of another. If you are using the work itself this is likely to involve copyright issues, but if you are looking to use the ideas rather than the work this may not involve copyright issues at all.\n\n\n\nCopyright is finite and lasts for a set duration based on the type of work and where it was created.\nIn Europe and USA this period is 70 years after the author dies. According to the international Berne Convention the minimum protection period is the life of the author plus 50 years after their death. Copies or reproductions of works where copyright expired do not get protection in EU or USA:\nWhen copyright expires it becomes Public Domain however given the differences in duration across borders a work may be Public Domain in one country yet still under copyright in another.\nFor example, Canada has a copyright duration of 50 years after death for literary works whereas in France it’s 70. In Canada the work would not require permission for certain uses but in France those same uses would still require a licence or an exception.\nAnother example is the UK. “Some works are protected in the UK until 31st December 2039, even where the author died perhaps hundreds of years ago. This is also known as the ‘2039’ rule and applies to literary, dramatic and musical works, but not artistic works other than photographs and engravings. Other rules apply for photographs, films and sound recordings.”\nWhen a work enters the Public Domain it is free to be used by anyone in any way without the permission of the owner. When copyright expires also the moral rights of the creator expire, so works can be altered and used without crediting the author. However, many countries have given public authorities, such as the Ministry of Education/ Culture the possibility to protect the ‘educational and cultural value’ of works that are in the public domain, Italy for example.\n\n\n\nOwnership is important as it determines who has control over how and when a work is used, as well as who can access and use it. Owners, also known as rights holders, have the right to control who can access the work, how they can use it, if they can make copies, how it is performed or communicated to the public. They can licence these permissions to use to a licensee or they can sell these rights completely to another party. Ownership is a requirement for licensing, for example for licensing with Creative Commons licences.\nCopyright is an intangible asset which is separate to possession of a physical work such as a painting or book and transferring physical possession does not include any transfer of copyright.\nUsing a work without permission from the copyright owner, usually in the form of a licence, is a copyright infringement, unless an exception applies.\nCopyright ownership is granted to the creator of the work in the EU automatically by copyright legislation. However, this can be changed by contract. In the UK for example, the law says the creator is the owner but if a work was created in the course of employment, the employer will own the copyright unless the employment contract says otherwise. The US has a work-for-hire clause in the copyright legislation so that copyright is born to the employer if not otherwise agreed. Even ownership is not quite straightforward and local knowledge is important.\n\n\n\nOwners of copyright works are able to apply any licensing conditions they wish to their work, however research funders may make it a condition of a grant that certain outputs arising from funded research must be released openly. Where this is the case, they will communicate their preferred licensing choice.\nThe most common licences used are Creative Commons licences. Creative Commons licences are intended to pre-approve certain uses meaning a user can make use of a work within the terms of those licence conditions. If a user wishes to make other uses they will need to contact the owner in the usual way and negotiate separate permissions. If a user breaches the Creative Commons terms they can be sued for infringement by the owner.\nCreative Commons licences do not impact on the ownership status of the work- they are simply licences. Only the copyright owner of a work has the authority to grant a Creative Commons licence.\nCreative Commons licences can be very open permitting any reuse provided the creator and the licence are cited, or they can be closer to a traditional ‘all rights reserved’ approach which might enable access to a work but any reuse is limited in nature. The licence terms are binding so any user must mention the name of the author and the work as shown in the licence, and if there are additional terms such as Non-Commercial or Share-Alike these have to be complied with.\nCreative Commons has a comprehensive website with guidance but it is highly likely that research institutions and libraries will have other additional guidance on this too.\n\n\n\n\nCopyright protected materials are central to research activity whether that is in the form of text, music, images or code. Data itself is not protected by copyright, but databases can be protected as catalogue or sui generis database, as noted above.\nResearchers will produce copyright protected works when writing articles, monographs or code. Researchers will need protection for the right to be recognised as authors and also as owners of copyright. Research ethics requires contributors to be recognised in a research output, even if they are not owners or authors in a copyright sense. Good scientific research requires contributor roles to be defined and mentioned in research outputs and CRediT – Contributor Role Taxonomy (niso.org) describes 14 roles that can be used when defining contributor roles. Contributor roles should be agreed before sending a manuscript to a publisher.\nResearchers will use works created by others- either as a fundamental part of their research methodology or during publication. Where exceptions like those for non-commercial research or non-commercial data mining do not apply, ensuring that licences are in place that allow for the uses within the research activity is essential. The use of research data and the management of data related rights should be considered and outlined within the data management plan which must also take into account how the research data are to be archived and used, as well as how the authors of the data are attributed in compliance with research ethics.\n\n\nIn order to use the copyright protected work, either permission from the owner, agreements covering the uses, or legislation allowing the use is needed.\nCopyright legislation tries to strike a balance between protecting the freedom of sciences, expression, and information, and the protection of the copyright owner. This means that while the owner of the rights can control it, there are exceptions to those rights which enable some uses without the need for the owner’s permission. These are known as exceptions, or user rights.\nCopyright exceptions include for example certain educational uses, the provision of inter library loans by libraries, text and data mining for non-commercial scientific research purposes and commercial purposes, creating accessible copies of works for those with disabilities\nCopyright laws vary by country and, while EU law is largely harmonised, there are differences between member states concerning the copyright exceptions. Understanding local national law exceptions for research and education is important.\n\n\n\nUsing archival materials can raise some unusual situations which mean the normal copyright rules don’t apply. Below are a couple of examples of unusual copyright scenarios:\nWorks of art on public display The rules around works of art on public display vary by country. In some EU countries the so-called ’Freedom of Panorama’ rules dictate what can and cannot be done with such works for commercial purposes. Italy for example controls commercial uses of works of cultural importance regardless of their copyright status.\nContractual issues\nWhile works in the public domain may be free from copyright access to them and their use may be controlled via contract law. Many museums and galleries apply terms and conditions to the use of digital surrogates which apply irrespective of the copyright status.\nDatabase Rights\nThe EU sui generis database protection and the Nordic catalogue protection intend to protect the investment in a database. A database usually does not have the original artistic or literary form that protection of a database as an original work would require but it does involve creative choices in the structure layout and data fields being collected. While the data items themselves may not have copyright the overall database will be protected by the database right. Ownership of database rights may vary by law or contract. For example in the Nordic version these rights are given to the university as employer, not to the researcher as the employee.\nUnpublished works\nThere are specific rules surrounding the copyright of works that have never been ‘communicated to the public’ or they have never been publicly accessible.\nOrphan works\nWhere the owner of the rights in a copyright work is known but cannot be traced they are classed as orphan work. Within the EU the Orphan works Licensing Scheme is a EU wide licensing mechanism that gives assurance to users of these works subject to the payment of a fee.\nOut of commerce works\nWhere a work is no longer commercially exploited by the owner, or publisher for example, there are EU rules around how a user might use these items.\nEthical authorship\nCopyright authorship and who are authors in a scientific publication differ. When listing authors and those persons who have contributed to the research and to the publication should be mentioned, contributor roles should be defined, and a tool for this is the CRediT – Contributor Role Taxonomy (niso.org).\n\n\n\n\nLicensing agreements are a central type of legal contract concerning copyright works. Use of published content within institutions will be covered by licences. Access to ebooks, e-journals, databases etc are all covered by licences. It is important to know and understand the terms under which access to content is provided so that users can use the content without risk of breaching the licence terms.\nMany of the permitted uses within licences closely mirror the copyright exceptions mentioned above, however they provide a clarity and certainty that the exceptions may not.\nIn general, licences give institutions, their staff and students, permission to use the licensed content for specific purposes. These purposes are usually limited to education and non-commercial research activities, i.e. the students, researchers and educators can use the content for their purposes but HR or financial teams that are not directly engaged in research or teaching delivery cannot.\nThe terms of the licences will vary but they frequently allow for saving or printing of parts of the licensed works. Some licences will allow users to include extracts within teaching materials or even within publications. How much can be used will also vary.\nIt is important that these purposes and licence terms are clearly understood and that the use they expect to make of the content is expressly permitted within the licence terms. For example if an institution has an active research interest in data mining, licences that seek to prevent or restrict this activity will be problematic. Where licence terms are unclear this should be raised with the provider. Where they conflict with the legal exceptions in law this should also be queried.\nInstitutions may also rely on licences provided by collective licensing societies- official bodies that represent a group of authors, publishers or rights holders. The licences may cover things like photocopying and scanning of printed works, showing broadcast television programmes or playing recorded music. Again understanding the terms, the uses and obligations is important.",
    "crumbs": [
      "TOPIC GUIDES",
      "Copyright & Licensing: Current context and considerations for researchers and libraries using AI in research today"
    ]
  },
  {
    "objectID": "copyright.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "href": "copyright.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "title": "Copyright & Licensing: Current context and considerations for researchers and libraries using AI in research today",
    "section": "Relevance to the Library Sector (Case Studies/Use Cases)",
    "text": "Relevance to the Library Sector (Case Studies/Use Cases)\nLibraries and cultural heritage institutions today don’t just support academics to undertake computational research by providing guidance and increasingly computational access to digital collections, they undertake digital research in their own right as part of library work, using existing models and developing new ones for analysing digital collections at scale for metadata improvement and enhancement and a whole host of other applications. For European institutions understanding TDM rights granted by the Directive on Copyright in the Digital Single Market (later the DSM or Directive (EU) 2019/790) and the EU AI Act is important when undertaking this work, as well as keeping up to date on your local contexts which aligns with these but in some cases may differ, such as in the UK.\nThis is an evolving area and our aim here is to provide a brief overview of the current copyright and licensing context for European researchers and institutions using AI tools and methods in research today.\n\nText and Data Mining (TDM)\nText and data mining (TDM) is a common research technique that allows researchers, and research organisations to analyse large volumes of data using modern computing power. Under EU law the Directive on Copyright in the Digital Single Market (later the DSM or Directive (EU) 2019/790) introduced TDM copyright exceptions. TDM is defined Article 2(2) as:\n\n‘text and data mining’ means any automated analytical technique aimed at analysing text and data in digital form in order to generate information which includes but is not limited to patterns, trends and correlations;\n\nTDM is a core part of machine learning and artificial intelligence (AI) technologies. It could include the harvesting and scrapping of online data sources, or digitising printing items so that they can be read by computers.\nDSM directive Article 3 allows for the use of copyright works in TDM activities for the purposes of non-commercial scientific research by research organisations and cultural heritage institutions provided they have lawful access to the content. This exception is mandatory and rights holders can not override it using agreements or technical measures when EU legislation is applicable. If the agreement is done with an organisation outside EU and governed by legislation other than EU legislation, researchers should contact their legal department for advice on how EU legislation exceptions can be applied to contractual obligations (see Regulation (EC) N o 593/2008 of the European Parliament and of the Council of 17 June 2008 on the law applicable to contractual obligations (Rome I). It is advisable to define in agreements with US/other non-EU companies that mandatory exceptions to copyright in national EU member state legislation apply to the agreement, despite being otherwise governed by US legislation.\nDSM directive Article 4 allows for text and data mining for any purpose by any organisation or person, provided they have lawful access. However, right holders are permitted to opt out of this broad exception as defined using a machine-readable opt-out, as defined in Article 4(3):3.\n\nthe exception or limitation provided for in paragraph 1 shall apply on condition that the use of works and other subject matter referred to in that paragraph has not been expressly reserved by their rightholders in an appropriate manner, such as m_achine-readable means in the case of content made publicly available online.\n\nWhat is the way to opt out in “appropriate manner, such as machine-readable means” is now to be discussed in a court case in Germany Machine readable or not? - notes on the hearing in LAION e.v. vs Kneschke - Kluwer Copyright Blog (kluweriplaw.com). District Court of Hamburg, Germany has on 27.9.2024 made a decision in the first European case that examines the relying on the the TDM exception for the purpose of training generative AI models\nAs the DSM is a directive, member states were able to implement certain elements as they see fit and this has led to some disjointed approaches across the EU with some countries taking different approaches. Ireland for example requires that an author is entitled to be informed that the copy has been made for text and data mining purposes and ask for details about the steps taken to ensure the security of the works copied (see Copyright and Related Rights Act, 2000 (as amended) sections 53A and 53B). Similar requirement of transparency regarding the materials used for AI training of generative AI models is a key point in the AI Act; the sections concerning generative AI are applicable from August 2025.\n\nExample 1\nThe library is a partner on a non-commercial collaborative research project at a university where a research team wants to engage in linguistic analysis, using computational methods, of EU newspaper articles the library has made available publicly online. In order to complete the research they need to extract all of the articles during a certain period to build a corpus of data sourced from different EU newspapers. Once the corpus is complete the researcher wants to use a computer program to perform the analysis. As the data is sourced from different newspaper websites, there is some data cleaning required.\nAll of the copying of the articles for the purposes of this research is permitted as is any data cleaning under the terms of the TDM exception above. The research team is permitted to carry out any steps necessary to obtain and format the data to enable them to complete the analysis using computational methods. If the researchers want to use printed articles those could be digitised and made machine-readable too.\n\n\nExample 2\nNow the corpus is complete the researcher wants to use a free online AI service to complete the analysis.\nThe model’s terms say that the user of the service declares owning all of the input data they provide and grants a licence to the model provider which allows the model provider to retain the input data and use it as a part of the training data. The DSM directive Article 3 exception or its national legislations do not allow this granting of licence to commercial companies to the input data, so the researcher can only use paid services, which the university has purchased, and which have terms that allow the input data to stay on the university VPN.\nWhile the mandatory exception would cover the collection and analysis of the data for scientific research purposes, it does not enable the researcher to own the data nor does the exception give the researcher the authority to grant permissions for non-scientific training data uses. If the researcher would give the material to the AI system provider, contrary to the scope of the exception legislation, then the AI system provider would not have acquired the data lawfully, so the general text and data mining exception would not apply.\n\n\n\nAI Act and Copyright\nThe EU AI Act legislates obligations for providers and deployers of artificial intelligence (AI) systems and AI models and includes articles concerning the copyright protected content as training data of AI models. The AI Act confirms that text and data mining exceptions support the use of content for training AI models. AI Act Article 53 contains obligations for providers of general-purpose AI models:\n\n\nArticle 53(c) the provider of a general purpose AI model must put in place a policy to comply with Union law on copyright and related rights, and in particular to identify and comply with, including through state-of-the-art technologies, a reservation of rights (opt-out) expressed in Article 4(3) of Directive (EU) 2019/790 (DSM directive).\nArticle 53(d) the provider of a general purpose AI model must draw up and make publicly available a sufficiently detailed summary about the content used for training of the general-purpose AI model, according to a template that will be provided by the EU AI Office.\n\n\nArticle 53 and other general-purpose AI sections of the AI Act are applied from August 2025 onwards.\nAI models that are used to create content, such as text or images, for example Midjourney or ChatGPT, are considered general-purpose AI models in the recitals of the AI Act.\n\n\nAI Act Article 3 (4) defines ‘provider’ as a natural or legal person, public authority, agency or other body that develops an AI system or a general-purpose AI model or that has an AI system or a general-purpose AI model developed and places it on the market or puts the AI system into service under its own name or trademark, whether for payment or free of charge.\n\n\nHowever, the AI Act is not directly applied to scientific research:\n\n\nArticle 2(6) The AI Act does not apply to AI systems or AI models, including their output, specifically developed and put into service for the sole purpose of scientific research and development.\n\n\nBut if the result of a research study is a general-purpose AI model, and it is placed on the market or put to use, other than for the sole purpose of scientific research, then the provider requirements apply, e.g. the provider needs to be able to list a sufficiently detailed summary of the content used for training of the general-purpose AI model. According to Article 2 (8) the AI Act does not apply to testing or development prior to placing it on the market, but it applies to real world testing of the general-purpose AI model.\nAI Act does not regulate artificial intelligence, which is a philosophical rather than legal term, but it regulates AI systems that are are defined in Article 3 (1):\n\n\n‘AI system’ means a machine-based system that is designed to operate with varying levels of autonomy and that may exhibit adaptiveness after deployment, and that, for explicit or implicit objectives, infers, from the input it receives, how to generate outputs such as predictions, content, recommendations, or decisions that can influence physical or virtual environments.\n\n\nThe autonomy of the AI systems makes it different from other tools that are controlled by the author and this autonomous aspect of generative AI has an effect when regarding the human authorship of the generative AI system output.\nAI Act Article 3 (33) defines that ‘input data’ means data provided to or directly acquired by an AI system on the basis of which the system produces an output. Both input data and output should be considered in the framework of copyright, so that neither are infringing copyright of third parties.\nWhen applying the exception rules allowing text and data mining, users of third party works as training data must bear in mind that the three step test limits all exception rules.\n\n\nDirective 2001/29 Article 5 (5) states that the exceptions and limitations of copyright can only be applied in certain special cases which do not conflict with a normal exploitation of the work or other subject-matter and do not unreasonably prejudice the legitimate interests of the rights holder. For example a generative AI model that would produce illustrations in the style of an illustrator could unreasonably prejudice the legitimate interests of that illustrator as rights holder.\n\n\n\n\nConsiderations for libraries and research projects using AI\nIf a research project intends to use copyright protected works as training data for AI models, researchers should consider how the text and data mining exception in EU legislation would allow the intended reproduction of works as training data. The recent court case from Hamburg District Court, considers scientific research to be a wide concept. If the research outputs are to be commercialised, consideration must also be given to the new EU AI Act and its requirement in Article 53 to document all copyright protected training data.\nIf researchers are using copyright protected works in existing third party AI tools, use should be balanced against the exceptions or licences covering the content they wish to use. Researchers should consider whether they are required to grant the third party tool permissions to use the content, and whether this is possible within the scope of the licence or exception. As the researcher may not own the content they wish to input, they may not have the authority to grant those permissions. This is especially important where third party tools develop their model using input data.\nIncreasingly, publishers are seeking to restrict the use of the licensed content as training data to train AI models or as input used in AI systems, while in other instances they are creating licencing agreements to allowing large technology companies access to scholarly content (see Generative AI Licensing Agreement Tracker - Ithaka S+R and An academic publisher has struck an AI data deal with Microsoft – without their authors’ knowledge). The ICOLC Statement on AI in Licensing offers a useful template to begin to push back to ensure researchers and institutions are able to use licensed content for non-commercial research at least. Of course institutions are heavily involved in the translation of research into commercial activity so the ICOLC statement is only of limited use, but it’s a start.\nConsideration should also be given to the impact of AI tools on library systems and the ingestion of content, openly licensed or otherwise, by generative AI tools. For instance, the KB restricts access to collections for training commercial AI | KB, National Library of the Netherlands and in January 2024 issued a Statement on commercial generative AI | KB, National Library of the Netherlands outlining their position “that commercial parties who crawl digital resources on websites on a large scale for training models, using applications such as ChatGPT, are not complying with the AI principles established by the KB in 2020.”\nThe harvesting of vast volumes of online content as training data for AI models is under increasing scrutiny, as is the harvesting of personal data. It should be noted that some right holders are actively seeking to prevent their content being analysed, accessed, or processed by any AI tools, regardless of whether they are “inhouse”, third party, secure/ protected/ ring fenced or otherwise. Different jurisdictions have differing legislation and court cases will further define AI and copyright legal questions over time.\n\n\nAI and original work protected by copyright\nAI is bringing a new urgency to the requirement of originality, which is a fundamental aspect of copyright. According to the Berne Convention for the Protection of Literary and Artistic Works, a copyright protected work has to reflect/contain the intellectual creation of the author. This requirement of originality is a fundamental part of what copyright protects and is a feature of national and EU legislation endorsed in many court cases.\n\nExample 3\nIn the US the person or company wishing to register copyright can apply for copyright registration from the US Copyright Office (USCO). USCO received and examined an application containing images that were created by generative AI program and service Midjourney. Users of Midjourney operate through “prompts” (text commands) which include the description of what Midjourney should generate. Midjourney does not interpret prompts as specific instructions to create a particular expressive result, but simply converts words and phrases into smaller tokens that are used for the training of data and to generate an image. The process is not controlled by the user because it is not possible to predict what Midjourney will create ahead of time.\nUSCO concluded that the images generated by Midjourney are not original works of authorship protected by copyright, since Midjourney generates images in an unpredictable way. The fact that Midjourney´s specific output cannot be predicted by users makes Midjourney different for copyright purposes from other tools used by artists for example editing tools and assistive tools that allow the choice of specific changes and include specific steps to control the final image by the user.\nIn the US District Court Of Columbia copyright case Thaler v. Perlmutter, the Court decided that human authorship is a fundamental requirement for copyright claim.\nIn the EU, courts have the same requirement of human authorship and require the ability of the author to control the creative process by making free choices. The Court of Justice of the European Union has considered the originality requirement in the cases C‑5/08 Infopaq and C-145/10 Painer defining that copyright can only apply to a work which is original in the sense that it is its author’s own intellectual creation. An intellectual creation is an author’s own if it reflects the author’s personality. That is the case if the author was able to express his creative abilities in the production of the work by making free and creative choices. Simple facsimile copies of original works, then would not be copyright works in their own right.\n\n\nExample 4\nDigital copies of historic artworks that are in the Public Domain are created to replicate the original as far as possible. The items are photographed and then the images are uploaded to a website.\nThese digital surrogates would not contain any originality as defined and would not attract a new, distinct copyright. The creator of the photograph is trying to copy the original, they are not making free creative choices. They are not creating their own creative outputs.\nThere is a parallel here with generative AI perhaps.\n\n\nExample 5\nIn the Czech decision by the Prague Municipal Court 11.10 2023, a person (claimant) filed a lawsuit against a law firm (defendant) after it published an image on its website without the claimant’s permission. The claimant had created an image with the generative AI service DALL-e. The image shows two hands signing a business contract, and it had been created by the person using the following text prompt : “create a visual representation of two parties signing a business agreement in a formal environment; for example, in a conference room or a law office in Prague. Show only the hands.”\nIn the Court’s opinion, the image cannot as a matter of principle be protected by copyright, because such an image is not the result of creative activity of a natural person – an author. The Court concluded that the image is not a copyright-protected work. The claimant argued that the image was created on the basis of his specific prompt, which justified the claimant’s copyright to the image. The Court considered that the prompt itself could only be regarded as a theme or idea for a work, neither of which can be protected by copyright. The Czech Copyright Act specifically lists themes, ideas and similar more abstract concepts as excluded from copyright protection, which is a principle generally recognised internationally.",
    "crumbs": [
      "TOPIC GUIDES",
      "Copyright & Licensing: Current context and considerations for researchers and libraries using AI in research today"
    ]
  },
  {
    "objectID": "copyright.html#hands-on-activity-and-other-self-guided-tutorials",
    "href": "copyright.html#hands-on-activity-and-other-self-guided-tutorials",
    "title": "Copyright & Licensing: Current context and considerations for researchers and libraries using AI in research today",
    "section": "Hands-on activity and other self-guided tutorial(s)",
    "text": "Hands-on activity and other self-guided tutorial(s)\nThis guide contains a ton of resources for learning about copyright but for something a little bit different, check out the Copyright Card Game or online quizzes such as European Copyright 10 Questions.",
    "crumbs": [
      "TOPIC GUIDES",
      "Copyright & Licensing: Current context and considerations for researchers and libraries using AI in research today"
    ]
  },
  {
    "objectID": "copyright.html#recommended-readingviewing",
    "href": "copyright.html#recommended-readingviewing",
    "title": "Copyright & Licensing: Current context and considerations for researchers and libraries using AI in research today",
    "section": "Recommended Reading/Viewing",
    "text": "Recommended Reading/Viewing\nCopyright and AI is a constantly moving area and it can be hard to keep up with the latest developments but we can recommend following the The IPKat (ipkitten.blogspot.com) and Kluwer Copyright Blog (kluweriplaw.com) and News from the LIBER Copyright & Legal Matters Working Group for excellent updates.\nMuch guidance is based on national law, so you will need to keep an eye on copyright legislation, which will provide an overview of the local picture. These international networks and organisations are also useful places for getting more in depth information:\n\nWIPO\nEU Intellectual Property Office\nCreative Commons\nKR21\nCommunia Association",
    "crumbs": [
      "TOPIC GUIDES",
      "Copyright & Licensing: Current context and considerations for researchers and libraries using AI in research today"
    ]
  },
  {
    "objectID": "copyright.html#finding-communities-of-practice",
    "href": "copyright.html#finding-communities-of-practice",
    "title": "Copyright & Licensing: Current context and considerations for researchers and libraries using AI in research today",
    "section": "Finding Communities of Practice",
    "text": "Finding Communities of Practice\nIf you are employed in an institution that is a member of LIBER do join or reach out to the LIBER Copyright & Legal Matters Working Group, a group of librarians, lawyers, professors and communications professionals who monitor current European law and react to proposed changes, on behalf of libraries, archives, researchers and students.",
    "crumbs": [
      "TOPIC GUIDES",
      "Copyright & Licensing: Current context and considerations for researchers and libraries using AI in research today"
    ]
  },
  {
    "objectID": "workingwdata.html",
    "href": "workingwdata.html",
    "title": "Working with Data",
    "section": "",
    "text": "Data is all around us, and it almost cannot be avoided. Libraries and universities are full of data, but staff often think they do not work with data. Have you ever been asked how many loans a book has had? What about how many visitors came in at the weekend? Or if a certain book is available? These are all data questions, answerable with quantifiable facts.\nData is often considered to be a number, like the number of times a book has been loaned, but what about who borrowed it, or what their review was? These are all different forms of data, and can provide all new insights to the popularity of a book - maybe a book was borrowed 10 times, but in fact got 10 1-star reviews, versus a book borrowed 5 times with 5 5-star reviews, using this data, which one would you recommend?\nThis guide will explore the use of data within libraries through proposing questions to think through when undertaking your own data tasks, alongside practical examples from libraries around the world.\n\n\nData is often overwhelming (the term ‘Big Data’ floats around a lot!), but that shouldn’t stop you from exploring it, because it can greatly improve your work. Just to clarify, Big Data will not be discussed here, Big Data requires data to be high in volume and velocity, which is not the case for most library data (think about downloading a document every time the hashtag #photooftheday is used).\nSo first, let’s establish some definitions (for this guide at least) while looking at one of our most central collections of data:\n\n\n\n\n\n\n\n\nDefinition\n\n\n\n\nData\nA collection of information.\n\n\nData Point\nSingle point of data (e.g. a data point could be the title of a book, however alone that information tells us very little about the book. Therefore a ‘record’ containing relevant data points will be created.).\n\n\nMetadata\nData that provides information about other data (e.g. columns of data in a spreadsheet). (e.g. in a library catalalogue the metadata about the book includes the price information, the isbn, author and title\n\n\nDataset\nA collection of data from a single source or for a single project. (e.g. we might create a dataset of all catalogue records relating to a particular topic of interest to researchers)\n\n\nDatabase\nA table with structured (organised) data.\n\n\nDataframe\nA structured representation of data\n\n\nSoftware\nProgram for a computer.\n\n\nHardware\nThe physical components of technology.\n\n\nBack-end\nThe part of a system that is not usually visible or accessible to a user of that system.\n\n\nFront-end\nA software interface designed to enable user-friendly interaction with software.\n\n\n\n\n\n\nData can be qualitative (sentiment) or quantitative (numerical), therefore when we think about visitors to a library, do you know how they felt about their visit (qualitative data) or how many hours they spent at the library (quantitative data)?\nHere are some examples to get you thinking about what data points stem from a library;\n\n\n\n\n\n\n\n\nInstitution\nStaffing\nAcquisitions\n\n\n\n\nThe Building / SpaceWider CommunityStakeholdersFacilitiesBusinessOpening Hours\nLibrary StaffInstitution DepartmentsQualifications and Education\nSubscriptions (ongoing)Purchasing (one time)SoftwareSuppliersSpending / Financial Information\n\n\n\n\n\n\n\n\n\n\n\nResources\nEngagement\nPatrons\n\n\n\n\nMaterials metadataCollection(s)Care and MaintenanceDiscovery ServicesAccessibility Services\nResearch Data ManagementTrainingOutreachToursCommunicationQuantity of Users\nHelpdesk (in-person)Queries (email, online chat etc.)User SupportFeedbackInteractions\n\n\n\nConsidering the above, what do you interact with? Do you consider yourself to work with data?",
    "crumbs": [
      "TOPIC GUIDES",
      "Working with Data"
    ]
  },
  {
    "objectID": "workingwdata.html#introduction",
    "href": "workingwdata.html#introduction",
    "title": "Working with Data",
    "section": "",
    "text": "Data is all around us, and it almost cannot be avoided. Libraries and universities are full of data, but staff often think they do not work with data. Have you ever been asked how many loans a book has had? What about how many visitors came in at the weekend? Or if a certain book is available? These are all data questions, answerable with quantifiable facts.\nData is often considered to be a number, like the number of times a book has been loaned, but what about who borrowed it, or what their review was? These are all different forms of data, and can provide all new insights to the popularity of a book - maybe a book was borrowed 10 times, but in fact got 10 1-star reviews, versus a book borrowed 5 times with 5 5-star reviews, using this data, which one would you recommend?\nThis guide will explore the use of data within libraries through proposing questions to think through when undertaking your own data tasks, alongside practical examples from libraries around the world.\n\n\nData is often overwhelming (the term ‘Big Data’ floats around a lot!), but that shouldn’t stop you from exploring it, because it can greatly improve your work. Just to clarify, Big Data will not be discussed here, Big Data requires data to be high in volume and velocity, which is not the case for most library data (think about downloading a document every time the hashtag #photooftheday is used).\nSo first, let’s establish some definitions (for this guide at least) while looking at one of our most central collections of data:\n\n\n\n\n\n\n\n\nDefinition\n\n\n\n\nData\nA collection of information.\n\n\nData Point\nSingle point of data (e.g. a data point could be the title of a book, however alone that information tells us very little about the book. Therefore a ‘record’ containing relevant data points will be created.).\n\n\nMetadata\nData that provides information about other data (e.g. columns of data in a spreadsheet). (e.g. in a library catalalogue the metadata about the book includes the price information, the isbn, author and title\n\n\nDataset\nA collection of data from a single source or for a single project. (e.g. we might create a dataset of all catalogue records relating to a particular topic of interest to researchers)\n\n\nDatabase\nA table with structured (organised) data.\n\n\nDataframe\nA structured representation of data\n\n\nSoftware\nProgram for a computer.\n\n\nHardware\nThe physical components of technology.\n\n\nBack-end\nThe part of a system that is not usually visible or accessible to a user of that system.\n\n\nFront-end\nA software interface designed to enable user-friendly interaction with software.\n\n\n\n\n\n\nData can be qualitative (sentiment) or quantitative (numerical), therefore when we think about visitors to a library, do you know how they felt about their visit (qualitative data) or how many hours they spent at the library (quantitative data)?\nHere are some examples to get you thinking about what data points stem from a library;\n\n\n\n\n\n\n\n\nInstitution\nStaffing\nAcquisitions\n\n\n\n\nThe Building / SpaceWider CommunityStakeholdersFacilitiesBusinessOpening Hours\nLibrary StaffInstitution DepartmentsQualifications and Education\nSubscriptions (ongoing)Purchasing (one time)SoftwareSuppliersSpending / Financial Information\n\n\n\n\n\n\n\n\n\n\n\nResources\nEngagement\nPatrons\n\n\n\n\nMaterials metadataCollection(s)Care and MaintenanceDiscovery ServicesAccessibility Services\nResearch Data ManagementTrainingOutreachToursCommunicationQuantity of Users\nHelpdesk (in-person)Queries (email, online chat etc.)User SupportFeedbackInteractions\n\n\n\nConsidering the above, what do you interact with? Do you consider yourself to work with data?",
    "crumbs": [
      "TOPIC GUIDES",
      "Working with Data"
    ]
  },
  {
    "objectID": "workingwdata.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "href": "workingwdata.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "title": "Working with Data",
    "section": "Relevance to the Library Sector (Case Studies/Use Cases)",
    "text": "Relevance to the Library Sector (Case Studies/Use Cases)\n\nData exists, so what?\nData should have a purpose. If data has no purpose, why waste your time managing it? The purpose of data could be any of the following;\n\nProvide insights to pertinent questions, and thus make informed decisions.\nProvide evidence of a decision or conclusion.\nExplore relationships / trends, to tell a story and provide insights.\nExplain (and display) complex information more effectively.\n\nData can provide additional power when making a decision (big or small) - knowing exactly how many users visit at the weekend can prove the library does require the funding and staffing to stay open on the weekend. However, if it proves no one is visiting, do not fudge the numbers. Use those numbers to question why, such as what else could attract users, what do patrons use it for currently, or was there a cause to the decline in weekend patrons?\n\n\nProof is in the Pudding\nKnowing that data exists in a library is the first step, but what can be done with it? While this guide has touched on a few questions you can use data to answer, below will explore real world examples of libraries utilising their data to make powerful changes.\nData can inform decisions about:\n\nCollection Management: what is being used, when, by who, and why (if you have a review system).\n\nExample: Within our collection, how often do users borrow material published before 2000? (But remember, borrowing is not the only form of usage!).\n\nOutreach: who forms our community, what matters to the community,\n\nExample: Does the demographic of people attending our events reflect the demographic of people in our wider community? Which events could make the library more appealing to the wider community?\n\nFunding / Expenditure: Use data about patron usage, reader requests or patron feedback as part of an application for additional funding or staffing to prove your standing within the community.\n\nExample: How much would it cost to buy an additional copy of a book, if it had more than three reservations at a given time?\n\nReviewing Success: When starting a new project or approach, consider how it will be measured as a success. Knowing how to measure the impact of a project will enable you to actively reflect and produce solid facts about the success of your project.\n\nExample: How can we measure patron satisfaction currently, so that at the end of the project a 10% increase can be quantified and thus the project can be considered a success?\n\n\nHere are a few real world examples of big data projects within libraries, but remember, small or internal projects should be informed by data too.\n\nTelling Stories with Library Data July 2021\n\nThe Metropolitan Museum of Art (New York) Watson Library explores their production of data visualisations using Microsoft Power BI in regards to their library activities. Using the library management system (data which they already had), google analytics, digital collections and some manual tallies, they explored six years of library data. This exploration demonstrated the benefit of moving their blog from an external website, created an index of African American Artists,and ease in sharing library metrics for the previous six years publicly.\n\nWhen is a Year Complete? October 2023 It is well known that publications databases take time to update, but how long? Collection Analysis Librarian at Iowa State University, Eric Schares, wanted to know how long to wait before being able to analyse a calendar year of publications, and set about doing so by comparing data from three different publication services (Dimensions, Web of Science and Open Alex). The data (which continues to be updated), documented the rise of Open Alex, and demonstrated part of the effectiveness of each service for Iowa State University - however he also shares his code and thus you can replicate this data question at your own institution.\nUse of Institution Data Analysis for Publisher Negotiations July 2023 | Utilising Data to Understand the Institutions Relationship with a Publisher March 2024 Data Analyst at the University of Cambridge Library Niamh Malin, was responsible for supporting the many publisher negotiations. The first paper addresses the use of Microsoft Excel and Dimensions publications data to document the relationship of the university with Springer Nature. The second presentation documents the transition to Microsoft Power BI to create data dashboards which ensure every publisher negotiation is informed by usage and publications data.\nUsing Analytics to Extract Value from the Library’s Data - Event Part One: Analytics Behind the Scenes and Part Two: Actionable Data Analysis September 2018. The National Information Standards Organization (NISO) hosted a two part webinar in 2018 about extracting value from library data. The slides for the six presentations are available, and cover topics such as; setting up a data analysis strategy, analysing metadata, utilising data visualisations, actioning data insights for utilising physical spaces and building confidence in your data analysis skills.\nLibraries support data-driven decision making February 2024. An OCLC-Liber blog post following their “Building for the future” program where librarians had gathered to discuss their understanding and practical interpretations of data driven libraries.\nUtilising new modes of data to enhance research strategy and collaboration November 2023. Digital science looks at how institutions can get high-quality insights into research by standardising their data systems.",
    "crumbs": [
      "TOPIC GUIDES",
      "Working with Data"
    ]
  },
  {
    "objectID": "workingwdata.html#hands-on-activity-and-other-self-guided-tutorials",
    "href": "workingwdata.html#hands-on-activity-and-other-self-guided-tutorials",
    "title": "Working with Data",
    "section": "Hands-on activity and other self-guided tutorial(s)",
    "text": "Hands-on activity and other self-guided tutorial(s)\nNow that you’ve found some data, and/or you’ve formulated some questions to answer, how do you know the data will be good enough? Let’s take some time to assess the data, and ensure it is fit for purpose, because a key analogy in data analysis is;\n    **GIGO: Garbage in, garbage out!.**\nThe process of utilising data is a cycle, a standard process model that describes a common approach to data is CRISP-DM (Cross-industry standard process for data mining). It has six stages, listed below.\n\nThis section will enable you to assess your data, through a variety of leading questions, at each stage of the cycle. How long each phase takes will depend entirely on the project, there is no right or wrong, and it is cyclical, you will return to questions as you develop the project. These are structured as questions because one guide cannot have all the answers, and therefore giving a variety of questions which hopefully ensure you do not miss anything, and learn much more which is relevant to your project. This approach will enable you to assess if the data you have is relevant to the question, and if it has the potential to answer it correctly.\nThis guide hopes to calm your nerves about using data, and to see that you are capable of answering data questions confidently.\n\nBusiness Understanding\nThe Business Understanding phase focuses on understanding the objectives and requirements of the project. Here you are planning your project\n\nWhat questions are you answering?\nWho are your stakeholders?\nWhat are the criteria and limitations to the project?\nWhat is the goal of using this data? Doing this project?\nWhat resources are (or are not) available?\nWhat is the timeline on the project? And the data input specifically?\nWhat stage of the project requires data analysis?\nWhat is the expected outcome of the data analysis?\n\n\n\nData Understanding\nData Understanding drives the focus to identify, collect, and analyse the relevant datasets.\n\nCan you access the data you require? What is the source?\nWhat data (and metadata) is missing?\nHow reliable is the data?\nWhat relationships are relevant within the data?\nWho is involved in gathering and preparing the data?\n\n\n\nData Preparation\nA common rule of thumb is that 80% of the project is data preparation.\n\nWhat data is not necessary from the dataset?\nHow are errors or duplications handled?\nWhat new attributes or formulas are required?\nHow do datasets interact with one another?\nIs the data formatted correctly?\nWhat acronyms are in use? Are they formatted correctly?\nHas the data been standardised?\nAre the column names useful and appropriate?\nDoes every database have a unique identifier column?\nHow do you handle missing metadata?\nAre you editing the master / only copy?\nHave you documented the process so that you can provide evidence if needed?\nIs the data in a clear and useable tabular format (rows and columns)?\nHave all merged cells been removed / updated?\n\n\n\nModelling\nWhat is often regarded as the most exciting work is also often the shortest phase. Now is the time to build and assess various models or visualisations.\n\nWhat conclusions can be drawn from the data?\nWhat visualisations are appropriate to display the data?\nWhat comparisons and relationships should be highlighted to align with your initial goal?\nDoes the data contradict the hypothesis? Why?\nDo the formulas need to be live? Tip: Live formula within a spreadsheet can cause it to be slow and large in size.\n\n\n\nEvaluation\nThis phase looks more broadly at the data project and what to do next.\n\nDid the data fulfil the goal of this project?\nWhat was unable to be achieved?\nWhat is required for the next data project to run more efficiently?\nHas the project been completed successfully?\n\n\n\nDeployment\nDepending on the requirements, the deployment phase can be as simple as emailing a graph, or as complex as publishing a live dashboard of intricate data and visuals.\n\nWho requires the outcome of this project?\nWill the outcome need to be presented in multiple formats?\nWill this be repeated again? Has it been documented?\nWhere will the data and outcome be stored?\n\n\nStoring a datafile / spreadsheet\nOnce the data exists, it must be accessible. There are a variety of software which can store your data, and taking the time to assess the needs of your data is important.\n\nIs the file formatted correctly (CSV vs Microsoft Excel)?\nWill it need to be accessed online and/or offline?\nDoes the file require a software licence to access?\nWhat backups are required?\nHow long are files required to be stored? Use this webpage for guidance on different file formats.",
    "crumbs": [
      "TOPIC GUIDES",
      "Working with Data"
    ]
  },
  {
    "objectID": "workingwdata.html#recommended-readingviewing",
    "href": "workingwdata.html#recommended-readingviewing",
    "title": "Working with Data",
    "section": "Recommended Reading/Viewing",
    "text": "Recommended Reading/Viewing\n\nDefining Data Librarians\n\nDefining data librarianship: a survey of competencies, skills, and training (July 2018). Federer aims to define data librarianship by exploring the skills and knowledge that data librarians utilise and the training that they need to succeed.\nIntroduction to Databrarianship: The Academic Data Librarian in Theory and Practice (2016). Thompson and Kellam explore the diverse field of data librarianship, highlighting its key commitment to accessible data.\nData librarianship: a day in the life (2011). Interviews with data librarians across the world highlight the challenge and opportunities of data in libraries, including the creation of data services within an academic library.\nThe future for numeric data services (2011). Exploring the future of data librarians, with trends in visualisation, mapping, standardisation, citation and data management plans.\nLibrarian roles in the digital data-driven world (September 2021). Thai/English paper exploring the role of data librarians as someone who continues to acquire new knowledge and skills with technology and the digital era.\nCILIP (Chartered Institute of Library and Information Professionals) provides definitions on the data science roles available within a library.\n\n\n\nLibrary Endorsed Resources\n\nLIBER members have created the Digital Scholarship & Data Science Essentials for Library Professionals, which this guide is a part of. Guidance also includes data visualisation and data as collections, and continues to grow.\nJISC has published resources to support data-driven decisions, including interactive insights on graduate outcomes and conducting online surveys as a form of data gathering.\nThe DSVIL (Data Science and Visualization Institute for Librarians) provides great guidance and resources for finding, cleaning, analysing, visualising and managing data.\nThe Bodleian Library, University of Oxford, hosts a variety of resources to support data analysis (including audio-visual), data mining, and visualisation tools.\nDuke University Libraries have a plethora of resources for data science, data management and data visualisation freely available.\nARL (Associations of Research Libraries) demonstrate the impact data analytics can have within libraries and library communities.\nIFLA (International Federation of Library Associations and Institutions) has a variety of data analytics resources which cover using specific software, trends in the news, and practical applications of data within libraries.\nThe PLA (Public Library Association) (which is part of ALA, the American Library Association), have developed data tools to enable public libraries to be compared across multiple metrics.\n\n\n\nLearning Data Beyond Libraries\nThere are numerous platforms dedicated to data skills, listed below are some of the most popular for beginning your data journey.\n\nThe Carpentries: Community-led coding and data science courses for researchers and librarians, with three specialties; Data Carpentry (data skills for conducting research), Library Carpentry (software and data skills for librarians), and Software Carpentry (lab skills for research computing).\nDatacamp: great for free cheat sheets (webpage or PDF) on data literacy, understanding data knowledge levels and data storytelling. As well as resources and courses for a variety of coding and data software.\nLinkedIn Learning: a wonderful resource of videos for anything from coding to people management to making the perfect Microsoft Excel graph.\nGoogle Skillshop: Training and certification in google analytics which could upport queries about library engagement.",
    "crumbs": [
      "TOPIC GUIDES",
      "Working with Data"
    ]
  },
  {
    "objectID": "workingwdata.html#taking-the-next-step",
    "href": "workingwdata.html#taking-the-next-step",
    "title": "Working with Data",
    "section": "Taking the next step",
    "text": "Taking the next step\n\nEnsuring Good Practice\nWorking with data is very exciting and rewarding, but can quickly become overwhelming. There are fears of being hacked and having data stolen, or even losing data due to bad organisation or not knowing it needed saving. Sadly this guide cannot have all of the answers on the practices and policies which should be in place. But it will instead ask a few provoking questions to ensure you can rest the worries of data loss and theft.\n\nHave you established a naming convention for files? Does it account for versions, dating and author? Tip: Have titles be meaningful, in a relevant order, and versions discernible.\nWhen will the file(s) be deleted or archived?\nIs there clear documentation of the processes undertaken? Therefore ensuring the task can be repeated, or to justify any conclusions. Tip: This should include the source of the data, any cleaning steps made, and all relevant metadata.\nWhere are the files stored, are the folders easy to access? Is there a naming convention and folder hierarchy in place for the project, and the team?\n\n\n\nWhat skills are you looking for?\nIf you have read through this guide, and still thirst for more, here are some questions to encourage your exploration in library data!\n\nWhat in-house data can you combine (such as the library management system and google analytics)?\nThink of a report that is repeated regularly but often time consuming, is there a software or data task that could make this quicker?\nWhat software do you regularly use, how could you expand those skills? Does the library management system provide specialist training?\nIs coding, AI or visualisation an area you would like to explore? What else do you want to do with data?\nWhich elements of the data process do you want to focus? Cleaning, analysing, visualising etc.\nCan you attend a conference which discusses library data you are interested in?",
    "crumbs": [
      "TOPIC GUIDES",
      "Working with Data"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to Digital Scholarship & Data Science Essentials",
    "section": "",
    "text": "Digital Scholarship & Data Science Essentials for Library Professionals (DS Essentials) aims to make it easier for LIBER library professionals to quickly gain a concise overview of the new technologies and concepts that underpin digital scholarship and data science practice in research libraries today, and find trusted training material recommendations to start their professional learning journey."
  },
  {
    "objectID": "index.html#is-ds-essentials-for-me",
    "href": "index.html#is-ds-essentials-for-me",
    "title": "Welcome to Digital Scholarship & Data Science Essentials",
    "section": "Is DS Essentials for me?",
    "text": "Is DS Essentials for me?\nAre you someone working in or around research libraries with an interest in learning more about how to do cool and interesting things with digital collections and data at your institution? Wondering how data science techniques can help you in your work? Are you interested in gaining valuable digital literacy skills and knowledge to support emerging areas of modern scholarship such as Digital Humanities? Do you need some of the technology jargon you hear about these days demystified?\nThen this resource is for you!\nIt is very important to us that the guides here are inclusive and intellectually accessible, challenging but not terrifying and as such we focus primarily on an introductory audience where no programming or particular digital skills are required.\nThough written from the research library professional perspective we think these guides will be useful for anyone currently (or aspiring to be) working in and around digital collections and data in heritage institutions:\n\nLibrary & Information Science students\nProject managers\nDevelopers\nInformation specialists\nMetadata Managers\nSubject librarians\nSystem librarians\nInstitutional leadership\n\nAnd so many more!"
  },
  {
    "objectID": "index.html#why-this-resource",
    "href": "index.html#why-this-resource",
    "title": "Welcome to Digital Scholarship & Data Science Essentials",
    "section": "Why this resource?",
    "text": "Why this resource?\nOver the past few decades, the development of excellent self-paced tutorials and training materials relating to undertaking digital scholarship and data science in libraries have proliferated online.\nFor library professionals who are relatively new to this area however, it can be hard to know where to begin! Without knowing a little bit about the context of how new technologies are being deployed in research libraries, this dearth of resources can seem quite daunting. Even if you might have an idea of what learning you’d like to undertake, it can be difficult and time consuming to try and navigate the wealth of individual training resources out there on your own.\nDigital Scholarship & Data Science Essentials for Library Professionals is a training reference resource we have developed to remove some of the barrier of having to hunt for recommended training and resources to get you on the learning ladder.\nFrom working with data, automatic handwritten recognition technologies and more, our Topic Guides provide contextualised and gentle introductions, written from the library practitioners perspective, to a wide range of key topics and technologies relevant to working innovatively with our digital collections and data."
  },
  {
    "objectID": "index.html#what-are-topic-guides",
    "href": "index.html#what-are-topic-guides",
    "title": "Welcome to Digital Scholarship & Data Science Essentials",
    "section": "What are Topic Guides?",
    "text": "What are Topic Guides?\nTopic Guides are the heart and soul of Digital Scholarship & Data Science Essentials for Library Professionals. The aim of each is to provide research library professionals with a gentle and concise introduction to the key topics in this area today. They offer those with no prior knowledge, quick and curated guidance to personally recommended hands-on tutorials, use-cases, articles, videos, networks and communities of practice to deepen learning.\nEach Topic Guide follows a fixed structure, consisting of five components in order to make it easier to quickly find what you might need:\n\nIntroduction to the topic\nRelevance to the library sector (Case studies/Use cases)\nHands-on activities and other self-guided tutorial(s)\nRecommended Reading & Viewing\nFinding Communities of Practice"
  },
  {
    "objectID": "index.html#how-to-use-this-resource",
    "href": "index.html#how-to-use-this-resource",
    "title": "Welcome to Digital Scholarship & Data Science Essentials",
    "section": "How to use this resource",
    "text": "How to use this resource\nThis resource has a dual purpose; it is written as a tool for self-study but also as a guide for individuals and institutions interested in establishing their own local training programmes.\nAs a self-study resource, we hope it can serve as a useful first point of entry into complex topics in digital scholarship and data science and their application in the library world. It is not meant to be completed in any particular order, rather, learners are invited to jump in and out of individual topic guides as personal curiosity or practical need dictates.\nThe materials here can also be utilised in group study, as part of a reading group or even a hands-on Hack & Yack. See our special section on “How to start your own training programme” for some tips and tricks from British Library Digital Research Team colleagues on utilising the materials referenced here at your own library or within your network."
  },
  {
    "objectID": "networks.html",
    "href": "networks.html",
    "title": "USEFUL NETWORKS",
    "section": "",
    "text": "Working groups are open to staff at participating LIBER Member institutions:\n\nLIBER Data Science in Libraries\nLIBER Digital Scholarship & Digital Cultural Heritage\nOr have a look at the other LIBER Working Groups - LIBER Europe\n\n\n\n\n\nAI4LAM\nCode4Lib\nElectronic Literature Organisation\nFlickr Commons\nGlam Labs International\nIIIF/UV Open Collective\nIMPACT Centre of Competence\nMuseums Computer Group\nTranskribus\nWikidata Community)\n\n\n\n\n\n\n\nRLUK Digital Scholarship Network\n\n\n\n\n\n\n\nThink we’re missing something?\n\n\n\n\n\nWe’d love to hear it! Suggest edits by opening a new Issue or adding to the discussion on existing Issues on the project Github. If you’re new to GitHub don’t worry, we have a Topic Guide for that: GitHub: How to navigate and contribute to Git-based projects! Or just drop us a line!"
  },
  {
    "objectID": "networks.html#liber-working-groups",
    "href": "networks.html#liber-working-groups",
    "title": "USEFUL NETWORKS",
    "section": "",
    "text": "Working groups are open to staff at participating LIBER Member institutions:\n\nLIBER Data Science in Libraries\nLIBER Digital Scholarship & Digital Cultural Heritage\nOr have a look at the other LIBER Working Groups - LIBER Europe"
  },
  {
    "objectID": "networks.html#international-networks",
    "href": "networks.html#international-networks",
    "title": "USEFUL NETWORKS",
    "section": "",
    "text": "AI4LAM\nCode4Lib\nElectronic Literature Organisation\nFlickr Commons\nGlam Labs International\nIIIF/UV Open Collective\nIMPACT Centre of Competence\nMuseums Computer Group\nTranskribus\nWikidata Community)"
  },
  {
    "objectID": "networks.html#national-networks-european",
    "href": "networks.html#national-networks-european",
    "title": "USEFUL NETWORKS",
    "section": "",
    "text": "RLUK Digital Scholarship Network\n\n\n\n\n\n\n\nThink we’re missing something?\n\n\n\n\n\nWe’d love to hear it! Suggest edits by opening a new Issue or adding to the discussion on existing Issues on the project Github. If you’re new to GitHub don’t worry, we have a Topic Guide for that: GitHub: How to navigate and contribute to Git-based projects! Or just drop us a line!"
  },
  {
    "objectID": "gettingstarted.html",
    "href": "gettingstarted.html",
    "title": "Getting Started in DS",
    "section": "",
    "text": "This guide provides a general introduction to all resources available to you via publications, platforms of network.",
    "crumbs": [
      "TOPIC GUIDES",
      "Getting Started in DS"
    ]
  },
  {
    "objectID": "gettingstarted.html#introduction",
    "href": "gettingstarted.html#introduction",
    "title": "Getting Started in DS",
    "section": "",
    "text": "This guide provides a general introduction to all resources available to you via publications, platforms of network.",
    "crumbs": [
      "TOPIC GUIDES",
      "Getting Started in DS"
    ]
  },
  {
    "objectID": "gettingstarted.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "href": "gettingstarted.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "title": "Getting Started in DS",
    "section": "Relevance to the Library Sector (Case Studies/Use Cases)",
    "text": "Relevance to the Library Sector (Case Studies/Use Cases)",
    "crumbs": [
      "TOPIC GUIDES",
      "Getting Started in DS"
    ]
  },
  {
    "objectID": "gettingstarted.html#hands-on-activity-and-other-self-guided-tutorials",
    "href": "gettingstarted.html#hands-on-activity-and-other-self-guided-tutorials",
    "title": "Getting Started in DS",
    "section": "Hands-on activity and other self-guided tutorial(s)",
    "text": "Hands-on activity and other self-guided tutorial(s)\nTRAINING PLATFORMS\nWhen you’re ready to go further and have a better idea of the specific skills you need for a particular task, we can recommend having a good search through these excellent platforms which host or link to a great many in-depth training materials:\n\nDARIAH-Campus https://campus.dariah.eu/\nDARIAH is a pan-European infrastructure for arts and humanities scholars working with computational methods. It supports digital research as well as the teaching of digital research methods. Though not specific to the library professional context, tutorials here are useful for applying techniques to digital collections.\n\n\nThe Glam Workbench https://glam-workbench.net/\nThe GLAM Workbench is the brainchild of Tim Sherratt, a historian, and is a collection of Jupyter notebooks to help you explore and use data from GLAM institutions (galleries, libraries, archives, and museums). It includes tools, tutorials, examples, hacks, and even some pre-harvested datasets. It’s aimed at researchers in the humanities but has useful tutorials for anyone interested in working with GLAM data.\n\n\nIneo https://www.ineo.tools/\nIneo is a project developed and maintained by CLARIAH that lets you search, browse, find and select digital resources for research in humanities and social sciences. At the end of 2024 it will offer access to thousands of tools, datasets, workflows, standards and learning material. It is a work in progress so do keep that in mind when browsing.\n\n\nLibrary Carpentry https://librarycarpentry.org/\nLibrary Carpentry is an international volunteer community, under the Carpentries, focussed building software and data skills within library and information-related communities. The lessons here are meant to be taught as workshops led by a Carpentries certified instructor (for a fee) but you may find it useful to have a read through the content which is open and available to all.\n\n\nThe Programming Historian https://programminghistorian.org/en/\nThe Programming Historian has been publishing peer-reviewed tutorials on digital tools and techniques for humanists since 2008 and though they’re generally aimed at academic researchers, staff at British Library have found them highly useful over the years in their own work!\n\n\nSocial Sciences & Humanities Open Marketplace https://marketplace.sshopencloud.eu/search?order=score&categories=training-material\nBuilt as part of the Social Sciences and Humanities Open Cloud project (SSHOC), the Social Sciences and Humanities Open Marketplace is a discovery portal which pools and contextualises resources for Social Sciences and Humanities research communities: tools, services, training materials, datasets, publications and workflows. The Marketplace highlights and showcases solutions and research practices for every step of the SSH research data life cycle.",
    "crumbs": [
      "TOPIC GUIDES",
      "Getting Started in DS"
    ]
  },
  {
    "objectID": "gettingstarted.html#recommended-readingviewing",
    "href": "gettingstarted.html#recommended-readingviewing",
    "title": "Getting Started in DS",
    "section": "Recommended Reading/Viewing",
    "text": "Recommended Reading/Viewing\nThere is no shortage of recommended reading lists out there, here we try and highlight a few of the most up to date and useful lists out there for the sector today!\nZotero Library for Digital Scholarship and Data Science Essentials for Library Professionals\nThis library contains links to all of the resources referenced within Topic Guides and across our site.\nZotero | Groups &gt; collections as data - projects, initiatives, readings, tools, datasets\nOngoing collection of projects, readings, initiatives, tools, and datasets that are in some way or another related to collections as data. This group is an open resource, welcoming contributions from anyone who has a resource to share.",
    "crumbs": [
      "TOPIC GUIDES",
      "Getting Started in DS"
    ]
  },
  {
    "objectID": "gettingstarted.html#finding-communities-of-practice",
    "href": "gettingstarted.html#finding-communities-of-practice",
    "title": "Getting Started in DS",
    "section": "Finding Communities of Practice",
    "text": "Finding Communities of Practice\nYou might want to explore any of the existing communities of practice\nLIBER Working Groups\nWorking groups are open to staff at participating LIBER Member institutions: - LIBER Data Science in Libraries - LIBER Digital Scholarship & Digital Cultural Heritage - Or have a look at the other LIBER Working Groups - LIBER Europe\nInternational Networks - AI4LAM - Code4Lib - Electronic Literature Organisation - Flickr Commons - Glam Labs International - IIIF/UV Open Collective - IMPACT Centre of Competence - Museums Computer Group - Transkribus - Wikidata Community)\nNational Networks (European)\nIreland/UK - RLUK Digital Scholarship Network\n\n\n\n\n\n\nTip\n\n\n\n\n\n## Think we’re missing something? We’d love to hear it! Suggest edits by opening a new Issue or adding to the discussion on existing Issues on the project Github. If you’re new to GitHub don’t worry, we have a Topic Guide for that: GitHub: How to navigate and contribute to Git-based projects! Or just drop us a line!",
    "crumbs": [
      "TOPIC GUIDES",
      "Getting Started in DS"
    ]
  },
  {
    "objectID": "dstp.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "href": "dstp.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "title": "Start your own local DS Training Programme",
    "section": "Relevance to the Library Sector (Case Studies/Use Cases)",
    "text": "Relevance to the Library Sector (Case Studies/Use Cases)",
    "crumbs": [
      "TOPIC GUIDES",
      "Start your own local DS Training Programme"
    ]
  },
  {
    "objectID": "dstp.html#hands-on-activity-and-other-self-guided-tutorials",
    "href": "dstp.html#hands-on-activity-and-other-self-guided-tutorials",
    "title": "Start your own local DS Training Programme",
    "section": "Hands-on activity and other self-guided tutorial(s)",
    "text": "Hands-on activity and other self-guided tutorial(s)",
    "crumbs": [
      "TOPIC GUIDES",
      "Start your own local DS Training Programme"
    ]
  },
  {
    "objectID": "dstp.html#recommended-readingviewing",
    "href": "dstp.html#recommended-readingviewing",
    "title": "Start your own local DS Training Programme",
    "section": "Recommended Reading/Viewing",
    "text": "Recommended Reading/Viewing",
    "crumbs": [
      "TOPIC GUIDES",
      "Start your own local DS Training Programme"
    ]
  },
  {
    "objectID": "dstp.html#finding-communities-of-practice",
    "href": "dstp.html#finding-communities-of-practice",
    "title": "Start your own local DS Training Programme",
    "section": "Finding Communities of Practice",
    "text": "Finding Communities of Practice\nThe Digital Research Team at the British Library has been providing training to staff for over a decade through our bespoke British Library Digital Scholarship Training Programme.\nThe following are a few things we’ve learned along the way, and pointers for how to practically use the materials presented here on DS Essentials to start your own localised and sustainable digital scholarship and data science training programme at your own institutions!\n\nFind your people\nGet a small group of willing colleagues at your institution together and set up a way for them to communicate regularly, preferably asynchronously/remotely. We use a corporate wide MS Teams channel for this but you could also set up things like a slack channel or even a whatsapp channel. Focus on your purpose of bringing people together, think about the messaging and keep it light, “learn new stuff together that can help make your job easier” usually suffices! Try not to be too targeted, cast the net wide as people of all interests/academic disciplines/job profiles, abilities and backgrounds will undoubtedly have something to contribute: digital scholarship and data science is a collaborative affair and your group will be all the better for its diversity.\n\n\nIdentify shared needs\nWhat are problems colleagues at your institution are facing (cataloguing backlogs? etc.), and what computational methods might help them to solve these? By framing digital scholarship/data science skill training as an investment that can be a helpful tool for colleagues to resolve long standing issues you will find a more willing audience for your efforts. Quick wins in the digital realm (for instance in learning a tool like Open Refine to normalise and analyse catalogue records) can often build confidence very quickly and open the door to trying out new technologies.\n\n\nGet Buy-in (if you need to!)\nIn some cases you may need buy-in from managers to allow staff time and space to dedicate to learning these new skills. It can be difficult to convince managers sometimes of the value of learning skills now which may take some years to truly embed or come to practical fruition. Digital Scholarship & Data Science Essentials contains loads of evidence to share with your management for why investing in digital scholarship and data science staff skills is key to sustainable digital transformation over time. Have a look at the Skills Competency Frameworks & Key Reports sections for the latest supporting research on this. Each Topic Guide also contains useful real-life applications of new technologies being put into action under the Relevance to the Library Sector (Case Studies/Use Cases). At the British Library we’ve started to capture individual staff digital transformation stories as well which help to demonstrate the tangible value to individuals and institutions.\n\n“The Digital Scholarship Training Programme has introduced me to new software, opened my eyes to digital opportunities, provided inspiration for me to improve, and helped me attain new skills” -Graham Jevon, British Library\n\nRead more about Graham Jevon’s digital transformation journey on the British Library Digital Scholarship blog or have a look at this series of videos we created to mark the 10th Anniversary of the British Library Digital Scholarship Training Programme in 2022.\n\n\n\nHow are you using your new skills in your own work?",
    "crumbs": [
      "TOPIC GUIDES",
      "Start your own local DS Training Programme"
    ]
  },
  {
    "objectID": "dstp.html#run-a-monthly-hack-yack",
    "href": "dstp.html#run-a-monthly-hack-yack",
    "title": "Start your own local DS Training Programme",
    "section": "Run a monthly Hack & Yack",
    "text": "Run a monthly Hack & Yack\nEstablishing a regular Hack & Yack style meeting is a really nice way to learn something new with other colleagues. At the British Library our Hack & Yack’s are once a month for two hours on a set day and time. It is a casual, hands-on session where colleagues from across all departments of the institution come together to understand a current topic or digital method and work through an online tutorial at everyone’s own pace but with support of colleagues.\nWe use it as an opportunity to explore new tools/techniques/applications relevant to digital research and keep our own skills up to speed. Note this is not a formal training session, we’re all learning together and come to the tutorials with a variety of experience/knowledge/skills.\nEach Hack & Yack usually starts with one person, which may or may not be the organiser, giving a high-level view of the topic of the day, and then sharing one or more tutorials that the group can try out, either stepping through one online activity together as a group or providing time for everyone to explore individually at their own pace and chat about how it’s going as they work through the steps. These sessions aren’t recorded so that attendees can be open and frank about their experience!\nWithin each of these Topic Guides is a Hands-on activity and other self-guided tutorial(s) section that would make a perfect start for your first Hack & Yacks!",
    "crumbs": [
      "TOPIC GUIDES",
      "Start your own local DS Training Programme"
    ]
  },
  {
    "objectID": "dstp.html#start-a-discussion-group",
    "href": "dstp.html#start-a-discussion-group",
    "title": "Start your own local DS Training Programme",
    "section": "Start a discussion group",
    "text": "Start a discussion group\nWhether you call it a ‘reading group’, a discussion group, a lunchtime series - the point is to provide regular opportunities for people to get together, and learn and support each other through discussion. You might set an article, blog post or chapter, a video or podcast.\nThings we’ve found useful:\nBegin each session with quick introductions - name and department, or name and another useful piece of information. Why? Hopefully you’ll have a range of folk and they mightn’t all have met before, and it means that everyone has spoken at least once right from the start.\nMake it ok for people not to have finished reading, watching or listening to the thing you’re discussing. You could do a show of hands to see who’s finished it or not finished it. Why? There’s something about ‘confessing’ that lets people ask questions without worrying that it was covered somewhere towards the end. It can also be useful to understand why people didn’t finish (unless they just ran out of time, which is highly relatable) - did the piece get complex, jargony, boring?\nEach Topic Guide has a Recommended Reading/Viewing section and you can also find some good starting points under Recommended Reading Lists.",
    "crumbs": [
      "TOPIC GUIDES",
      "Start your own local DS Training Programme"
    ]
  },
  {
    "objectID": "dstp.html#create-an-identity",
    "href": "dstp.html#create-an-identity",
    "title": "Start your own local DS Training Programme",
    "section": "Create an identity",
    "text": "Create an identity\nAfter your group of the willing has been running for awhile it’s useful to create an identify for yourselves. Perhaps you consider yourselves a network, or an interest group or maybe you’d like to start formalising your gatherings under a “training programme” moniker. Whatever you decide, it helps to bring in new folks when there is an established identity and even maybe a logo in advertisements.",
    "crumbs": [
      "TOPIC GUIDES",
      "Start your own local DS Training Programme"
    ]
  },
  {
    "objectID": "python.html",
    "href": "python.html",
    "title": "Python",
    "section": "",
    "text": "Python\nAll things Python :)"
  },
  {
    "objectID": "github.html",
    "href": "github.html",
    "title": "GitHub: How to navigate and contribute to Git-based projects",
    "section": "",
    "text": "GitHub is a collaborative software development platform. Like a kind of google docs for coders, it began as a tool for them to collaboratively work on software development projects, ie, allowing different coders to contribute to parts of an overall project, asynchronously and across teams and even international borders, keeping track of changes all the while to make sure the end result is one cohesive software.\nGitHub today however is used for many more different purposes by people in all different fields, not just software developers and software projects, to:\n\nrecord and share information on a collaborative project\nwork asynchronously and internationally\ntest and store scripts and technical documentation\nbuild a public website for a project\n\nGitHub allows people to collaboratively work on and share projects (called ‘repositories’) so that others can copy them, either to adapt or to contribute back to the original project. That’s because any ‘public’ repository of files on GitHub is accessible via the web. (Note that public repositories are created by default when you start a project, but it is also possible to make your repositories private if you like in the settings).\nRepositories may be filled with code, but they may also be filled with pages of text written in markdown and this markdown can be rendered by browsers as webpages. This very website you’re reading from right now is being hosted on GitHub!\nThis guide will help you to understand how to practically navigate and contribute to projects like this one hosted via GitHub, and will demystify some of the basic actions and jargon around using GitHub along the way.\n\n\nBefore we begin, it can be helpful to first grasp what Git, GitHub and GitHub Pages each are and how they relate to each other:\n\nGit is a distributed open source version control system. Version control allows you to track changes in a set of files. It does this by taking snapshots of repositories at each stage of development - in Git these snapshots are known as ‘commits’. In software development this means things can be tested and rolled back, and enables sharing of stages of development. Git can be used on its own but when used with GitHub has more potential for collaborative projects. You can download and install Git on your own machine. It runs in the command line or there are desktop GUIs available. Git for Humans (Alice Bartlett talk at UX Brighton 2016) is a nicely accessible introduction to the purpose and uses of Git.\nGitHub is a web-based software development platform. It has many of Git’s features and can host Git repositories but also provides a web interface and additional functionalities. You can view millions of repositories hosted there. Many are openly licensed, meaning you can freely copy (or fork) them, either to adapt for yourself or to contribute back to the original project. By default the files and folders in a repository you create are public, and with a little bit of extra code, a repository can also be turned into a more public-facing project website, blog or wiki using a feature called GitHub Pages.\nGitHub Pages is a feature within GitHub to turn any repository or project into a website. GitHub can also be used to host a site that has been created using other software packages. One example of such a software is RStudio, a visual editor for Quarto Markdown which is what we use for this DS Essentials project!\n\n\n\n\nA barrier to GitHub for beginners is that it has its own terminology for common tasks and actions. While off-putting at first, they do serve to outline core concepts of both Git and GitHub. When using Git in particular, these are important to understand as they relate to git commands such as fork, pull, commit, clone, or branch. There are many quick guides and cheat sheets to this terminology on the web which can be useful to use as a reference while familiarising yourself:\n\nGitHub Docs Glossary\nGit for Librarians Glossary\n\nIn the next section, we will demonstrate the actions behind these keywords as we walk through three types of ways librarians regularly interact with GitHub based projects:\n\nWriting an Issue\nContributing code/content to an existing project\nRe-using existing code/content for a new project",
    "crumbs": [
      "TOPIC GUIDES",
      "GitHub: How to navigate and contribute to Git-based projects"
    ]
  },
  {
    "objectID": "github.html#introduction",
    "href": "github.html#introduction",
    "title": "GitHub: How to navigate and contribute to Git-based projects",
    "section": "",
    "text": "GitHub is a collaborative software development platform. Like a kind of google docs for coders, it began as a tool for them to collaboratively work on software development projects, ie, allowing different coders to contribute to parts of an overall project, asynchronously and across teams and even international borders, keeping track of changes all the while to make sure the end result is one cohesive software.\nGitHub today however is used for many more different purposes by people in all different fields, not just software developers and software projects, to:\n\nrecord and share information on a collaborative project\nwork asynchronously and internationally\ntest and store scripts and technical documentation\nbuild a public website for a project\n\nGitHub allows people to collaboratively work on and share projects (called ‘repositories’) so that others can copy them, either to adapt or to contribute back to the original project. That’s because any ‘public’ repository of files on GitHub is accessible via the web. (Note that public repositories are created by default when you start a project, but it is also possible to make your repositories private if you like in the settings).\nRepositories may be filled with code, but they may also be filled with pages of text written in markdown and this markdown can be rendered by browsers as webpages. This very website you’re reading from right now is being hosted on GitHub!\nThis guide will help you to understand how to practically navigate and contribute to projects like this one hosted via GitHub, and will demystify some of the basic actions and jargon around using GitHub along the way.\n\n\nBefore we begin, it can be helpful to first grasp what Git, GitHub and GitHub Pages each are and how they relate to each other:\n\nGit is a distributed open source version control system. Version control allows you to track changes in a set of files. It does this by taking snapshots of repositories at each stage of development - in Git these snapshots are known as ‘commits’. In software development this means things can be tested and rolled back, and enables sharing of stages of development. Git can be used on its own but when used with GitHub has more potential for collaborative projects. You can download and install Git on your own machine. It runs in the command line or there are desktop GUIs available. Git for Humans (Alice Bartlett talk at UX Brighton 2016) is a nicely accessible introduction to the purpose and uses of Git.\nGitHub is a web-based software development platform. It has many of Git’s features and can host Git repositories but also provides a web interface and additional functionalities. You can view millions of repositories hosted there. Many are openly licensed, meaning you can freely copy (or fork) them, either to adapt for yourself or to contribute back to the original project. By default the files and folders in a repository you create are public, and with a little bit of extra code, a repository can also be turned into a more public-facing project website, blog or wiki using a feature called GitHub Pages.\nGitHub Pages is a feature within GitHub to turn any repository or project into a website. GitHub can also be used to host a site that has been created using other software packages. One example of such a software is RStudio, a visual editor for Quarto Markdown which is what we use for this DS Essentials project!\n\n\n\n\nA barrier to GitHub for beginners is that it has its own terminology for common tasks and actions. While off-putting at first, they do serve to outline core concepts of both Git and GitHub. When using Git in particular, these are important to understand as they relate to git commands such as fork, pull, commit, clone, or branch. There are many quick guides and cheat sheets to this terminology on the web which can be useful to use as a reference while familiarising yourself:\n\nGitHub Docs Glossary\nGit for Librarians Glossary\n\nIn the next section, we will demonstrate the actions behind these keywords as we walk through three types of ways librarians regularly interact with GitHub based projects:\n\nWriting an Issue\nContributing code/content to an existing project\nRe-using existing code/content for a new project",
    "crumbs": [
      "TOPIC GUIDES",
      "GitHub: How to navigate and contribute to Git-based projects"
    ]
  },
  {
    "objectID": "github.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "href": "github.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "title": "GitHub: How to navigate and contribute to Git-based projects",
    "section": "Relevance to the Library Sector (Case Studies/Use Cases)",
    "text": "Relevance to the Library Sector (Case Studies/Use Cases)\nBoth Git and GitHub have many potential applications for librarians and libraries. Library systems, digital collections and digital preservation are key areas where many resources and scripts are community-led and open source, made available via GitHub and other code repositories. For those working with open source platforms such as Omeka, a basic understanding of GitHub provides access to a host of plugins developed by user communities that can be cloned and applied to your local instance where you may not have resources to develop them yourself. In less technical fields of library work there also is the opportunity to use it to develop or share documentation of working groups and special projects. In all of these, there is the facility to raise an issue or fork a repository and make a pull request if you are looking to query or contribute to a project.\nHere are some examples of library activity on GitHub from Week one reading for “Git and GitHub for Librarians” course and Library Carpentry Library Carpentry: Introduction to Git: Summary and Setup, with some personal additions of our own:\n\nSharing documentation and code for library-related projects and platforms:\n\nLiving with Machines\nBritish Library Repositories\nOmeka exhibit platform and related plugins\nDigital projects of Library of Congress\nCollection Builder\n\nDistributing OCR’d text extracted from digitised materials for collections-as-data analysis [example] [example] [example]\nStoring scripts for executing metadata ingests and transformations [example, example, [example]\nArchiving the source texts of open educational resources [example]\nWebsites for library workshops, to share course material or sample datasets [example, example, example],\nCollaborating on and contributing to a project Digital Scholarship & Data Science Essentials for Library Professionals\n\nLet’s look more closely at some practical ways you can get started navigating GitHub and contributing and making use of GitHub based projects for your library work!\n\n1. Writing Issues\nIssues are a great tool in GitHub to let the people know that something is possibly broken or something new is needed in a project. They help everyone by providing a place for everyone to discuss the concerns raised by the issue and providing a way to manage a response. If you have ever raised a ticket with the helpdesk of your IT department, you will notice a lot of similarities with Issues.\n\n\nPreparing to raise an issue\nIssues are a human centred tool in GitHub, so it is up to everybody involved to get the best out of them. Before raising an issue, consider these steps:\n\nRead the documentation carefully to make sure what you are experiencing is not down to any misunderstandings about the functionality or content provided.\nHave a look through the previous issues to make sure that what you are experiencing has not been raised before. If it has then consider adding details to that ticket and clicking on “Subscribe” under Notifications to be kept up to date with any fixes or changes.\nYou can raise issues for a variety of reasons, not just faults. You can also ask for new functionality or make a suggestion. Be clear, if you can, on the type of request you are making as the project maintainers may have different processes for different request types.\nRemember that what is obvious to you might not be obvious to a project maintainer, so explain fully and be patient with those trying to address the issue.\n\n\n\nReporting Bugs\nRaising an issue is a great opportunity to help to get something fixed. Providing good quality and complete information can cut down the time it takes to resolve an issue. A good write up should contain these elements:\n\nA full description of what happened, including:\n\nAny error messages or codes\nWhere you were in the project (e.g. for a web application what page you were on)\nWhat you were trying to do\n\nWhat did you expect to happen? Including:\n\nWhat normally happens\nWhat should have happened\nIf the behaviour is new\n\nAny other relevant information: the project maintainer will be looking into possible causes of the issue you are experiencing, so extra information can help enormously. For example of a web application this might include:\n\nThe time of day the error occurred\nWhich browser you use\nIf you have experienced any similar errors with other sites\n\n\n\n\nRequesting new features\nIssues are not only for reporting bugs. They can be used for requesting new features or further support. In this case explain why it would make sense to add your new feature to the project. Think about who might be affected by your change, both in a positive and negative way. Lastly, consider having a go at the change yourself and submitting a pull request. If this is not possible explain why here.\n\n\nThe life of an issue\nOnce you submit an issue you will see that it will have the status of “Open”. Usually, the issue will then be assigned to a specific member of the project team to examine further. During this process you may see comments added discussing the issue and possible implementations, fixes or feedback. The issue may even have some labels or categories applied to it to help classify the issue type. You may be asked for more information or input to help resolve the issue.\nWhen work on the issue stops, it will be “closed”. In GitHub there are two types of issue close:\n\nClose as completed: This means the issue has been worked on and that work is complete. E.g. this might mean a bug has been fixed or a feature added.\nClose as not planned: This means that the project maintainer has chosen not to work on the issue. This can be for a variety of reasons such as:\n\nWon’t fix: Adding a fix for this feature is outside the current scope of the project, beyond its resources or deemed unnecessary.\nCan’t reproduce: In software, developers must usually reproduce the error in order to fix it. Sometimes this is not possible to do, this might happen for intermittent errors or errors caused by particular hardware configurations.\nDuplicate: The issue has been reported elsewhere. There will usually be a reference to where this is.\nStale: Sometimes issues stay in the system for a long time. This might be because the initial reporter has moved on and is unable to answer queries about it. In this case the issue will be removed.\n\n\n\nWith an issue, there is no expectation that you will provide a solution to the problem you are facing or the new functionality that you would like. At some point you might contribute a fix or something new to a project, maybe as a result of an Issue. When this happens you will raise a “pull request”. This is a proposal to make a group of changes to files in a git repository. A maintainer can then decide whether to accept the pull request and “merge” it with the project, reject it, or send it back for further work.\n\n\n\n2. Contributing content/code to an existing project\nAs you now know, GitHub hosts many open-licensed projects and by clicking the fork button, any GitHub user can instantaneously create their own fully independent copy of that project to work on without affecting the original. This copy or forked project can then be used to work out new features in a piece of software (or in our case, writing new content for a project website) that can eventually be merged back into the original project. Let’s walk through a simplified example using the example of contributing substantial edits to one of the pages of DS Essentials. Let’s say you’d like to write up a new use case on one of the Topic Guides. That process may look a little like this:\n\n1. Find the GitHub repository/source code behind the website\nOn the web version of DS Essentials, look for the GitHub logo in order to be taken to the GitHub repository behind it.\n\n\n\n2. Make your own copy of the project (repository) to work on\nOnce on the project GitHub page you can fork your own copy of the repository so that you have a full copy of the project in your own GitHub account. You will now be owner of this new version and can make edits and changes as you please to the files without it affecting the main project. Just remember that eventually if you want your contributions to be merged with the original project those changes will need to be reviewed and approved by that maintainer.\n\n\n\n3. Find the file you would like to change and make your edits\nNavigate to the file you would like to edit in your own copy of the DSEssentials project and click the pencil icon to edit. (Note that one way you’ll know you’re working in your own copy is by seeing your personal GitHub username ahead of the repository name). Let’s say the Topic Guide on AI & ML in Libraries Literacies needs an update. To find the right file in the directory you can do a search or look for a markdown file in the list which corresponds to the url on the website version and has the file extension .md. Note, because this website was built using Quarto, the file extension in this example is .qmd. For instance if ml-ai.html is the web version, you would look for ml-ai.qmd in the file directory on GitHub.\n\nClick on the little pencil icon to edit this file in markdown. Markdown is a simple system for marking sections of text that should be stylised in a certain way, e.g. made bold or appear in a list of bullet points. Markdown files have the file extension “md” and can be edited in GitHub or with a text editor like Notepad. One common file in GitHub repositories that you will find in the markdown format is the “README.md” file which usually covers the purpose of the repository and how to get up and running.\nMarkdown works by using certain text characters to indicate styles. For example, placing a “#” in front of a line will make it a first level header. Placing “##” before the line makes it a second level header. Putting an asterisk around a piece of text, like this “*my text”, will cause that text to be italicised as my text. You can see more markdown commands and experiment with it on the site Markdown Live Preview.\n\n\n4. Commit your changes\nWhenever you are working in a repository that you have forked, you are the Owner of this copy of the original project and can commit (save) any changes and edits you make to files directly to this copy of the project without needing any approval. Committing builds up a history of changes that you can roll back as needed along the way. Each time you commit you have an option of writing a comment as to what has changed which is a useful tool to use and habit to get into for going back in time if you need to reverse something.\n\n\n\n5. Contribute your changes back to the original/main project\nWhen you are finished with your changes and would like to share your new updated copy with the original project (in this example, incorporating your new text on Generative AI into the main DS Essentials Topic Guide on AI & ML in Libraries) this is when you will start a pull request. Navigate to the Pull Requests section of your forked project (repository) and click on New pull request to start that process.\n\nThis will take you to back to the original project you forked from, where you can then formally “create a pull request”. Once this has been made your pull request notifies the maintainers of the original project that you have made changes to their project that they may like to consider merging into theirs. Your pull request will show up under their project where you can discuss and review the changes you’re suggesting. Once the review has been completed and everyone is happy with the changes suggested the maintainer of the project will merge your pull request and you will have officially contributed!\n\n\n\n\n3. Re-using existing code/content for a new project\nLet’s say that instead of just contributing code/content to an existing project you want to make use of the whole project, such as a piece of open source software shared there. This is quite common for instance when looking to reuse software that someone has created and shared on GitHub. And it’s a similar process to the above although in this case you might want to clone the repository rather than fork it as cloning allows you to save the whole repository directly to your local machine, rather than within the GitHub platform itself in order to implement it. Developers will find this much more practical than working in GitHub as they go through the process of installing, editing, adapting the code as needed to implement it. See for instance the example mentioned earlier of a variety of open source Omeka plugins being available for install from the Omeka GitHub repository.",
    "crumbs": [
      "TOPIC GUIDES",
      "GitHub: How to navigate and contribute to Git-based projects"
    ]
  },
  {
    "objectID": "github.html#hands-on-activity-and-other-self-guided-tutorials",
    "href": "github.html#hands-on-activity-and-other-self-guided-tutorials",
    "title": "GitHub: How to navigate and contribute to Git-based projects",
    "section": "Hands-on activity and other self-guided tutorial(s)",
    "text": "Hands-on activity and other self-guided tutorial(s)\nLike many technologies, the best way to learn git or GitHub is to use it. Luckily there are lots of tutorials out there with ready-made exercises and walkthroughs if you don’t have a clear purpose or aim to start with. Depending on your learning style, there are written lesson plans like the Carpentries’ ones, or plenty of walkthrough videos covering everything from basic terminology to full workflow development. Many of these resources begin with a grounding in git, the locally-installed version control software. While not essential to using GitHub, this can be useful to gain a broader understanding of the workings of both git and GitHub and maybe make sense of some of their additional functionalities. There are also specific lessons on various topics such as developing a static website using just GitHub and GitHub pages.\nOur list below is not intended to be comprehensive but is a selection of what is out there and all have been used by library staff like ourselves to get to grips with Git!:\n\nLearn the basics\n\nThis official GitHub tutorial teaches you GitHub essentials like repositories, branches, commits, and pull requests.\nAnother great tutorial over on GitHub uses the Spoon-Knife project, a test repository that’s hosted on GitHub.com that lets you test the fork and pull request workflow.\nGit-for-librarians exercise on branching and one on forking\n\n\n\nMaking a website using GitHub\n\nMaking a website with GitHub & GitHub Pages (lesson plan with video)\nMaking a website with GitHub & Quarto / RStudio (video)\nProgramming Historian - Building a static website with Jekyll and GitHub Pages\nProgramming Historian - Running a collaborative research website and blog with GitHub Pages\n\n\n\nWriting in Markdown (tools to try)\n\nMarkdown Live Preview is a tiny web tool to preview Markdown formatted text.\nWord to MD is a useful tool for uploading word files and transforming it into markdown\n\nAs with most platforms, specific functions or tasks may change occasionally on GitHub. So you may find a lesson which refers to an old term or function that is no longer called what it used to be. GitHub documentation should provide up-to-date information on the current practice in most cases.",
    "crumbs": [
      "TOPIC GUIDES",
      "GitHub: How to navigate and contribute to Git-based projects"
    ]
  },
  {
    "objectID": "github.html#recommended-readingviewing",
    "href": "github.html#recommended-readingviewing",
    "title": "GitHub: How to navigate and contribute to Git-based projects",
    "section": "Recommended Reading/Viewing",
    "text": "Recommended Reading/Viewing\n\nLibrary Carpentry Git & Version Control / Software Carpentry\nPush, Pull, Fork: GitHub for Academics (hybridpedagogy.org)\nA Comparative Analysis of the Use of GitHub by Librarians and Non-Librarians\nA reading list for librarians learning about Git and GitHub\nWeek one reading for “Git and GitHub for Librarians” course.",
    "crumbs": [
      "TOPIC GUIDES",
      "GitHub: How to navigate and contribute to Git-based projects"
    ]
  },
  {
    "objectID": "github.html#finding-communities-of-practice",
    "href": "github.html#finding-communities-of-practice",
    "title": "GitHub: How to navigate and contribute to Git-based projects",
    "section": "Finding Communities of Practice",
    "text": "Finding Communities of Practice\nThe best way to understand GitHub is to have a play yourself and if you get into trouble we’ve found that asking questions over on the GitHub Community Hub is a great way to get connected with other users. You can also join networks like AI4LAM and ask questions of members of the very engaged and helpful community on their slack.",
    "crumbs": [
      "TOPIC GUIDES",
      "GitHub: How to navigate and contribute to Git-based projects"
    ]
  },
  {
    "objectID": "crowdsourcing.html",
    "href": "crowdsourcing.html",
    "title": "Crowdsourcing and Citizen Science in Cultural Heritage",
    "section": "",
    "text": "Crowdsourcing in cultural heritage is a method for enabling meaningful public participation in research or practical tasks based on cultural heritage collections or knowledge (adapted from Ridge et al 2021). In practical terms, a typical example involves asking people outside the institution to contribute effort via tasks such as transcribing, tagging, researching or sharing artefacts. Crowdsourcing projects tend to focus on creating enjoyable, inherently rewarding experiences that lead to high quality data with minimal risk of errors. This means that crowdsourcing platforms can also be a great way for staff to work with their own collections.\nFor example, you could ask locals to share their memories, stories or artefacts about your region, or you could work with the public to co-create an exhibition or collaborate with international experts on research tasks. Volunteers can follow their interests on specific topics, or encounter parts of a collection that are entirely new to them.\nSo perhaps more importantly than the data collected or enhanced, crowdsourcing in cultural heritage is a way of inviting people to spend time with collections and institutions that they might never encounter otherwise. For example, the Living with Machines project engaged over 5000 online volunteers on the citizen science platform, many of whom had no previous experience with library or humanities research, and no previous relationship with the British Library.\nWhile crowdsourcing in other fields might involve payment for tasks completed (for example, via Mechanical Turk), the rewards for contributing to crowdsourcing in cultural heritage are usually intrinsic or altruistic. Thinking of it as a form of online volunteering can be helpful - participants can help enhance collections metadata, research objects or stories, contribute their own knowledge and experience, etc, with opportunities to learn or socialise during the process. But unlike traditional volunteering, crowdsourcing isn’t limited to a venue’s location or hours of operation - online projects can be open to anyone, anywhere in the world, 24 hours a day.\nVolunteers are often motivated by their interest in a topic or source type (e.g. beautiful maps or interesting photographs), the challenge of completing a task well (e.g. deciphering old handwriting), developing their skills and knowledge (e.g. becoming more accurate as they practise palaeography, or learning more about a collection or research question). They often stay motivated because they get feedback from project teams, and gain a sense of purpose or community.\nIncreasingly, libraries might combine crowdsourcing with machine learning and AI tools, ideally by building workflows and systems that take care of lower-level tasks such as pre-selecting relevant records, distributing and verifying tasks, and quality checking and formatting the results, supporting innovation in creating enjoyable volunteer or staff experiences. For example, the ‘Ad or not’ task we created for Living with Machines relies on people’s ability to understand the purpose of short pieces of text; the results of this task become the ‘ground truth’ dataset for training an experimental machine learning model. This simple ‘yes or no’ format also meant that the task was available in the Zooniverse app, further increasing its reach.\n\n\n\nScreenshot of the Zooniverse task interface, with an historical newspaper image on the left, and options to label it ‘yes’ or ‘no’ in response to a question asking if it is an ad\n\n\nScreenshot of an early version of the ‘ad or not’ task on Zooniverse.\n\n\n‘Crowdsourcing’ is an awkward name, with implications of ‘outsourcing’ and anonymous crowds, but thus far it has the most traction and recognition. Other terms used for similar work include digital public participation, community-generated digital content (CGDC), online volunteering, and variations such as ‘niche-sourcing’ for small or invitation-only projects.\n‘Citizen science’ is another commonly used term with a lot of overlap with crowdsourcing. Citizen science projects might include natural history observations in the world (for example, recording wildlife, or monitoring water quality) or screen-based tasks such as counting penguins in photographs. With roots in a broader concept of ‘science’ (Wissenschaft) as knowledge or areas of study, ‘citizen science’ also includes citizen history, humanities (Geisteswissenschaften), social sciences and any other field that works with knowledge about the world.\n\n\n\nCrowdsourcing isn’t for everyone nor the answer for every need. For example, running a successful project draws on a range of skills, and may require collaboration across many departments in an institution. The development of machine learning / AI methods and increasingly sophisticated crowdsourcing platforms can reduce the amount of work required to gather source material, review and quality control contributions and process the resulting data, but you will still need the resources and inclination for reviewing and sharing progress reports, social interactions with volunteers, and responding to questions. It may take a few iterations to create tasks that produce useful data via tasks that will attract volunteers. If you don’t enjoy talking to volunteers, negotiating with colleagues and wrangling resources (or don’t have any resources to spare), it might not be right for you right now.\nIdeally, you would also be able to ensure that the source collections, desired data results and types of tasks available on your platform of choice are a good match by prototyping or piloting workflows before committing to a full project. That said, you don’t have to limit your project to the types of tasks you’ve seen before - you can invent new tasks and workflows, and work with new technologies to meet your needs. For example, the Living with Machines project invented a ‘close reading’ task that asked volunteers to discern the sense in which specific words were used, supported by computational linguistic analysis.",
    "crumbs": [
      "TOPIC GUIDES",
      "Crowdsourcing and Citizen Science in Cultural Heritage"
    ]
  },
  {
    "objectID": "crowdsourcing.html#introduction",
    "href": "crowdsourcing.html#introduction",
    "title": "Crowdsourcing and Citizen Science in Cultural Heritage",
    "section": "",
    "text": "Crowdsourcing in cultural heritage is a method for enabling meaningful public participation in research or practical tasks based on cultural heritage collections or knowledge (adapted from Ridge et al 2021). In practical terms, a typical example involves asking people outside the institution to contribute effort via tasks such as transcribing, tagging, researching or sharing artefacts. Crowdsourcing projects tend to focus on creating enjoyable, inherently rewarding experiences that lead to high quality data with minimal risk of errors. This means that crowdsourcing platforms can also be a great way for staff to work with their own collections.\nFor example, you could ask locals to share their memories, stories or artefacts about your region, or you could work with the public to co-create an exhibition or collaborate with international experts on research tasks. Volunteers can follow their interests on specific topics, or encounter parts of a collection that are entirely new to them.\nSo perhaps more importantly than the data collected or enhanced, crowdsourcing in cultural heritage is a way of inviting people to spend time with collections and institutions that they might never encounter otherwise. For example, the Living with Machines project engaged over 5000 online volunteers on the citizen science platform, many of whom had no previous experience with library or humanities research, and no previous relationship with the British Library.\nWhile crowdsourcing in other fields might involve payment for tasks completed (for example, via Mechanical Turk), the rewards for contributing to crowdsourcing in cultural heritage are usually intrinsic or altruistic. Thinking of it as a form of online volunteering can be helpful - participants can help enhance collections metadata, research objects or stories, contribute their own knowledge and experience, etc, with opportunities to learn or socialise during the process. But unlike traditional volunteering, crowdsourcing isn’t limited to a venue’s location or hours of operation - online projects can be open to anyone, anywhere in the world, 24 hours a day.\nVolunteers are often motivated by their interest in a topic or source type (e.g. beautiful maps or interesting photographs), the challenge of completing a task well (e.g. deciphering old handwriting), developing their skills and knowledge (e.g. becoming more accurate as they practise palaeography, or learning more about a collection or research question). They often stay motivated because they get feedback from project teams, and gain a sense of purpose or community.\nIncreasingly, libraries might combine crowdsourcing with machine learning and AI tools, ideally by building workflows and systems that take care of lower-level tasks such as pre-selecting relevant records, distributing and verifying tasks, and quality checking and formatting the results, supporting innovation in creating enjoyable volunteer or staff experiences. For example, the ‘Ad or not’ task we created for Living with Machines relies on people’s ability to understand the purpose of short pieces of text; the results of this task become the ‘ground truth’ dataset for training an experimental machine learning model. This simple ‘yes or no’ format also meant that the task was available in the Zooniverse app, further increasing its reach.\n\n\n\nScreenshot of the Zooniverse task interface, with an historical newspaper image on the left, and options to label it ‘yes’ or ‘no’ in response to a question asking if it is an ad\n\n\nScreenshot of an early version of the ‘ad or not’ task on Zooniverse.\n\n\n‘Crowdsourcing’ is an awkward name, with implications of ‘outsourcing’ and anonymous crowds, but thus far it has the most traction and recognition. Other terms used for similar work include digital public participation, community-generated digital content (CGDC), online volunteering, and variations such as ‘niche-sourcing’ for small or invitation-only projects.\n‘Citizen science’ is another commonly used term with a lot of overlap with crowdsourcing. Citizen science projects might include natural history observations in the world (for example, recording wildlife, or monitoring water quality) or screen-based tasks such as counting penguins in photographs. With roots in a broader concept of ‘science’ (Wissenschaft) as knowledge or areas of study, ‘citizen science’ also includes citizen history, humanities (Geisteswissenschaften), social sciences and any other field that works with knowledge about the world.\n\n\n\nCrowdsourcing isn’t for everyone nor the answer for every need. For example, running a successful project draws on a range of skills, and may require collaboration across many departments in an institution. The development of machine learning / AI methods and increasingly sophisticated crowdsourcing platforms can reduce the amount of work required to gather source material, review and quality control contributions and process the resulting data, but you will still need the resources and inclination for reviewing and sharing progress reports, social interactions with volunteers, and responding to questions. It may take a few iterations to create tasks that produce useful data via tasks that will attract volunteers. If you don’t enjoy talking to volunteers, negotiating with colleagues and wrangling resources (or don’t have any resources to spare), it might not be right for you right now.\nIdeally, you would also be able to ensure that the source collections, desired data results and types of tasks available on your platform of choice are a good match by prototyping or piloting workflows before committing to a full project. That said, you don’t have to limit your project to the types of tasks you’ve seen before - you can invent new tasks and workflows, and work with new technologies to meet your needs. For example, the Living with Machines project invented a ‘close reading’ task that asked volunteers to discern the sense in which specific words were used, supported by computational linguistic analysis.",
    "crumbs": [
      "TOPIC GUIDES",
      "Crowdsourcing and Citizen Science in Cultural Heritage"
    ]
  },
  {
    "objectID": "crowdsourcing.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "href": "crowdsourcing.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "title": "Crowdsourcing and Citizen Science in Cultural Heritage",
    "section": "Relevance to the Library Sector (Case Studies/Use Cases)",
    "text": "Relevance to the Library Sector (Case Studies/Use Cases)\nCultural heritage institutions can support citizen science projects that ask participants to make observations about the natural world. For example, community science projects at the UK’s Natural History Museum ask people to help investigate noise pollution and local pondlife.\nLibraries, archives and museums can ask volunteers to help create or enhance collection data by transcribing handwritten text, entering data from catalogue or specimen cards into databases, or adding tags or labels to describe images. For example, Smithsonian Digital Volunteers: Transcription Center.\nThey might also ask volunteers to research objects or record information from their personal knowledge. For example, photos on Flickr Commons have been tagged with locations, personal names and histories, and specialist object labels identified by people with local or historical knowledge about photographs.\nLibrary and other GLAM staff can initiate projects, help manage and run them, and check, process and ingest data from crowdsourcing projects. For example, the Library of Congress reviewed comments left on their Flickr Commons images, and updated some of their collections records with information provided by the public.\nLibraries can support projects run on national portals, such as Latvia’s iesaisties.lv. They can point language learners or people with local knowledge to projects in a range of languages and other national portals.",
    "crumbs": [
      "TOPIC GUIDES",
      "Crowdsourcing and Citizen Science in Cultural Heritage"
    ]
  },
  {
    "objectID": "crowdsourcing.html#hands-on-activity-and-other-self-guided-tutorials",
    "href": "crowdsourcing.html#hands-on-activity-and-other-self-guided-tutorials",
    "title": "Crowdsourcing and Citizen Science in Cultural Heritage",
    "section": "Hands-on activity and other self-guided tutorial(s)",
    "text": "Hands-on activity and other self-guided tutorial(s)\nThe best way to learn more about crowdsourcing is to try a range of different projects. This will help you understand participant motivations, get a sense of the importance of great text in getting you started, and think about how data might move between GLAM systems and crowdsourcing platforms.\nYou can find projects to try at:\n\nhttps://www.zooniverse.org/projects\nhttps://fromthepage.com/findaproject\nhttps://scistarter.org/\nhttps://transcription.si.edu/\nhttp://lesherbonautes.mnhn.fr/\n\nIf your organisation has records in Europeana, you might be able to devise crowdsourcing tasks for them on the CrowdHeritage site.",
    "crumbs": [
      "TOPIC GUIDES",
      "Crowdsourcing and Citizen Science in Cultural Heritage"
    ]
  },
  {
    "objectID": "crowdsourcing.html#recommended-readingviewing",
    "href": "crowdsourcing.html#recommended-readingviewing",
    "title": "Crowdsourcing and Citizen Science in Cultural Heritage",
    "section": "Recommended Reading/Viewing",
    "text": "Recommended Reading/Viewing\nIf you are interested in learning more about participating in, creating or using data from crowdsourcing projects, a recent comprehensive publication is the open access publication, T_he Collective Wisdom Handbook: Perspectives on Crowdsourcing in Cultural Heritage_.\nThe Collective Wisdom Handbook is designed to answer the most common questions that people have as they think about starting, maintaining and using data from a crowdsourcing or citizen science project. Topics covered include:\n\nWhat is crowdsourcing in cultural heritage?\nWhy work with crowdsourcing in cultural heritage?\nIdentifying, aligning, and enacting values in your project\nDesigning cultural heritage crowdsourcing projects\nUnderstanding and connecting to participant motivations\nAligning tasks, platforms, and goals\nChoosing tasks and workflows\nSupporting participants\nWorking with crowdsourced data\nManaging cultural heritage crowdsourcing projects\nConnecting with communities\nPlanning crowdsourcing events\nEvaluating your crowdsourcing project",
    "crumbs": [
      "TOPIC GUIDES",
      "Crowdsourcing and Citizen Science in Cultural Heritage"
    ]
  },
  {
    "objectID": "crowdsourcing.html#finding-communities-of-practice",
    "href": "crowdsourcing.html#finding-communities-of-practice",
    "title": "Crowdsourcing and Citizen Science in Cultural Heritage",
    "section": "Finding Communities of Practice",
    "text": "Finding Communities of Practice\nWhen you’re ready to think about creating crowdsourcing projects or working with crowdsourcing data it’s useful to reach out to existing communities of practice for support and feedback.\nThe LIBER Citizen Science Working Group is a community of practice open to all LIBER members. They are currently producing a guide for Citizen science in Research Libraries. Topics published to date include:\n\nSkills: Citizen Science skills development for staff, researchers, and the public\nInfrastructures: As being active in the development of infrastructure for researchers to carry out Citizen Science\n\nThe low-traffic JISCMail discussion list on crowdsourcing has many interested members and is a great way to connect with others who have an interest and experience in crowdsourcing in cultural heritage.",
    "crumbs": [
      "TOPIC GUIDES",
      "Crowdsourcing and Citizen Science in Cultural Heritage"
    ]
  },
  {
    "objectID": "openresearch.html",
    "href": "openresearch.html",
    "title": "Open Research (Open Science)",
    "section": "",
    "text": "Open Research - used interchangeably with Open Science - is an umbrella term that sets values and practises to make research easily discoverable, transparent, equitable, available and re-usable across all disciplines and across the entire research lifecycle. It aims to remove barriers to knowledge and make access as inclusive as possible.\nThe aim of Open Research is:\n\nTo promote a collaborative, sustainable and inclusive research culture\nTo incentivise innovation and creativity\nTo support reproducibility of research outputs (where relevant)\n\n\n\nUniversities and researchers are recognising that Open Research has benefits extending far beyond each individual institution:\n\nThe general public has free access to quality information that matters in their lives\nPractitioners and policy makers can put the findings of research into practice more quickly and easily\nPublic funds result in knowledge that can be shared as a public good\nEconomic benefits derive from reducing attrition between research and commercial applications\nStudents in a variety of context face no barriers to accessing materials that help them\nAccess to knowledge is more equitably distributed around the world\nFindings from research are more transparent and trustworthy\n\n\n\n\nIndividual researchers also benefit from sharing their research:\n\nMore visibility as outputs are not restricted by paywalls and other barriers\nGreater impact as more people read and apply their work\nMore credibility through making the process of research more transparent\nCompliance with funders’ requirements and career opportunities\n\nOpen research is more than just making research findings public. It’s a philosophy that encourages transparency, accessibility, and collaboration throughout the entire research process. This module focuses on the FAIR principles as an open research practice for improving confidence in research:\n\n\n\n\nFindable: Research data, software and publications should be easy to discover using clear and consistent identification methods.\nAccessible: Data, software and publications should be readily available to anyone with minimal barriers, often through open access repositories.\nInteroperable: Data should be presented in a standardised format that allows for seamless integration and analysis with other datasets.\nReusable: Data, software and publications should be accompanied by clear documentation and licensing, allowing others to understand and build upon them.\n\n\n\n\nFunders, institutions, research groups and individual researchers from around the world are actively working to overcome technical, cultural, ethical, legal and financial challenges to make open research the norm. This includes developing robust infrastructure, fostering a culture that values openness, ensuring ethical practices, clarifying legal frameworks, and establishing sustainable funding models.",
    "crumbs": [
      "TOPIC GUIDES",
      "Open Research (Open Science)"
    ]
  },
  {
    "objectID": "openresearch.html#introduction",
    "href": "openresearch.html#introduction",
    "title": "Open Research (Open Science)",
    "section": "",
    "text": "Open Research - used interchangeably with Open Science - is an umbrella term that sets values and practises to make research easily discoverable, transparent, equitable, available and re-usable across all disciplines and across the entire research lifecycle. It aims to remove barriers to knowledge and make access as inclusive as possible.\nThe aim of Open Research is:\n\nTo promote a collaborative, sustainable and inclusive research culture\nTo incentivise innovation and creativity\nTo support reproducibility of research outputs (where relevant)\n\n\n\nUniversities and researchers are recognising that Open Research has benefits extending far beyond each individual institution:\n\nThe general public has free access to quality information that matters in their lives\nPractitioners and policy makers can put the findings of research into practice more quickly and easily\nPublic funds result in knowledge that can be shared as a public good\nEconomic benefits derive from reducing attrition between research and commercial applications\nStudents in a variety of context face no barriers to accessing materials that help them\nAccess to knowledge is more equitably distributed around the world\nFindings from research are more transparent and trustworthy\n\n\n\n\nIndividual researchers also benefit from sharing their research:\n\nMore visibility as outputs are not restricted by paywalls and other barriers\nGreater impact as more people read and apply their work\nMore credibility through making the process of research more transparent\nCompliance with funders’ requirements and career opportunities\n\nOpen research is more than just making research findings public. It’s a philosophy that encourages transparency, accessibility, and collaboration throughout the entire research process. This module focuses on the FAIR principles as an open research practice for improving confidence in research:\n\n\n\n\nFindable: Research data, software and publications should be easy to discover using clear and consistent identification methods.\nAccessible: Data, software and publications should be readily available to anyone with minimal barriers, often through open access repositories.\nInteroperable: Data should be presented in a standardised format that allows for seamless integration and analysis with other datasets.\nReusable: Data, software and publications should be accompanied by clear documentation and licensing, allowing others to understand and build upon them.\n\n\n\n\nFunders, institutions, research groups and individual researchers from around the world are actively working to overcome technical, cultural, ethical, legal and financial challenges to make open research the norm. This includes developing robust infrastructure, fostering a culture that values openness, ensuring ethical practices, clarifying legal frameworks, and establishing sustainable funding models.",
    "crumbs": [
      "TOPIC GUIDES",
      "Open Research (Open Science)"
    ]
  },
  {
    "objectID": "openresearch.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "href": "openresearch.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "title": "Open Research (Open Science)",
    "section": "Relevance to the Library Sector (Case Studies/Use Cases)",
    "text": "Relevance to the Library Sector (Case Studies/Use Cases)\nThe role of libraries on Open Research has been discussed for a while and endorsed publicly by international organisations and stakeholders such as the European commission (European Commission, 2012) and OECD (OECD, 2015).\nOECD defines libraries as enablers “Libraries have adapted their role and are now active in the preservation, curation, publication and dissemination of digital scientific materials, in the form of publications, data and other research-related content. Libraries and repositories constitute the physical infrastructure that allows scientists to share use and reuse the outcome of their work, and they have been essential in the creation of the Open Science movement”\nThere is no ‘one size fits all’ way of adoption Open Research practices, but Libraries are contributing in the following ways:\n1. Advocating and raising awareness of Open Research\nOften, a lack of institutional support and funds can negatively affect researchers when they are publishing open research.\nLibrary staff have an important role in encouraging their institution to make open research a priority, and deliver practical support to their researchers.\n2. Managing or supporting the infrastructure\nLibraries are usually responsible to maintain and enhance the records deposited on the institutional or national repository.\nIt is important to make sure the platform you are using allows researchers to surface\n3. Training supporting researcher\nLibraries play an important role supporting researchers across the research life cycle as follow:\nPlanning a Research Project\n\nExplored Pre-registered studies and protocols\nUsing existing open datasets can inspire new research questions and applications.\nOpen Peer Review practices\nName your chosen data repository and outline your data management plans for during and after the project including file type\nDevelop a Research Data Management plan\n\nDuring the Research Project\n\nDevelop a pre-registration document (https://osf.io/preprints/osf/8v2n7)\nExplore the use of open source software and tools (UKRN Primer: Open Code and Software)\nHow to best document data collection process ( e.g. The Turing Way: A handbook for reproducible, ethical and collaborative research: open notebooks)\nUse of pre-prints as way to share preliminary results (seePreprints)\n\nAfter the end of the Project\n\nHow to sharer results in an open and suitable long-term format (e.g. UK Data Service: Recommended File Formats &Library of Congress Recommended Formats)\nHow to upload (anonymised if appropriate) research data to a trusted open access data repository\nHow to Publish research findings in open access journals and/or deposit them in open access repositories with a permissive reuse licence\n\n4. Finding innovative solutions to help your institution embrace open research publishing practices\nTo help researchers publish openly and share data more easily, you could work with them to understand their specific barriers. It could also be useful to collaborate with other faculties to understand if their researchers are facing the same challenges. Doing this could help find the right solutions for your researchers’ needs, and even expand their open research publishing options.\nOne way this could be approached is by creating institutional platforms, such as a repository capable of hosting (and making open) data sets and other materials. These would be useful resources to share across faculties, to drive open research at your institution.\nIt is important to remember there are a few limitations if you were to rely solely on repositories to support open research.\nThey are often only accessible to staff at the institution, so there is a lack of opportunity to share contents with external researchers and the public to get their insights.\nResearchers may rely on librarians to upload their research outputs to a repository, meaning an increased workload for librarians.\nMany repositories are lacking in uploads of articles, chapters and books, so librarians may need to seek an efficient institutional platform, to protect their workload.\nLibrary staff can also help their institutions to recognise, showcase, and reward high impact data sets which have been shared openly and reused by other researchers. Colleagues who work with bibliometrics can help develop their institution’s understanding of the impact of their research and shared data, especially if more outputs across the research lifecycle are being openly published. This activity can encourage open research practices and help institutions incentivise open practices.",
    "crumbs": [
      "TOPIC GUIDES",
      "Open Research (Open Science)"
    ]
  },
  {
    "objectID": "openresearch.html#hands-on-activity-and-other-self-guided-tutorials",
    "href": "openresearch.html#hands-on-activity-and-other-self-guided-tutorials",
    "title": "Open Research (Open Science)",
    "section": "Hands-on activity and other self-guided tutorial(s)",
    "text": "Hands-on activity and other self-guided tutorial(s)\nhttps://www.fosteropenscience.eu/resources\nhttps://carpentries-incubator.github.io/fair-bio-practice/02-os-introduction/index.html",
    "crumbs": [
      "TOPIC GUIDES",
      "Open Research (Open Science)"
    ]
  },
  {
    "objectID": "openresearch.html#recommended-readingviewing",
    "href": "openresearch.html#recommended-readingviewing",
    "title": "Open Research (Open Science)",
    "section": "Recommended Reading/Viewing",
    "text": "Recommended Reading/Viewing\n UNESCO Recommendation on Open Science (2021)\nUKRN resources https://www.ukrn.org/open-research-resources/ & UKRN resources on Open Science applied to each discipline https://www.ukrn.org/disciplines/\nThe Community Sourced Open Research glossary is a good place to start to find out more about the terminology connected to Open Research, which can be sometimes overwhelming and confusing:\nParsons, S., Azevedo, F., Elsherif, M. M., Guay, S., Shahim, O. N., Govaart, G. H., … & Aczel, B. (2022). A Community-Sourced Glossary of Open Scholarship Terms. Nature human behaviour, 6(3), 312-318. https://doi.org/10.1038/s41562-021-01269-4\nIf you prefer podcasts, I can recommend:\n\nEverything Hertz (in particular podcast 57 & 176) & Orion Open Science will give you a perspective or Open research from different fields and\nThe first few episodes of ReproducibilitiTea are an excellent introduction to Open research\n\nUKRN has also providing discipline specific case studies: UKRN case studies for different disciplines",
    "crumbs": [
      "TOPIC GUIDES",
      "Open Research (Open Science)"
    ]
  },
  {
    "objectID": "openresearch.html#finding-communities-of-practice",
    "href": "openresearch.html#finding-communities-of-practice",
    "title": "Open Research (Open Science)",
    "section": "Finding Communities of Practice",
    "text": "Finding Communities of Practice\nLearning about Open Research can be overwhelming at first, especially if you are new to it, I would suggest looking at the Open Research or Open Science strategy of your institution first. As it covers the entire research life cycle, you might find you might already know quite a lot about some areas!\nLIBER’s Open Access Working Group is also a great community to join as they are playing an important role in the Open Research Europe (ORE) Project - LIBER Europe and have many members well versed in this topic!",
    "crumbs": [
      "TOPIC GUIDES",
      "Open Research (Open Science)"
    ]
  },
  {
    "objectID": "training-platforms.html",
    "href": "training-platforms.html",
    "title": "TRAINING PLATFORMS",
    "section": "",
    "text": "TRAINING PLATFORMS\nWhen you’re ready to go further and have a better idea of the specific skills you need for a particular task, we can recommend having a good search through these excellent platforms which host or link to a great many in-depth training materials:\n\nDARIAH-Campus\nDARIAH is a pan-European infrastructure for arts and humanities scholars working with computational methods. It supports digital research as well as the teaching of digital research methods. Though not specific to the library professional context, tutorials here are useful for applying techniques to digital collections. https://campus.dariah.eu/\n\n\nThe Glam Workbench\nThe GLAM Workbench is the brainchild of Tim Sherratt, a historian, and is a collection of Jupyter notebooks to help you explore and use data from GLAM institutions (galleries, libraries, archives, and museums). It includes tools, tutorials, examples, hacks, and even some pre-harvested datasets. It’s aimed at researchers in the humanities but has useful tutorials for anyone interested in working with GLAM data. https://glam-workbench.net/\n\n\nIneo\nIneo is a project developed and maintained by CLARIAH that lets you search, browse, find and select digital resources for research in humanities and social sciences. At the end of 2024 it will offer access to thousands of tools, datasets, workflows, standards and learning material. It is a work in progress so do keep that in mind when browsing. https://www.ineo.tools/\n\n\nLibrary Carpentry\nLibrary Carpentry is an international volunteer community, under the Carpentries, focussed building software and data skills within library and information-related communities. The lessons here are meant to be taught as workshops led by a Carpentries certified instructor (for a fee) but you may find it useful to have a read through the content which is open and available to all. https://librarycarpentry.org/\n\n\nThe Programming Historian\nThe Programming Historian has been publishing peer-reviewed tutorials on digital tools and techniques for humanists since 2008 and though they’re generally aimed at academic researchers, staff at British Library have found them highly useful over the years in their own work! https://programminghistorian.org/en/\n\n\nSocial Sciences & Humanities Open Marketplace\nBuilt as part of the Social Sciences and Humanities Open Cloud project (SSHOC), the Social Sciences and Humanities Open Marketplace is a discovery portal which pools and contextualises resources for Social Sciences and Humanities research communities: tools, services, training materials, datasets, publications and workflows. The Marketplace highlights and showcases solutions and research practices for every step of the SSH research data life cycle. https://marketplace.sshopencloud.eu/search?order=score&categories=training-material"
  },
  {
    "objectID": "topicguides.html",
    "href": "topicguides.html",
    "title": "TOPIC GUIDES",
    "section": "",
    "text": "TOPIC GUIDES\nTopic Guides are the heart of Digital Scholarship and Data Science Essentials for Library Professionals. Written by LIBER professionals working in research libraries all across Europe, the aim of each guide is to provide a gentle and concise introduction to the key topics in this area today. The guides offer those with no prior knowledge, quick and curated guidance, from fellow library colleagues, to personally recommended hands-on tutorials, use-cases, articles, videos, networks and communities of practice to deepen learning.\nEach Topic Guide follows a fixed structure, in order to make it easier to quickly find the information you might need:\n\nIntroduction to the topic\nRelevance to the library sector (case studies/use cases)\nHands-on activities and other self-guided tutorial(s)\nRecommended reading & viewing\nFinding Communities of Practice\n\nThe guides are not presented, nor meant to be completed, in any particular order, rather, you are invited to jump in and out of individual topics as personal curiosity or practical need dictates.\nThe Topic Guide list in this first edition draws heavily on the existing skills framework and topics covered in the British Library’s Digital Scholarship Training Programme, as well as those recommended by attendees of a series of development workshops held with LIBER working groups throughout 2023.\nOur current wishlist for future editions in 2025/2026 includes but is not limited to topics such as:\n\nClimate Change and Sustainability\nCultural Competency & Ethics\nDemystifying Computational Environments for Digital Scholarship\nDigital Scholarship Project Management, Evaluation and Assessment\nDigital Storytelling\nFoundation models: When and why to use LLMs or SLMs\nWikimedia",
    "crumbs": [
      "TOPIC GUIDES",
      "**TOPIC GUIDES**"
    ]
  },
  {
    "objectID": "iiif.html",
    "href": "iiif.html",
    "title": "IIIF",
    "section": "",
    "text": "IIIF (pronounced “triple-eye-eff”) stands for the International Image Interoperability Framework. Quite a tongue twister that one, but it broadly represents two things:\n\na set of open standards for delivering high-quality, attributed digital objects online at scale.\nthe open, international community of software developers, libraries, researchers, educators, museums, universities, creative agencies, and more working together to develop and implement the IIIF APIs to make the above open standards happen.\n\n\n\nEver try to look at a large high-resolution digitised manuscript online only for it to take ages to load, and when it finally does you have no way to actually move around the image easily nor see any of the metadata or annotations related to it?\nOr maybe spent months on end negotiating the terms and methods around sending copies of a variety of differently sized individual images to another institution for them to host as part of collaborative project?\nIIIF brings a whole new efficiency to the way in which we in the cultural heritage sector go about sharing and making our digitised collections available online, while greatly expanding the functionality around the way users interact with them. It’s an open standard, collaboratively developed and maintained by a host of cultural heritage institutions around the world that defines a consistent method for the delivery of images and audio/visual files from servers to different environments on the Web where they can then be viewed and interacted with in many ways.\nIIIF basically specifies a way for browsers to display an image or audio/visual files in a way that enables much richer functionality on the Web:\n\nMakes it easier to display large images on the web in a way that is scalable (enabling deep zoom)\nAllows easy comparison between two objects, connecting and uniting materials across institutional boundaries\nDisplays structure and metadata and annotations with the digital collection item. (For a digitised manuscript for instance this might be page order and searchable text, for audio/visual materials, that means being able to deliver complex structures (such as several reels of film that make up a single movie) along with things like captions, transcriptions/translations, annotations, and more.)\n\n\n“At its simplest, IIIF uses APIs to load images quickly and zoom smoothly without additional loading time. But IIIF also allows you to do much more, including pulling IIIF-enabled images from different sites into viewers for comparison without downloading them (at full resolution), and enabling saving links to details of images or portions of A/V files for future reference. IIIF also allows you to use many open-source tools that help you to compare, annotate, transcribe, collaborate, and more. You can even gather multiple IIIF images together from across multiple archival collections and/or institutions to create projects or exhibits without advanced technical skills”. -From IIIF for Archives\n\nMaking your collections IIIF enabled makes it easier to share your content online in a consistent way, enabling portability across different IIIF enabled viewers. This means that rather than endlessly creating copies and different access versions of your images to send all over the world for different projects, they can stay on your same IIIF Image server, but be accessed and displayed by viewers hosted at institutions elsewhere in any fashion you require.\n\n\n\nThe IIIF community is made up of over 100 major cultural heritage organisations worldwide who have formally adopted it, including many of our very own LIBER members. It was started in 2011 as a collaboration between The British Library, Stanford University, the Bodleian Libraries (Oxford University), the Bibliothèque nationale de France, Nasjonalbiblioteket (National Library of Norway), Los Alamos National Laboratory Research Library, and Cornell University. It’s a really nice example of an open, grassroots but global community effort, backed by a consortium of leading cultural institutions, who have been working together to develop and implement this new capability for decades and solve their shared problems with delivering, managing, sharing, and working with their resources.\n\n\n\nIf you want the deep nitty gritty technical stuff around all the APIs and how they fit together there is quite a bit of implementation documentation on their website that goes into all this. But essentially, the basic set up behind making your own digitised collections “IIIF enabled”, as they say, looks a little something like this:\n\nSet-up a IIIF image server (you can choose one developed by the community, or there are IIIF-compatible image servers available from vendors or other web hosts), move your content there and implement the IIIF Image API to make those images and audio/video materials available from there.\nImplement the IIIF Presentation API which creates the all important IIIF Manifest files (also many open source or vendor products can help handle this bit too) for each of your objects. This Manifest file is really the prime unit in IIIF, it essentially combines and packages in json code, information about your images and structural data from your metadata source. It lists all the information that makes up your new IIIF enabled object, from how to display it to what information IIIF viewers should (and should not) display (such as structure or the order of pages, or even as minute as where an illustration is located within an image if you like). If you want to see an example of what one looks like this is a IIIF Manifest from the Bodleian Libraries at University of Oxford relating to this collection item. Each manifest has its own URL and that’s the bit you’ll use to do cool things with the object in different IIIF viewers, such as allowing a manuscript to be easily dragged and dropped into Mirador for instance for comparison with other IIIF enabled manuscripts.\nChoose one of the many IIIF enabled viewers for displaying your images and add it to your own collection site. Again, looking at that same collection item record above, note in the upper left hand-corner (see image below) there is an option to view in Mirador or Universal Viewer which are two different styles of IIIF viewer that afford different functionalities.\nConsider making your IIIF Manifests available publicly for download so users can work with them in all the interesting ways you’ve now enabled!",
    "crumbs": [
      "TOPIC GUIDES",
      "IIIF"
    ]
  },
  {
    "objectID": "iiif.html#introduction",
    "href": "iiif.html#introduction",
    "title": "IIIF",
    "section": "",
    "text": "IIIF (pronounced “triple-eye-eff”) stands for the International Image Interoperability Framework. Quite a tongue twister that one, but it broadly represents two things:\n\na set of open standards for delivering high-quality, attributed digital objects online at scale.\nthe open, international community of software developers, libraries, researchers, educators, museums, universities, creative agencies, and more working together to develop and implement the IIIF APIs to make the above open standards happen.\n\n\n\nEver try to look at a large high-resolution digitised manuscript online only for it to take ages to load, and when it finally does you have no way to actually move around the image easily nor see any of the metadata or annotations related to it?\nOr maybe spent months on end negotiating the terms and methods around sending copies of a variety of differently sized individual images to another institution for them to host as part of collaborative project?\nIIIF brings a whole new efficiency to the way in which we in the cultural heritage sector go about sharing and making our digitised collections available online, while greatly expanding the functionality around the way users interact with them. It’s an open standard, collaboratively developed and maintained by a host of cultural heritage institutions around the world that defines a consistent method for the delivery of images and audio/visual files from servers to different environments on the Web where they can then be viewed and interacted with in many ways.\nIIIF basically specifies a way for browsers to display an image or audio/visual files in a way that enables much richer functionality on the Web:\n\nMakes it easier to display large images on the web in a way that is scalable (enabling deep zoom)\nAllows easy comparison between two objects, connecting and uniting materials across institutional boundaries\nDisplays structure and metadata and annotations with the digital collection item. (For a digitised manuscript for instance this might be page order and searchable text, for audio/visual materials, that means being able to deliver complex structures (such as several reels of film that make up a single movie) along with things like captions, transcriptions/translations, annotations, and more.)\n\n\n“At its simplest, IIIF uses APIs to load images quickly and zoom smoothly without additional loading time. But IIIF also allows you to do much more, including pulling IIIF-enabled images from different sites into viewers for comparison without downloading them (at full resolution), and enabling saving links to details of images or portions of A/V files for future reference. IIIF also allows you to use many open-source tools that help you to compare, annotate, transcribe, collaborate, and more. You can even gather multiple IIIF images together from across multiple archival collections and/or institutions to create projects or exhibits without advanced technical skills”. -From IIIF for Archives\n\nMaking your collections IIIF enabled makes it easier to share your content online in a consistent way, enabling portability across different IIIF enabled viewers. This means that rather than endlessly creating copies and different access versions of your images to send all over the world for different projects, they can stay on your same IIIF Image server, but be accessed and displayed by viewers hosted at institutions elsewhere in any fashion you require.\n\n\n\nThe IIIF community is made up of over 100 major cultural heritage organisations worldwide who have formally adopted it, including many of our very own LIBER members. It was started in 2011 as a collaboration between The British Library, Stanford University, the Bodleian Libraries (Oxford University), the Bibliothèque nationale de France, Nasjonalbiblioteket (National Library of Norway), Los Alamos National Laboratory Research Library, and Cornell University. It’s a really nice example of an open, grassroots but global community effort, backed by a consortium of leading cultural institutions, who have been working together to develop and implement this new capability for decades and solve their shared problems with delivering, managing, sharing, and working with their resources.\n\n\n\nIf you want the deep nitty gritty technical stuff around all the APIs and how they fit together there is quite a bit of implementation documentation on their website that goes into all this. But essentially, the basic set up behind making your own digitised collections “IIIF enabled”, as they say, looks a little something like this:\n\nSet-up a IIIF image server (you can choose one developed by the community, or there are IIIF-compatible image servers available from vendors or other web hosts), move your content there and implement the IIIF Image API to make those images and audio/video materials available from there.\nImplement the IIIF Presentation API which creates the all important IIIF Manifest files (also many open source or vendor products can help handle this bit too) for each of your objects. This Manifest file is really the prime unit in IIIF, it essentially combines and packages in json code, information about your images and structural data from your metadata source. It lists all the information that makes up your new IIIF enabled object, from how to display it to what information IIIF viewers should (and should not) display (such as structure or the order of pages, or even as minute as where an illustration is located within an image if you like). If you want to see an example of what one looks like this is a IIIF Manifest from the Bodleian Libraries at University of Oxford relating to this collection item. Each manifest has its own URL and that’s the bit you’ll use to do cool things with the object in different IIIF viewers, such as allowing a manuscript to be easily dragged and dropped into Mirador for instance for comparison with other IIIF enabled manuscripts.\nChoose one of the many IIIF enabled viewers for displaying your images and add it to your own collection site. Again, looking at that same collection item record above, note in the upper left hand-corner (see image below) there is an option to view in Mirador or Universal Viewer which are two different styles of IIIF viewer that afford different functionalities.\nConsider making your IIIF Manifests available publicly for download so users can work with them in all the interesting ways you’ve now enabled!",
    "crumbs": [
      "TOPIC GUIDES",
      "IIIF"
    ]
  },
  {
    "objectID": "iiif.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "href": "iiif.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "title": "IIIF",
    "section": "Relevance to the Library Sector (Case Studies/Use Cases)",
    "text": "Relevance to the Library Sector (Case Studies/Use Cases)\nIIIF was initiated by a bunch of libraries and cultural heritage collections holders and it shows! It was proposed in late 2011 as a collaboration between The British Library, Stanford University, the Bodleian Libraries (Oxford University), the Bibliothèque nationale de France, Nasjonalbiblioteket (National Library of Norway), Los Alamos National Laboratory Research Library, and Cornell University. The intention of the consortium has always been to combine resource and effort in building viewers that reflected the way we wanted our digital collections to be displayed online, rather than everyone still spending time and resource making our own custom viewers and building our own content silos. It’s brought a huge amount of efficiency too in the way that we share images with each other and researchers. It’s changed the way collaborative projects are undertaken where endless metadata mapping exercises, contract negotiations around re-use and hosting, and the copying and shipping of digitised materials on external hard drives were the norm.\nThere are quite a number of use cases and case studies available on the IIIF Demos page but let’s have a quick look at three real life (and canonical) examples of IIIF in action.\n\nDeep Zoom and Annotations\nThe example here is of the Ōmi Kuni-ezu 近江國絵圖 Japanese Tax map created in 1837. It’s meant to be read in the round by someone standing in the middle–you can see the scale when this zooms out– the map is eleven by seventeen FEET, and the person standing next to it, Wayne who works in the library at Stanford, is six feet four inches tall. This image is a composite of 158 individual images with a file size of 1.27Gb. IIIF allows just enough of an image to be delivered to a viewer–going from a whole image to just the part that they are zooming in on. Without IIIF, an end user might have to download an extremely large file, but using IIIF provides a smooth and easy viewing experience.\n\nHave a play and view this image in their Universal viewer here\n\n\nVirtual Reconstruction\nThe virtual reconstruction of this damaged manuscript from Châteauroux in France (Grandes Chroniques de France, ca. 1460) is probably one of the most well-known and best examples of the power of IIIF to support this use case (and my own personal favourite!). At some point in the manuscripts history, fourteen of its illuminations were cut out. These illuminations eventually ended up at the Bibliothèque nationale de France in the 19th century and were digitised individually. In the demo you see the reuniting of the miniatures with the full manuscript as IIIF allows a virtual repositioning of the cut out decorations with the text, virtually reconstructing the manuscript online using the Mirador Viewer so it reflects its original state.\n\nI highly recommend having a play around with the Mirador Viewer: Châteauroux demo.",
    "crumbs": [
      "TOPIC GUIDES",
      "IIIF"
    ]
  },
  {
    "objectID": "iiif.html#hands-on-activity-and-other-self-guided-tutorials",
    "href": "iiif.html#hands-on-activity-and-other-self-guided-tutorials",
    "title": "IIIF",
    "section": "Hands-on activity and other self-guided tutorial(s)",
    "text": "Hands-on activity and other self-guided tutorial(s)\nThe following tutorials are two of my favourite recommendations for colleagues interested in having a play with IIIF manifests yourself and in the process gaining a practical understanding of how they work, and the benefits!\n\nIIIF Online Workshops The community itself has created a number of excellent and free self-paced tutorials and though they host live online workshops for a fee, these are recorded and available and useful for newcomers for free afterwards. In fact staff at British Library have walked through these self-guided resources online quite often with great success. There is also the opportunity to hire a IIIF Trainer to come to deliver live bespoke training directly to your institution (for a fee), which we have also partaken in!\nWorking with IIIF images in education, communication and research This is a self-guided workshop available online in Dutch and English and has some excellent exercises to get you familiar with finding IIIF manifests in catalogues and importing them into different viewers. I highly recommend making some time (they recommend 120 minutes) to read through this and try out some of the exercises.",
    "crumbs": [
      "TOPIC GUIDES",
      "IIIF"
    ]
  },
  {
    "objectID": "iiif.html#recommended-readingviewing",
    "href": "iiif.html#recommended-readingviewing",
    "title": "IIIF",
    "section": "Recommended Reading/Viewing",
    "text": "Recommended Reading/Viewing\nThere is a useful collection of articles and data related to IIIF being compiled by the community on Zenodo\nThe IIIF organisation has also created a number of useful resources alongside their training materials such as How It Works, a plain-language guide to how the IIIF API’s work and a glossary of “Key concepts you’ll encounter when working with IIIF”.\nIt’s worth having a look at how other institutions have provided IIIF Resources.\nThere is also a massive list of learning resources, Awesome IIIF, compiled and maintained by the IIIF Community if you are looking to take your knowledge a bit further and dig deeper into some of the exciting implementations of IIIF.",
    "crumbs": [
      "TOPIC GUIDES",
      "IIIF"
    ]
  },
  {
    "objectID": "iiif.html#finding-communities-of-practice",
    "href": "iiif.html#finding-communities-of-practice",
    "title": "IIIF",
    "section": "Finding Communities of Practice",
    "text": "Finding Communities of Practice\nLearning about IIIF can be overwhelming at first, especially if you’re not a programmer, but the IIIF Community is a very supportive and engaged one and has created a number of ways to get involved and find support and help.\nI recommend checking out their community page IIIF Community to find details of their next open community calls, or to join their Slack Channel where you can post questions and join the discussion with other users.",
    "crumbs": [
      "TOPIC GUIDES",
      "IIIF"
    ]
  },
  {
    "objectID": "licensing.html",
    "href": "licensing.html",
    "title": "LICENSING & RE-USE",
    "section": "",
    "text": "The project team behind this resource is committed to upholding the values of open source and open science and are keen for the Topic Guides and other content provided here to be used widely and adapted where necessary for local contexts. To enable this, Digital Scholarship & Data Science Essentials for Library Professionals, including all Topic Guides published here, are contributed under a CC BY 4.0 Deed | Attribution 4.0 International | Creative Commons license.\nThis means you are free to:\nShare — copy and redistribute the material in any medium or format for any purpose, even commercially.\nAdapt — remix, transform, and build upon the material for any purpose, even commercially.\nThe licensor cannot revoke these freedoms as long as you follow the license terms.\nUnder the following terms:\nAttribution — You must give appropriate credit , provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.\nNo additional restrictions — You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.\n\n\nSuggested citations are written in APA (American Psychological Association) citation style for Journal Articles and are given on each individual guide:\nMcGregor, Nora, “IIIF,” Digital Scholarship & Data Science Essentials for Library Professionals (2024), [DOI link]\nTo cite the full resource:\nMcGregor, N., Verhaar, P., Moopen, N., Double, J., Irollo, A., & Kiraly, P. (Eds.). (2024, March 12). Digital Scholarship & Data Science Essentials for Library Professionals. https://libereurope.github.io/ds-essentials"
  },
  {
    "objectID": "licensing.html#citing-this-resource",
    "href": "licensing.html#citing-this-resource",
    "title": "LICENSING & RE-USE",
    "section": "",
    "text": "Suggested citations are written in APA (American Psychological Association) citation style for Journal Articles and are given on each individual guide:\nMcGregor, Nora, “IIIF,” Digital Scholarship & Data Science Essentials for Library Professionals (2024), [DOI link]\nTo cite the full resource:\nMcGregor, N., Verhaar, P., Moopen, N., Double, J., Irollo, A., & Kiraly, P. (Eds.). (2024, March 12). Digital Scholarship & Data Science Essentials for Library Professionals. https://libereurope.github.io/ds-essentials"
  },
  {
    "objectID": "ai-ml.html",
    "href": "ai-ml.html",
    "title": "AI & Machine Learning in Libraries",
    "section": "",
    "text": "AI is mentioned absolutely everywhere these days, first it was just in movies, the news, but now it’s cropping up in our library meetings and strategies and funding calls, but what does it really mean, particularly in a library context? Let’s try to get to the bottom of this!\nTo do that I always like to start off with a bit of basic jargon busting.\nArtificial Intelligence (AI) is actually a really broad field of computer science (and an umbrella term) that refers to the research and development of systems and machines capable of doing tasks that typically require human intelligence to perform, such as\n\nReasoning\nProblem-solving\nLearning\nPerception\n\nSometimes folks may speak of or refer to AI as systems and machines that actually have true intelligence, and though today’s AI systems are shockingly convincing in how well they perform, what we’re seeing today are just very advanced machine learning algorithms and models performing specific and discrete functions extremely well! We’re a long way off (if ever) from machines having sentience (or, Artificial General Intelligence (AGI)/Strong AI) so don’t worry!\nYou might also sometimes hear people talk about Traditional AI vs Generative AI. Traditional AI refers to using machine learning based systems for doing tasks like classifying data (e.g., assigning labels to images, automatically transcribing handwritten texts, or identifying genre of digitised texts). This is the type of AI we make a whole lot of use of in the library world. Generative AI on the other hand refers broadly to systems whose primary function is to generate new content (e.g., conversation, books, art), often in response to text or image prompts. This is where conversation generating AI systems like ChatGPT (Generative Pre-trained Transformer) fall under for example and we’re only just now exploring the potential applications for these new powerful Generative AI systems in library work.\nWhenever AI is being discussed you may often hear the term Machine Learning (ML) mentioned, and sometimes they’re used interchangeably which can be confusing!\nMachine Learning (ML) is more specifically a main subfield of AI and core technology underpinning the other subfields of AI, that focuses on the development of algorithms and models that allow computers to learn patterns and relationships from data and make predictions on new data. Instead of being explicitly programmed for specific tasks, ML algorithms use data to learn and improve their performance over time.\n\nThe primary task of Machine Learning is prediction.\n\nAn algorithm is a plan, a set of step-by-step instructions, in order of operation, for solving a problem or performing a task. Making a sandwich is a classic example. “Get two pieces of bread…” If we want to tell a computer to do something, we have to write a computer program that will tell it, step-by-step, exactly what we want it to do and how we want it to do it.\nA machine learning algorithm is a special kind of algorithm designed to help computers learn from data. Instead of giving the computer explicit instructions for every task, we give it data and let it find patterns, relationships, and trends in that data in order to make decisions or predictions on new data on its own.\n“Training a model” is the process of teaching a machine learning algorithm to make predictions or decisions based on data. It’s important to remember that data is the lifeblood of ML and the model is only as good as the type and quality of data you give it.\nA machine learning model represents what was learned by a machine learning algorithm and this is what can be used to make predictions on new data without needing explicit instructions. The model contains the rules, numbers, and any other algorithm-specific data structures required to make predictions on new data. If it doesn’t work very well, you can go back and give the algorithm more data or tweak its parameters to create a new better model.\n\nHere’s a super simplistic example of this type of process in action:  Let’s say I have thousands of images of handwritten manuscript pages digitised from our library collection and ready to go online. The problem is, I want to make them all text searchable as well, but to transcribe these all by hand would take me well into my retirement and I have other things to be getting on with. I would like to train a machine learning model to help me automatically recognise the handwritten text in this collection. I would first need to somehow show my machine learning algorithm examples of a correct result so that it could start to recognise the pattern of that (in this case, text on a page). To do this I can show it images with associated text annotations which have been transcribed perfectly by me, the more, the better! Once the algorithm has learned a bit about what a correct page of handwritten text looks like, a model is then created which contains all the rules and parameters and calculations ready for the particular task I have set it of predicting what handwritten text is on pages of this particular collection that it’s never seen before!\n\nWe actually do quite alot of the above at the British Library, you can read more about the actual process and results here, and I’ll cover a bit more of this in the next section!\n Snapshot of an interface from Transkribus software used to create data to train a model to recognise handwritten arabic manuscript pages from a British Library collection.\n\n\nRemembering that Machine Learning is about prediction, which of the following do you think would require ML?\n\nCounting the number of people in a museum using information from entry and exit barriers.\nA search system that looks for images similar to a user submitted sketch.\nA system that recommends library books based on what other users have ordered.\nA queueing system that spreads people evenly between 5 ticket booths\nA program which extracts names from documents by finding all capitalised words and checking them against a list of known names\nA system which turns digitised handwritten documents into searchable text\nA robot that cleans the vases in a museum without bumping into them or breaking them\n\nIf you answered 2, 3, 6 & 7 you are correct! The others could all be most easily executed with a straightforward algorithm, programmed using a simple set of easily defined rules, rather than requiring prediction.",
    "crumbs": [
      "TOPIC GUIDES",
      "AI & Machine Learning in Libraries"
    ]
  },
  {
    "objectID": "ai-ml.html#introduction",
    "href": "ai-ml.html#introduction",
    "title": "AI & Machine Learning in Libraries",
    "section": "",
    "text": "AI is mentioned absolutely everywhere these days, first it was just in movies, the news, but now it’s cropping up in our library meetings and strategies and funding calls, but what does it really mean, particularly in a library context? Let’s try to get to the bottom of this!\nTo do that I always like to start off with a bit of basic jargon busting.\nArtificial Intelligence (AI) is actually a really broad field of computer science (and an umbrella term) that refers to the research and development of systems and machines capable of doing tasks that typically require human intelligence to perform, such as\n\nReasoning\nProblem-solving\nLearning\nPerception\n\nSometimes folks may speak of or refer to AI as systems and machines that actually have true intelligence, and though today’s AI systems are shockingly convincing in how well they perform, what we’re seeing today are just very advanced machine learning algorithms and models performing specific and discrete functions extremely well! We’re a long way off (if ever) from machines having sentience (or, Artificial General Intelligence (AGI)/Strong AI) so don’t worry!\nYou might also sometimes hear people talk about Traditional AI vs Generative AI. Traditional AI refers to using machine learning based systems for doing tasks like classifying data (e.g., assigning labels to images, automatically transcribing handwritten texts, or identifying genre of digitised texts). This is the type of AI we make a whole lot of use of in the library world. Generative AI on the other hand refers broadly to systems whose primary function is to generate new content (e.g., conversation, books, art), often in response to text or image prompts. This is where conversation generating AI systems like ChatGPT (Generative Pre-trained Transformer) fall under for example and we’re only just now exploring the potential applications for these new powerful Generative AI systems in library work.\nWhenever AI is being discussed you may often hear the term Machine Learning (ML) mentioned, and sometimes they’re used interchangeably which can be confusing!\nMachine Learning (ML) is more specifically a main subfield of AI and core technology underpinning the other subfields of AI, that focuses on the development of algorithms and models that allow computers to learn patterns and relationships from data and make predictions on new data. Instead of being explicitly programmed for specific tasks, ML algorithms use data to learn and improve their performance over time.\n\nThe primary task of Machine Learning is prediction.\n\nAn algorithm is a plan, a set of step-by-step instructions, in order of operation, for solving a problem or performing a task. Making a sandwich is a classic example. “Get two pieces of bread…” If we want to tell a computer to do something, we have to write a computer program that will tell it, step-by-step, exactly what we want it to do and how we want it to do it.\nA machine learning algorithm is a special kind of algorithm designed to help computers learn from data. Instead of giving the computer explicit instructions for every task, we give it data and let it find patterns, relationships, and trends in that data in order to make decisions or predictions on new data on its own.\n“Training a model” is the process of teaching a machine learning algorithm to make predictions or decisions based on data. It’s important to remember that data is the lifeblood of ML and the model is only as good as the type and quality of data you give it.\nA machine learning model represents what was learned by a machine learning algorithm and this is what can be used to make predictions on new data without needing explicit instructions. The model contains the rules, numbers, and any other algorithm-specific data structures required to make predictions on new data. If it doesn’t work very well, you can go back and give the algorithm more data or tweak its parameters to create a new better model.\n\nHere’s a super simplistic example of this type of process in action:  Let’s say I have thousands of images of handwritten manuscript pages digitised from our library collection and ready to go online. The problem is, I want to make them all text searchable as well, but to transcribe these all by hand would take me well into my retirement and I have other things to be getting on with. I would like to train a machine learning model to help me automatically recognise the handwritten text in this collection. I would first need to somehow show my machine learning algorithm examples of a correct result so that it could start to recognise the pattern of that (in this case, text on a page). To do this I can show it images with associated text annotations which have been transcribed perfectly by me, the more, the better! Once the algorithm has learned a bit about what a correct page of handwritten text looks like, a model is then created which contains all the rules and parameters and calculations ready for the particular task I have set it of predicting what handwritten text is on pages of this particular collection that it’s never seen before!\n\nWe actually do quite alot of the above at the British Library, you can read more about the actual process and results here, and I’ll cover a bit more of this in the next section!\n Snapshot of an interface from Transkribus software used to create data to train a model to recognise handwritten arabic manuscript pages from a British Library collection.\n\n\nRemembering that Machine Learning is about prediction, which of the following do you think would require ML?\n\nCounting the number of people in a museum using information from entry and exit barriers.\nA search system that looks for images similar to a user submitted sketch.\nA system that recommends library books based on what other users have ordered.\nA queueing system that spreads people evenly between 5 ticket booths\nA program which extracts names from documents by finding all capitalised words and checking them against a list of known names\nA system which turns digitised handwritten documents into searchable text\nA robot that cleans the vases in a museum without bumping into them or breaking them\n\nIf you answered 2, 3, 6 & 7 you are correct! The others could all be most easily executed with a straightforward algorithm, programmed using a simple set of easily defined rules, rather than requiring prediction.",
    "crumbs": [
      "TOPIC GUIDES",
      "AI & Machine Learning in Libraries"
    ]
  },
  {
    "objectID": "ai-ml.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "href": "ai-ml.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "title": "AI & Machine Learning in Libraries",
    "section": "Relevance to the Library Sector (Case Studies/Use Cases)",
    "text": "Relevance to the Library Sector (Case Studies/Use Cases)\nAs you now know, machine learning algorithms and models underpin all the other subfields of AI and there are a LOT of subfields of AI depending on who you talk to! In this guide though we’ll focus our attention on just these two particular AI research areas to give you a general sense of how machine learning is practically applied in the library context today:\n\nNatural Language Processing (NLP): which is concerned with making AI systems more capable of natural and effective interaction with humans (text and speech)\nComputer Vision (CV): which is concerned with enabling machines to interpret and make decisions based on visual data from the world.\n\nFor a really great overview of a wider range of AI use cases in Libraries I recommend having a read of Section 3: Library Applications in Cox A & Mazumdar’s Defining artificial intelligence for librarians (2022) from 2022 which covers back-end operations and library services for users.\nLet’s have a look at some NLP and Computervision use cases in a library setting:\n\nNatural Language Processing (NLP)\nNLP involves the development of a wide range of algorithms, models, and systems for analysing, understanding and extracting meaningful information from textual and speech data representing human language. We can use NLP for things like:\n\nSubject indexing to enhance library catalogue search\nNamed Entity Recognition (NER) is a text analysis process within NLP that helps turn unstructured text into structured text. A sentence or a chunk of text is parsed through to find entities that can be put under categories like names, organisations, locations, quantities, monetary values, percentages, etc.\n\nIn the library world it can be used as part of a process to understand what subjects (people, places, concepts) are contained within a digitised text and help us enhance our catalogue records for items or search functionality. There is a very nicely outlined use case here of how the United States Holocaust Memorial Museum used NER to automatically extract person names and location from Oral History Transcript to improve indexing and search in their catalogue.\n\n\nAutomatic Language Detection & Genre Classification\nThe British Library has used different machine learning techniques and experiments derived from the field of NLP to assign language codes and genre classification to catalogue records, in order to enhance resources described. In the first phase of the Automated Language Identification of Bibliographic Resources project, language codes were assigned to 1.15 million records with 99.7% confidence. The automated language identification tools developed will be used to contribute to future enhancement of over 4 million legacy records. The genre classification case study includes a nice description of machine learning as well as references to other use cases for metadata clean up.\n\n\nText & Conversation Generation\nLanguage models are a type of machine learning model designed to predict the likelihood of a sequence of text, which means that they can be set up to predict the most likely way to continue a conversation. A large language model (LLM), such as the models behind ChatGPT, are highly complex neural networks that have been exposed to an enormous amount of text from books, articles, websites, and more. They perform natural language processing tasks such as generating and classifying text, answering questions, and translating text and are the backbone of NLP today. On the other hand there are small language models (SML) too which, well, you guessed it, are much smaller, as in, they don’t need quite as much data and time to be trained. Whether or not to use either depends on your use case and motivations!\nThere are and have been for many years, large language models out there actually but ChatGPT has currently caught the popular imagination because of its publicly available interface and remarkable performance, so it’s worth spending a little time here unpacking just what ChatGPT is and its potential impact on library work.\nThe large language models behind ChatGPT have learned something about patterns in grammar and word meaning, including the way that meaning arises contextually across multiple sentences and multiple turns in a conversation. When you ask ChatGPT a question, you are presenting the model with new information it tries to make a prediction on, in this case, it tries to generate a response that matches the pattern of conversation.\nYou ask questions or give prompts to the model, and it provides responses in natural language, or rather, estimates what should come next in a conversation. When ChatGPT gives a response, it isn’t actually looking up information and then composing that information into a response; it’s just making an estimation of a response based on patterns it has seen. So, when you ask it factual questions, especially ones with common answers or phrases, it might give you an answer that sounds right but remember this is because it’s mimicking what it has seen in its training data.\nLibrarians are still investigating use cases for this new Generative AI applications, but for now at least, ChatGPT is certainly useful as a personal writing assistant or tool to help give you ideas for\n\ncreating a title for a new exhibition\ncreating exhibition labels\noutlining a basic structure for an information literacy workshop\ncreating a blog post on a topic for which you are very familiar\nhelping you reword something for different audiences\nwriting a funding proposal!\n\nIt’s also good to get in the habit of trying out and being aware of how these particular models work as more and more library users will be using this technology too, and may not know quite have a clear understanding of what’s behind the responses generated by them. We’ve seen librarians having to answer queries about citations that have been made up by ChatGPT, article references which sound very much like they exist, but have just been hallucinated by the model!\n\n\n\nComputer Vision (CV) use cases\nWe can use computer vision to train models to automatically analyse and understand useful information from images and videos.\nIn the library world we can use this to label millions of images with descriptive metadata (“this is a picture of a cat”), or, as we see below, a model can be trained to classify this image as a newspaper based on objects identified in the layout (for example, a nameplate for the newspaper, a headline, photographs, and illustrations and so on). The model learns how to identify that this is the NYT based on learning from other newspaper images it’s seen (for example, if given NY Tribune, NY Times, and NY Post images, it can distinguish between the various titles).\n\n\n\nPutting it altogether: ML + CV + NLP\nOne of the state of the art applications of machine learning seen in cultural heritage at the moment is Handwritten Text Recognition (HTR) which we had a look at earlier briefly in our simple example of training a model. The idea with HTR is to convert digitised handwritten documents into searchable and machine readable text. To achieve this HTR actually uses a combination of Computer Vision (CV) and Natural Language Processing (NLP).\nSince handwriting can be tricky and ambiguous you might have a Computer Vision model try to identify possible letters from the shapes, and another to work out what the most likely word is from those shapes. But let’s imagine that there’s a smudge on the page, and the letters and maybe even whole words are completely illegible. In that case you might turn to your NLP language models which look at sentence level predictions, taking into account words in the whole line of text the model uses that context to work out what words are most likely missing in those smudged spots!\nSometimes a model trained for a particular task (in the case of this HTR example, identifying a particular handwriting style) can be applied to similar content (other handwriting styles) with very good results. Transkribus has Public AI Models (transkribus.org) that have been created by users of the system and are then shared and can be reused by anyone.",
    "crumbs": [
      "TOPIC GUIDES",
      "AI & Machine Learning in Libraries"
    ]
  },
  {
    "objectID": "ai-ml.html#hands-on-activity-and-other-self-guided-tutorials",
    "href": "ai-ml.html#hands-on-activity-and-other-self-guided-tutorials",
    "title": "AI & Machine Learning in Libraries",
    "section": "Hands-on activity and other self-guided tutorial(s)",
    "text": "Hands-on activity and other self-guided tutorial(s)\nThe following quick little hands-on activities below were developed by the Digital Research Team for British Library staff as part of the Digital Scholarship Training Programme.\n\nActivity: Explore Natural Language Processing\nCopy and paste a paragraph of text from somewhere around the web, or from your own collections, and see how each of these cloud services handle it:\n\nCloud Natural Language\nIBM Watson Natural Language Understanding Text Analysis\ndisplaCy\nVoyant Tools (voyant-tools.org) Voyant Tools is an open-source, web-based application for performing text analysis. It supports scholarly reading and interpretation of texts or corpus, particularly by scholars in the digital humanities, but also by students and the general public. It can be used to analyse online texts or ones uploaded by users.\nAnnif - tool for automated subject indexing There are many video tutorials here and the ability to demo the tool\n\n\n\nActivity: Explore Conversation Generation (ChatGPT)\nLogin to use the freely available ChatGPT (openai.com) interface.\nTo get a useful response from ChatGPT, “prompting” is key. If you only ask a simple question, you may not be happy with the results and decide to dismiss the technology too quickly, but today’s purpose is to have a deeper play in order to develop our critical thinking and information evaluation skills, allowing us to make informed decisions about utilising tools like ChatGPT in our endeavours. Basics of Prompting | Prompt Engineering Guide (promptingguide.ai) gives a nice quick walk-through of how to start writing good prompts or you can take a free course !\nHave a play trying to get ChatGPT to generate responses to some of the questions here (or come up with your own questions!) Critically evaluate the responses you receive from ChatGPT, what are its strengths and weaknesses, ethical considerations and challenges of using AI tools such as this.\n\nIs the information/response credible?\nAre there any biases in the responses?\nDoes the information align with what you know from other sources?\n\n\n\nActivity: Explore Computer Vision & Handwritten Text Recognition\nFind an image from somewhere on the web, or from your own collection, and see how each of these cloud services handles it! Try with some images of basic objects to see results (cars, fruit, bicycles…) and images with text within them.\n\nGoogle Cloud Vision API\nVisual Geometry Group - University of Oxford\nTranskribus(Try for free, but does require a free account to login)\n\n\n\nActivities: Exploring Hands-on AI (workshop materials)\nThe following workshop Exploring Hands-on AI was delivered to LIBER colleagues at the LIBER 2024 Annual Conference, but you can walk through many of the exercises at your own pace independently! Through a series of hands-on exercises, presented via Google Collab sheets, the workshop aimed to clarify how data science, and more particularly, generative AI systems based on Large Language Models (LLMs) can be applied within a library context and covers:\n\nGoogle Colab Basics\nIntroduction to Machine Learning\nObject detection with YOLO\nLarge Language Models\nRetrieval Augmented Generation",
    "crumbs": [
      "TOPIC GUIDES",
      "AI & Machine Learning in Libraries"
    ]
  },
  {
    "objectID": "ai-ml.html#recommended-readingviewing",
    "href": "ai-ml.html#recommended-readingviewing",
    "title": "AI & Machine Learning in Libraries",
    "section": "Recommended Reading/Viewing",
    "text": "Recommended Reading/Viewing\nMuch of this topic guide is based on both a Library Carpentry Intro to AI for GLAM lesson I have developed with colleagues and a 2024 talk I gave as part of a Research Libraries UK Digital Shift Forum so if you’d like to view/listen to the content covered in this topic guide as a lecture:\n\n\n\nWatch the video\n\n\nThere are of course untold numbers of lists out there with resources for learning more about AI & Machine Learning but I think this particular guide is exceptionally useful in its coverage and topics selected, particularly as they are quite specifically for Librarians: Add’tl Reading for Librarians & Faculty - Using AI Tools in Your Research - Research Guides at Northwestern University",
    "crumbs": [
      "TOPIC GUIDES",
      "AI & Machine Learning in Libraries"
    ]
  },
  {
    "objectID": "ai-ml.html#finding-communities-of-practice",
    "href": "ai-ml.html#finding-communities-of-practice",
    "title": "AI & Machine Learning in Libraries",
    "section": "Finding Communities of Practice",
    "text": "Finding Communities of Practice\nThe AI4Lam group is an excellent, engaged and welcoming international organisation dedicated to all things AI in Libraries, Archives and Museums. It’s free for anyone to join and is a great first step for anyone interested in learning more about this topic!",
    "crumbs": [
      "TOPIC GUIDES",
      "AI & Machine Learning in Libraries"
    ]
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "Preface",
    "section": "",
    "text": "Preface\nThis is a prototype of a self-guided training resource which is open, online and collaboratively curated. The en goal is learning hub which aims to help librarians who want to develop the skills and the knowledge needed to work with digital collections and with data.\nWe will present this prototype to participants attending the workshop on Digital Scholarship & Data Science Essentials for Library Professionals at the LIBER Winter Event 2023. It is meant to serve as inspiration and provide a basis for feedback on an ideal learning hub.\nThis ‘book’ is built with Quarto and hosted on GitHub. It is entirely open(-source) and therefore the community can actively engage with developing and maintaining it. With a bit of extra setup, it would be possible for users to contribute to the book directly on GitHub. All that would be needed is knowledge of Markdown syntax and some familiarity of a typical GitHub workflow via the web browser.\nLet us know what you think!"
  },
  {
    "objectID": "reports.html",
    "href": "reports.html",
    "title": "SKILLS COMPETENCY FRAMEWORKS & REPORTS",
    "section": "",
    "text": "SKILLS COMPETENCY FRAMEWORKS & REPORTS\nThe following are Skills Competency Frameworks & Key Reports relating to supporting Digital Scholarship and Data Science for library staff\n\nLIBER Publications\n\nLIBER Digital Skills for Library Staff & Researchers Working Group - LIBER Europe have lots of resources here, including a very useful diagram Identifying Open Science Skills for Library Staff & Researchers\nLIBER Job Description Repository Contains job description examples for Digital Curator and other digital roles which reference the types of skills required for such work.\nEurope’s Digital Humanities Landscape: A Study From LIBER’s Digital Humanities & Digital Cultural Heritage Working Group is a report based on a Europe-wide survey run by LIBER’s Digital Humanities & Digital Cultural Heritage Working Group. The survey focused on digital collections and the activities libraries undertake around them. It covered the following topics and themes including staffing/skills\n\n\n\nKey Publications specific to digital scholarship and data science skills for research library staff\n\nThe British Library and the Arts and Humanities Research Council published a report on skills: Scoping Skills and Developing Training Programme for Managing Repository Services in Cultural Heritage Organisations. There is a very useful section (Section 3.) that references several other digital skills frameworks for research library staff across Europe.\nLippincott, Joan K. Directions in Digital Scholarship: Support for Digital, Data-Intensive, and Computational Research in Academic Libraries. Coalition for Networked Information, June 2023. https://doi.org/10.56561/ULHJ1168\nPadilla, Thomas. ‘Responsible Operations: Data Science, Machine Learning, and AI in Libraries’. OCLC, 26 August 2020.\nCordell, R. C. (2020). Machine Learning + Libraries: A Report on the State of the Field. LC Labs, Library of Congress.\nFederer L. Defining data librarianship: a survey of competencies, skills, and training. J Med Libr Assoc. 2018 Jul;106(3):294-303. doi: 10.5195/jmla.2018.306. Epub 2018 Jul 1. PMID: 29962907; PMCID: PMC6013124.\n\n\n\nGeneral Competencies for Librarians which include reference to digital\n\nAmerican Library Association (ALA) Library Competencies (Various roles): Library Competencies | Tools, Publications & Resources (ala.org) (USA)\nCanadian Association of Research Libraries Competencies for Librarians in Canadian Research Libraries Publications and Documents (including specifically Competencies-Final-EN-1-2.pdf (Canada)\nCILIP: the library and information association Professional Knowledge & Skills Base - (UK)"
  },
  {
    "objectID": "collectionsasdata.html",
    "href": "collectionsasdata.html",
    "title": "Collections as Data: Getting Started",
    "section": "",
    "text": "GLAM (Galleries, Libraries, Archives and Museums) institutions have been making their content available to the public and researchers in a variety of formats for different purposes for decades. From maps, images, text, historical newspapers or postcards, digitising collections and displaying our items online are at the core of making this information accessible for research and enjoyment. But recent advances in and expansion of the use of AI and Machine Learning in library work and library research have transformed the way in which we and our users expect to access, view, use and search our collections. As the demand for computationally accessible cultural heritage collections continues to grow, and we’re being asked to provide our collections in the form of datasets for instance, how do we go about this practically?\nIn this new context, where GLAM institutions now find themselves playing a leading role as data providers and data curators, the Collections as Data concept emerged as a new approach, guidance and framework to support responsible development and computational use of digital cultural heritage collections. By computational use we mean the application of computational techniques such as natural language process, computer vision, and more to the analysis, exploration and reuse at scale of digitised cultural heritage content. For more practical use cases see our AI and Machine Learning in Libraries topic guide.\nThree particularly useful outputs from the Collections as Data community of practice are:\n\nFifty things (2018)\n\n“Want to support collections as data at your institution, but not sure how to begin? Drawing on what we learned from engaging with practitioners and researchers throughout the Always Already Computational project, the project team compiled a list of 50 Things you can do to get started. 50 Things is intended to open eyes, stimulate conversation, encourage stepping back, generate ideas, and surface new possibilities. If any of that gets traction, then perhaps you can make the case for investing in collections as data at your institution in a meaningful, if not systematic, way”\n\nVancouver Statement on Collections as data (2023)\n\n“The Vancouver Statement suggests a set of principles for thinking through questions that collections-as-data work produces, as part of an expanding global, interprofessional, and interdisciplinary effort to empower memory, knowledge, and data stewards (e.g., practitioners and scholars) who aim to support responsible development and computational use of collections as data. This stewardship role only grows in importance as artificial intelligence applications, trained on vast amounts of data, including collections as data, impact our lives ever more pervasively.”\n\nA Checklist to Publish Collections as Data in GLAM Institutions (2023)\n\nDeveloped as a result of a community-led effort, the checklist covers different aspects such as providing a suggested citation, including documentation about the datasets (e.g., README files or tutorials) or sharing examples of use (e.g., prototypes or Jupyter Notebooks).",
    "crumbs": [
      "TOPIC GUIDES",
      "Collections as Data: Getting Started"
    ]
  },
  {
    "objectID": "collectionsasdata.html#introduction",
    "href": "collectionsasdata.html#introduction",
    "title": "Collections as Data: Getting Started",
    "section": "",
    "text": "GLAM (Galleries, Libraries, Archives and Museums) institutions have been making their content available to the public and researchers in a variety of formats for different purposes for decades. From maps, images, text, historical newspapers or postcards, digitising collections and displaying our items online are at the core of making this information accessible for research and enjoyment. But recent advances in and expansion of the use of AI and Machine Learning in library work and library research have transformed the way in which we and our users expect to access, view, use and search our collections. As the demand for computationally accessible cultural heritage collections continues to grow, and we’re being asked to provide our collections in the form of datasets for instance, how do we go about this practically?\nIn this new context, where GLAM institutions now find themselves playing a leading role as data providers and data curators, the Collections as Data concept emerged as a new approach, guidance and framework to support responsible development and computational use of digital cultural heritage collections. By computational use we mean the application of computational techniques such as natural language process, computer vision, and more to the analysis, exploration and reuse at scale of digitised cultural heritage content. For more practical use cases see our AI and Machine Learning in Libraries topic guide.\nThree particularly useful outputs from the Collections as Data community of practice are:\n\nFifty things (2018)\n\n“Want to support collections as data at your institution, but not sure how to begin? Drawing on what we learned from engaging with practitioners and researchers throughout the Always Already Computational project, the project team compiled a list of 50 Things you can do to get started. 50 Things is intended to open eyes, stimulate conversation, encourage stepping back, generate ideas, and surface new possibilities. If any of that gets traction, then perhaps you can make the case for investing in collections as data at your institution in a meaningful, if not systematic, way”\n\nVancouver Statement on Collections as data (2023)\n\n“The Vancouver Statement suggests a set of principles for thinking through questions that collections-as-data work produces, as part of an expanding global, interprofessional, and interdisciplinary effort to empower memory, knowledge, and data stewards (e.g., practitioners and scholars) who aim to support responsible development and computational use of collections as data. This stewardship role only grows in importance as artificial intelligence applications, trained on vast amounts of data, including collections as data, impact our lives ever more pervasively.”\n\nA Checklist to Publish Collections as Data in GLAM Institutions (2023)\n\nDeveloped as a result of a community-led effort, the checklist covers different aspects such as providing a suggested citation, including documentation about the datasets (e.g., README files or tutorials) or sharing examples of use (e.g., prototypes or Jupyter Notebooks).",
    "crumbs": [
      "TOPIC GUIDES",
      "Collections as Data: Getting Started"
    ]
  },
  {
    "objectID": "collectionsasdata.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "href": "collectionsasdata.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "title": "Collections as Data: Getting Started",
    "section": "Relevance to the Library Sector (Case Studies/Use Cases)",
    "text": "Relevance to the Library Sector (Case Studies/Use Cases)\nMany institutions have started to adopt the collections as data principles to varying degrees, often combining publication of digital collections suitable for computational use, with a lab offering technical support to use them. You might notice that the examples below are all slightly different implementations of the principles though as each institution will necessarily need to decide for themselves, based on their individual goals and constraints (such as lack of resources, staff or IT skills) how to practically adopt the Collections as Data principles.\n\nData Foundry at the National Library of Scotland provides datasets in the form of downloadable files. Each of them includes a website with transparent information about the creation and curation of the content. It also provides examples of use and prototypes in the form of Jupyter Notebooks.\nNational Library of Luxembourg provides a digital collection based on Historical newspapers. It follows an innovative approach by providing different datasets in terms of the size and the content according to the purpose of the reuse (e.g., getting started or Big Data).\nBritish Library Labs provides a selection of datasets made available under open licences to experiment.\nDATA-KBR-BE is a project that aims at facilitating data-level access to KBR’s digitised and born-digital collections for digital humanities research.\nBiblioteca Virtual Miguel de Cervantes (BVMC Labs) is a digital library that published its bibliographic catalogue in the form of Linked Open Data. It also provides examples of use by means of of Jupyter Notebooks.\n\nMore advanced approaches are focused on the concept of data spaces, which are new cloud environments in which data can be shared for research use, while also allowing data suppliers to retain rights and control over the data. This can be useful for contexts in which the access of the data is restricted (e.g., geographic region, licensed content). A workflow to publish Collections as Data: the case of Cultural Heritage data spaces ) gives more information on this topic in the context of the European common data space for cultural heritage.\nIt is important to note that institutions need to carefully consider how and for what purpose they want to publish their digital content. For instance, the National Library of the Netherlands has recently restricted access to collections for training commercial AI. See our topic guide on Copyright and Licensing for more on that.",
    "crumbs": [
      "TOPIC GUIDES",
      "Collections as Data: Getting Started"
    ]
  },
  {
    "objectID": "collectionsasdata.html#hands-on-activity-and-other-self-guided-tutorials",
    "href": "collectionsasdata.html#hands-on-activity-and-other-self-guided-tutorials",
    "title": "Collections as Data: Getting Started",
    "section": "Hands-on activity and other self-guided tutorial(s)",
    "text": "Hands-on activity and other self-guided tutorial(s)\nOne simple activity you could do at your institution is to gather a group of like-minded colleagues together and have a read through Fifty things, Vancouver Statement on Collections as data and/or A Checklist to Publish Collections as Data in GLAM Institutions and have a look at some of the case studies above, and as a group consider the questions:\n\nAre there some activities suggested that are already underway?\nCan you identify one or two simple things that your institution could do now in order to start using these principles?\nWhat might you like “collections as data” to look like at your institution?\n\nIf you’d like to get a sense of how people are reusing collections published as data, the GLAM Workbench and the new computational access section of the International GLAM Labs Community website both have tutorials that can walk you through using cultural heritage datasets in a variety of ways.",
    "crumbs": [
      "TOPIC GUIDES",
      "Collections as Data: Getting Started"
    ]
  },
  {
    "objectID": "collectionsasdata.html#recommended-readingviewing",
    "href": "collectionsasdata.html#recommended-readingviewing",
    "title": "Collections as Data: Getting Started",
    "section": "Recommended Reading/Viewing",
    "text": "Recommended Reading/Viewing\nIf you are interested in reading more about the collections as data concept we highly recommend the Zotero | Groups &gt; collections as data - projects, initiatives, readings, tools, datasets which is an open bibliography collaboratively maintained by the community of practice of projects, readings, initiatives, tools, and datasets that are in some way or another related to collections as data.",
    "crumbs": [
      "TOPIC GUIDES",
      "Collections as Data: Getting Started"
    ]
  },
  {
    "objectID": "collectionsasdata.html#finding-communities-of-practice",
    "href": "collectionsasdata.html#finding-communities-of-practice",
    "title": "Collections as Data: Getting Started",
    "section": "Finding Communities of Practice",
    "text": "Finding Communities of Practice\nJoining the International GLAM Labs Community is a great way to get started on the path of opening your collections up as data as well as the Collections as Data - Google Group as both communities are very active and have a wide range of experience and expertise to share on this topic.",
    "crumbs": [
      "TOPIC GUIDES",
      "Collections as Data: Getting Started"
    ]
  },
  {
    "objectID": "guidelines.html",
    "href": "guidelines.html",
    "title": "AUTHOR GUIDANCE & STYLE GUIDE",
    "section": "",
    "text": "Each Topic Guide follows a distinct structure, beginning with a Header Section composing of a title, contributor information, published date, last modified info, and suggested citation followed by five key content blocks detailed below. Please have a look at the IIIF Guide as an example of how these pieces all fit together into one complete Topic Guide.\n\n\n\nTopic Guide Title: IIIF\nContributor(s) Name and (Orcid ID): Nora McGregor (ORCID iD)\nPublished date: 27/03/2024\nSuggested Citation: Nora McGregor, “IIIF,” Digital Scholarship & Data Science Essentials for Library Professionals (2024), [DOI link]\n\nNote: The project team will ensure each Topic Guide is given an individual DOI either through British Library Research Repository or Zenodo.\n\n\n\nThis introduction section should be pitched at a beginner/foundational level and gives a concise overview of the topic. It should be written in a relaxed and natural way. This section does not need to contain the world’s knowledge, just enough high-level knowledge to get the key concepts across.\n\nImagine that a colleague has come to you casually asking about the topic over tea. How might you go about explaining it to them in your own words? During the course of that casual conversation what key things would you leave in and what might you leave out in the interest of getting them to a basic understanding quickly?\n\nLinking can be used liberally for jargon busting throughout if explaining a particular term is more complex than our word count allows. Please see the Style Guidelines below for more writing tips!\n\n\n\nThis section provides a clear explanation of the topics’ specific relevance to the work of libraries.\nIt should contain:\n\nA short paragraph or two setting the scene as to why the topic is relevant to the work of libraries. Here you might also like to present opportunities and, if relevant, potential challenges for libraries around the topic as well.\nUp to 3 examples of real world (or potential) applications/case studies/projects briefly explained in a 100 max word summary provided each with links to further information if available. Note that it is not necessary to write up or create a new case study yourself here! Rather, we’re looking for briefly summarised references to existing ones. If there are quite a few other examples the contributor would like to reference include, links to these can be added at the end of this section (Example: “For further case studies, visit….”).\n\n\n\n\nThe objective of this section of the topic guide is to enable learners to familiarise themselves with the basics of the topic through active practice via self-paced tutorials and hand-on activities. Authors are not expected to create new activities or tutorials in this section, but rather to provide selected links to existing hands on tutorials which are known by them to have proven value and can be personally recommended for library professionals in particular.\nThe tutorials recommended should be free, online and suitable for independent study, and ideally, focussed on the library professional perspective where possible. Authors may wish to link to practical exercises or quizzes, specific online lessons that may exist in other online platforms, Juptyer Notebooks and GLAM workbench materials that provide detailed explanations of the steps learners can follow.\nFor the sake of consistency across the various topic guides, it is helpful if tutorial references are structured as follows:\n\nThe title/name of the activity/tutorial, the URL (added as a hyperlink), and citation information (please use APA Style and/or provide a DOI if there is one)\nA brief, personal explanation below it (no more than 200 words) as to why the author recommends this particular tutorial, and, optionally, an indication of topics covered and the level of complexity.\n\n\n\n\nThe section on recommended reading and viewing contains references to more passive learning resources such as:\n\nOpen access articles discussing the topic at a general level, or containing contextual information.\nVideo recordings of lectures about the topic, which do not demand practical activities from the viewer Podcasts about the topic\n\nWhen including citations please make sure to either write them in APA Style and/or simply provide the DOI with your text so that the project team can compile a dedicated Zotero Library.\n\n\n\nThis section provides guidance to library professionals on where to take their learning journey further. It should include:\n\nWhere to find (local/national/international) Communities of Practice or other relevant networks and organisations who can help with furthering their understanding of the topic.\nIf relevant you might also point to specific summer school courses, conferences and events that may further enhance learning.\n\n\n\n\n\n\n\nTo ensure consistency and inclusivity across our content, please consider these general guidelines:\n\nClarity and Simplicity: Write in a clear and straightforward manner, using simple language that is easy to understand for learners of all backgrounds and proficiency levels.\nLinking to Technical Terms: When introducing technical terms or concepts that may be unfamiliar to some learners, provide hyperlinks to additional resources or definitions where they can learn more. This helps to enhance understanding and allows learners to explore topics in more depth at their own pace. Ensure that the linked resources are reliable and authoritative to provide accurate information to the learners.\nAvoid Colloquialisms and Regionalisms: While it’s essential to maintain a casual and natural tone, please refrain from using colloquial expressions or regionalisms that may not be universally understood by our diverse audience.\nCultural Sensitivity: Be mindful of cultural differences and avoid language or examples that may be offensive or insensitive to any group of people. When providing examples or references, strive for universality and inclusivity.\nGender Neutrality: Use gender-neutral language whenever possible to ensure inclusivity and avoid assumptions about gender roles or identities.\nGlobal Perspective: Consider the international nature of our audience when crafting examples, scenarios, and references. Aim for content that resonates with learners from various cultural backgrounds and geographical locations."
  },
  {
    "objectID": "guidelines.html#structuring-the-topic-guide",
    "href": "guidelines.html#structuring-the-topic-guide",
    "title": "AUTHOR GUIDANCE & STYLE GUIDE",
    "section": "",
    "text": "Each Topic Guide follows a distinct structure, beginning with a Header Section composing of a title, contributor information, published date, last modified info, and suggested citation followed by five key content blocks detailed below. Please have a look at the IIIF Guide as an example of how these pieces all fit together into one complete Topic Guide.\n\n\n\nTopic Guide Title: IIIF\nContributor(s) Name and (Orcid ID): Nora McGregor (ORCID iD)\nPublished date: 27/03/2024\nSuggested Citation: Nora McGregor, “IIIF,” Digital Scholarship & Data Science Essentials for Library Professionals (2024), [DOI link]\n\nNote: The project team will ensure each Topic Guide is given an individual DOI either through British Library Research Repository or Zenodo.\n\n\n\nThis introduction section should be pitched at a beginner/foundational level and gives a concise overview of the topic. It should be written in a relaxed and natural way. This section does not need to contain the world’s knowledge, just enough high-level knowledge to get the key concepts across.\n\nImagine that a colleague has come to you casually asking about the topic over tea. How might you go about explaining it to them in your own words? During the course of that casual conversation what key things would you leave in and what might you leave out in the interest of getting them to a basic understanding quickly?\n\nLinking can be used liberally for jargon busting throughout if explaining a particular term is more complex than our word count allows. Please see the Style Guidelines below for more writing tips!\n\n\n\nThis section provides a clear explanation of the topics’ specific relevance to the work of libraries.\nIt should contain:\n\nA short paragraph or two setting the scene as to why the topic is relevant to the work of libraries. Here you might also like to present opportunities and, if relevant, potential challenges for libraries around the topic as well.\nUp to 3 examples of real world (or potential) applications/case studies/projects briefly explained in a 100 max word summary provided each with links to further information if available. Note that it is not necessary to write up or create a new case study yourself here! Rather, we’re looking for briefly summarised references to existing ones. If there are quite a few other examples the contributor would like to reference include, links to these can be added at the end of this section (Example: “For further case studies, visit….”).\n\n\n\n\nThe objective of this section of the topic guide is to enable learners to familiarise themselves with the basics of the topic through active practice via self-paced tutorials and hand-on activities. Authors are not expected to create new activities or tutorials in this section, but rather to provide selected links to existing hands on tutorials which are known by them to have proven value and can be personally recommended for library professionals in particular.\nThe tutorials recommended should be free, online and suitable for independent study, and ideally, focussed on the library professional perspective where possible. Authors may wish to link to practical exercises or quizzes, specific online lessons that may exist in other online platforms, Juptyer Notebooks and GLAM workbench materials that provide detailed explanations of the steps learners can follow.\nFor the sake of consistency across the various topic guides, it is helpful if tutorial references are structured as follows:\n\nThe title/name of the activity/tutorial, the URL (added as a hyperlink), and citation information (please use APA Style and/or provide a DOI if there is one)\nA brief, personal explanation below it (no more than 200 words) as to why the author recommends this particular tutorial, and, optionally, an indication of topics covered and the level of complexity.\n\n\n\n\nThe section on recommended reading and viewing contains references to more passive learning resources such as:\n\nOpen access articles discussing the topic at a general level, or containing contextual information.\nVideo recordings of lectures about the topic, which do not demand practical activities from the viewer Podcasts about the topic\n\nWhen including citations please make sure to either write them in APA Style and/or simply provide the DOI with your text so that the project team can compile a dedicated Zotero Library.\n\n\n\nThis section provides guidance to library professionals on where to take their learning journey further. It should include:\n\nWhere to find (local/national/international) Communities of Practice or other relevant networks and organisations who can help with furthering their understanding of the topic.\nIf relevant you might also point to specific summer school courses, conferences and events that may further enhance learning."
  },
  {
    "objectID": "guidelines.html#style-guidelines",
    "href": "guidelines.html#style-guidelines",
    "title": "AUTHOR GUIDANCE & STYLE GUIDE",
    "section": "",
    "text": "To ensure consistency and inclusivity across our content, please consider these general guidelines:\n\nClarity and Simplicity: Write in a clear and straightforward manner, using simple language that is easy to understand for learners of all backgrounds and proficiency levels.\nLinking to Technical Terms: When introducing technical terms or concepts that may be unfamiliar to some learners, provide hyperlinks to additional resources or definitions where they can learn more. This helps to enhance understanding and allows learners to explore topics in more depth at their own pace. Ensure that the linked resources are reliable and authoritative to provide accurate information to the learners.\nAvoid Colloquialisms and Regionalisms: While it’s essential to maintain a casual and natural tone, please refrain from using colloquial expressions or regionalisms that may not be universally understood by our diverse audience.\nCultural Sensitivity: Be mindful of cultural differences and avoid language or examples that may be offensive or insensitive to any group of people. When providing examples or references, strive for universality and inclusivity.\nGender Neutrality: Use gender-neutral language whenever possible to ensure inclusivity and avoid assumptions about gender roles or identities.\nGlobal Perspective: Consider the international nature of our audience when crafting examples, scenarios, and references. Aim for content that resonates with learners from various cultural backgrounds and geographical locations."
  },
  {
    "objectID": "api.html",
    "href": "api.html",
    "title": "APIs: A starter guide for Librarians",
    "section": "",
    "text": "APIs (Application Programming Interfaces) can sound intimidating, but the ideas behind them are not unfamiliar. An application programming interface (API) allows a connection between computers or between computer programs, it is a type of software interface offering a service to other pieces of software. A common analogy that can be helpful in understanding the process of how APIs work is the restaurant analogy.\nImagine going to a restaurant (server). You first consult the menu provided (API documentation / specification) to understand what is available for you to order (request). After consulting the menu (documentation) you have a good idea of what is likely to result in a successful order from the kitchen. The waiter is a bit like the restaurant’s API. Behind the waiter is a whole world of kitchen staff, bar staff, wholesalers, suppliers, shareholders and so on. You don’t need to worry about any of them, you probably won’t even ever speak to them. All your food orders (requests) and any extra instructions such as “chips or mash?” (parameters) will be passed to the kitchen (server) by the waiter (API). The kitchen (server) prepares your order (request) and passes it to the waiter (API) to deliver to your meal (response).\n\nJust as in our analogy above, sites will offer an API, and anyone can use it without having to know anything about the internal workings of that system. You don’t need to see the source code, the technologies they used to build it or know the name of the person who keeps it running at weekends. All you need to know is how to make a request to the API, and for this, APIs will normally have a site that will document what you can request and how. A good example is OpenLibrary’s API pages. API Documentation will detail individual methods (GET, POST, etc) with any parameters (see Lists API | Open Library for examples) you will need to pass for a successful response. It may also state any security considerations such as needing authentication (an API Key) or a log in before using the method.\nThis Topic Guide will focus on REST APIs as an example as it’s the most likely you’ll encounter in your day to day library work, just be aware that REST APIs are not the only type of API though, there are other API types such as:\n\nSOAP\nGraphQL\nRPC\n\nYou can find some information on those here: https://www.postman.com/what-is-an-api/#api-architectural-styles\nThe main thing to keep in mind is the idea that an API enables the exchange of data and information between two systems and provides a kind of contract between both sides as to how to do this. The user gets a documented way to find out how to interact with a system and understand everything that comes back from it. The provider of the service also knows exactly how their system is being interacted with. There should be no “backdoors” or undocumented ways of working with the system, and service providers who provide APIs should be careful not to change how the API is being served in such a way that it negatively affects users. Again, thinking about this idea in the context of a restaurant, a restaurant might find itself being hugely successful, so makes the decision to move to larger or multiple premises and upgrade its kitchen. If they keep the same menu, then the effect of this on you is minimal – you can still order your favourite dish, despite all the changes.\n\n\n\n\nDifferent types of requests are made to an API depending on what you want to do and whether you just want to read from the API or maybe send some information back. In a REST Api we call these types of requests “HTTP request methods”, and they are designed as a simple way to describe what you are trying to do. Have a look at Mozilla’s pages on methods for more in-depth details.\nThe main HTTP request methods are described in the table below:\n\n\n\n\n\n\n\nHttp Request Method\nDescription\n\n\n\n\nGET\nReads information from an API, does not change what is on the server, e.g. a list of available images or in individual image\n\n\nPOST\nAdds a new resource to the server, e.g. upload a new image to the server with its metadata\n\n\nPUT\nAmends a resource on a server, e.g. edit the metadata of one of the images\n\n\nDELETE\nRemoves a resource from the server.\n\n\n\nTo make these more understandable, let’s substitute in an editor of books in place of all this technology. Our editor character is the equivalent to the user of our API, and the author they are working with is the equivalent of the API itself, the mail is the equivalent of the Internet and the draft pages of the book are the resources handled by the API.\nOur editor starts the day by GETting a draft version of a book, dropped off by the local postman. Throughout the day they work on the book and PUTs onto the pages with a pen any corrections or amendments to the text. Usually these will be small corrections or suggestions, but sometimes it might be a suggestion to add some new content. As our character here is an editor, they would not write the additional material themselves but instead ask the original author to POST the new content.\nOccasionally, our editor will not be happy with the book at all. In which case they will ask the publisher to put every existing copy in the bin and thus DELETE it.\n\n\n\nIn our restaurant example, sending our requests to the right person, in this case the waiter or waitress, is essential. We do not want to accidentally ask another customer for our food! When using APIs it is essential to also make sure that we are sending our requests to the right place. However, when using APIs this can be a little more complicated as we must construct a web address that corresponds with what we want to do.\nAPI web addresses are made up of several parts. Take this URL as an example:\nhttps://api.example.org/v1/desserts/56\nWhen you consult the documentation for an API, you might see that a request is documented something like this:\nGET /v1/desserts/{id}\nYou will notice that the first part of the address, http://api.example.org, is omitted. This part of the web address routes to the whole API. Think of it as an address for a company, and everything that follows is different departments.\nThe rest we can break down like this:\n\n\n\n\n\n\n\n—\n—\n\n\n\n\nGET\nThe type of request we are making (see above). In this case we are reading information, not changing it or deleting it.\n\n\n/v1\nThe version number of the API. Having versions of the API allows providers to provide new versions of APIs, that may work in different ways, without breaking existing API requests.\n\n\ndesserts\nThis part of the URL tells you the type of resource you will be working. In this case dessert listings on our menu.\n\n\n{id}\nA unique identifier for the resource. This could be a number such as 56 or a string such as “sticky-toffee-pudding”\n\n\n\nAssuming your request was successful, the response from the server could be any sort of file type, it depends on the resources it handles. If the endpoint deals with metadata, then you might get back a JSON or XML encoded document. These are both ways of representing data in a way that can be easily understood by a computer program.\nFor instance, a response from our fictional restaurant menu API above which might look like this:\n{“id”: 56, “title”: “Rhubarb Crumble”, “description”: “A modern take on a classic pudding, served with custard or ice cream”, “gluten_free”: false, “vegetarian”: true, “vegan”: true, “price”: 5.99}\nSometimes you might not want to work with an individual resource, but instead a group. In this case the call will look slightly different, and we might use a parameter after a “?” symbol.\nFor example, let us find all the vegan desserts in our menu. To do this we need to “search”:\nhttps://api.example.org/v1/desserts/search?vegan=true\nThere will be some practical examples that will step you through how to make different API calls like this in the next section.\n\n\n\nWhen you make a request to an API you will get a three-digit number returned. This is called the HTTP status code. These codes can be broadly classified as follows:\n2XX: The request was understood, the right authorisation was present, and the server could process your request\n3XX: The web address you are trying to use is now at a different web address\n4XX: You have made an error, this could be caused by the server not understanding your request, or an authorisation problem\n5XX: There was an error on the server side. This could be a temporary or permanent problem, it could be caused by things like a fault in the server-side code, or a database being down.",
    "crumbs": [
      "TOPIC GUIDES",
      "APIs: A starter guide for Librarians"
    ]
  },
  {
    "objectID": "api.html#introduction",
    "href": "api.html#introduction",
    "title": "APIs: A starter guide for Librarians",
    "section": "",
    "text": "APIs (Application Programming Interfaces) can sound intimidating, but the ideas behind them are not unfamiliar. An application programming interface (API) allows a connection between computers or between computer programs, it is a type of software interface offering a service to other pieces of software. A common analogy that can be helpful in understanding the process of how APIs work is the restaurant analogy.\nImagine going to a restaurant (server). You first consult the menu provided (API documentation / specification) to understand what is available for you to order (request). After consulting the menu (documentation) you have a good idea of what is likely to result in a successful order from the kitchen. The waiter is a bit like the restaurant’s API. Behind the waiter is a whole world of kitchen staff, bar staff, wholesalers, suppliers, shareholders and so on. You don’t need to worry about any of them, you probably won’t even ever speak to them. All your food orders (requests) and any extra instructions such as “chips or mash?” (parameters) will be passed to the kitchen (server) by the waiter (API). The kitchen (server) prepares your order (request) and passes it to the waiter (API) to deliver to your meal (response).\n\nJust as in our analogy above, sites will offer an API, and anyone can use it without having to know anything about the internal workings of that system. You don’t need to see the source code, the technologies they used to build it or know the name of the person who keeps it running at weekends. All you need to know is how to make a request to the API, and for this, APIs will normally have a site that will document what you can request and how. A good example is OpenLibrary’s API pages. API Documentation will detail individual methods (GET, POST, etc) with any parameters (see Lists API | Open Library for examples) you will need to pass for a successful response. It may also state any security considerations such as needing authentication (an API Key) or a log in before using the method.\nThis Topic Guide will focus on REST APIs as an example as it’s the most likely you’ll encounter in your day to day library work, just be aware that REST APIs are not the only type of API though, there are other API types such as:\n\nSOAP\nGraphQL\nRPC\n\nYou can find some information on those here: https://www.postman.com/what-is-an-api/#api-architectural-styles\nThe main thing to keep in mind is the idea that an API enables the exchange of data and information between two systems and provides a kind of contract between both sides as to how to do this. The user gets a documented way to find out how to interact with a system and understand everything that comes back from it. The provider of the service also knows exactly how their system is being interacted with. There should be no “backdoors” or undocumented ways of working with the system, and service providers who provide APIs should be careful not to change how the API is being served in such a way that it negatively affects users. Again, thinking about this idea in the context of a restaurant, a restaurant might find itself being hugely successful, so makes the decision to move to larger or multiple premises and upgrade its kitchen. If they keep the same menu, then the effect of this on you is minimal – you can still order your favourite dish, despite all the changes.\n\n\n\n\nDifferent types of requests are made to an API depending on what you want to do and whether you just want to read from the API or maybe send some information back. In a REST Api we call these types of requests “HTTP request methods”, and they are designed as a simple way to describe what you are trying to do. Have a look at Mozilla’s pages on methods for more in-depth details.\nThe main HTTP request methods are described in the table below:\n\n\n\n\n\n\n\nHttp Request Method\nDescription\n\n\n\n\nGET\nReads information from an API, does not change what is on the server, e.g. a list of available images or in individual image\n\n\nPOST\nAdds a new resource to the server, e.g. upload a new image to the server with its metadata\n\n\nPUT\nAmends a resource on a server, e.g. edit the metadata of one of the images\n\n\nDELETE\nRemoves a resource from the server.\n\n\n\nTo make these more understandable, let’s substitute in an editor of books in place of all this technology. Our editor character is the equivalent to the user of our API, and the author they are working with is the equivalent of the API itself, the mail is the equivalent of the Internet and the draft pages of the book are the resources handled by the API.\nOur editor starts the day by GETting a draft version of a book, dropped off by the local postman. Throughout the day they work on the book and PUTs onto the pages with a pen any corrections or amendments to the text. Usually these will be small corrections or suggestions, but sometimes it might be a suggestion to add some new content. As our character here is an editor, they would not write the additional material themselves but instead ask the original author to POST the new content.\nOccasionally, our editor will not be happy with the book at all. In which case they will ask the publisher to put every existing copy in the bin and thus DELETE it.\n\n\n\nIn our restaurant example, sending our requests to the right person, in this case the waiter or waitress, is essential. We do not want to accidentally ask another customer for our food! When using APIs it is essential to also make sure that we are sending our requests to the right place. However, when using APIs this can be a little more complicated as we must construct a web address that corresponds with what we want to do.\nAPI web addresses are made up of several parts. Take this URL as an example:\nhttps://api.example.org/v1/desserts/56\nWhen you consult the documentation for an API, you might see that a request is documented something like this:\nGET /v1/desserts/{id}\nYou will notice that the first part of the address, http://api.example.org, is omitted. This part of the web address routes to the whole API. Think of it as an address for a company, and everything that follows is different departments.\nThe rest we can break down like this:\n\n\n\n\n\n\n\n—\n—\n\n\n\n\nGET\nThe type of request we are making (see above). In this case we are reading information, not changing it or deleting it.\n\n\n/v1\nThe version number of the API. Having versions of the API allows providers to provide new versions of APIs, that may work in different ways, without breaking existing API requests.\n\n\ndesserts\nThis part of the URL tells you the type of resource you will be working. In this case dessert listings on our menu.\n\n\n{id}\nA unique identifier for the resource. This could be a number such as 56 or a string such as “sticky-toffee-pudding”\n\n\n\nAssuming your request was successful, the response from the server could be any sort of file type, it depends on the resources it handles. If the endpoint deals with metadata, then you might get back a JSON or XML encoded document. These are both ways of representing data in a way that can be easily understood by a computer program.\nFor instance, a response from our fictional restaurant menu API above which might look like this:\n{“id”: 56, “title”: “Rhubarb Crumble”, “description”: “A modern take on a classic pudding, served with custard or ice cream”, “gluten_free”: false, “vegetarian”: true, “vegan”: true, “price”: 5.99}\nSometimes you might not want to work with an individual resource, but instead a group. In this case the call will look slightly different, and we might use a parameter after a “?” symbol.\nFor example, let us find all the vegan desserts in our menu. To do this we need to “search”:\nhttps://api.example.org/v1/desserts/search?vegan=true\nThere will be some practical examples that will step you through how to make different API calls like this in the next section.\n\n\n\nWhen you make a request to an API you will get a three-digit number returned. This is called the HTTP status code. These codes can be broadly classified as follows:\n2XX: The request was understood, the right authorisation was present, and the server could process your request\n3XX: The web address you are trying to use is now at a different web address\n4XX: You have made an error, this could be caused by the server not understanding your request, or an authorisation problem\n5XX: There was an error on the server side. This could be a temporary or permanent problem, it could be caused by things like a fault in the server-side code, or a database being down.",
    "crumbs": [
      "TOPIC GUIDES",
      "APIs: A starter guide for Librarians"
    ]
  },
  {
    "objectID": "api.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "href": "api.html#relevance-to-the-library-sector-case-studiesuse-cases",
    "title": "APIs: A starter guide for Librarians",
    "section": "Relevance to the Library Sector (Case Studies/Use Cases)",
    "text": "Relevance to the Library Sector (Case Studies/Use Cases)\nWhy do Libraries and cultural heritage organisations provide and/or use APIs? APIs for Librarians gives a really nice view of the various ways librarians may want to use APIs big and small for various purposes, from displaying Word of the Day on your website to providing access to Internet Archive material and Overcoming disintermediation: a call for librarians to learn to use web service APIs | Emerald Insight outlines what APIs can enable for our institutions and users. Below are some additional use cases for providing and using APIs in a cultural heritage context:\n\nIntegrate\nThe technological beating heart of a modern library is the Library Management System (LMS). This is the electronic brain of a library, but to be able to do its job it must link to many other systems, usually through APIs. This is called Systems integration.\nAn example of this is obtaining details about a book that has been bought. The LMS can talk to the Publisher’s website through an API to get all the details needed to catalogue the item without the need for someone to manually type it in.\n\n\nEncourage Reuse\nAPIs are a great way to help people interact with cultural heritage collections. They allow people to develop new applications that could access your API, maybe in conjunction with many others, to search for types of items across many collections. They enable users, both inside and outside organisations to be able to analyse information, create visualisations and integrate collections data with other systems and workflows.\nIn the case of digital resources, they can make it easier to reuse and share those resources. For example, the IIIF standard enables images from a cultural heritage institutions’ collection to be easily embedded into learning materials produced by a completely different organisation.\n\n\nAuthentication\nMost APIs will require authentication in some way in order to use them, ensuring data providers retain some confidence and control over how the data provided is interacted with. This is in place of logging into the website.\nThere are several main types of authentication that you will use:\n\nUsername and password\nAPI Key – this is a long alphanumeric bit of text that uniquely identifies you to the system.\nOAuth – this is a bit like an API key, but every so often it gets exchanged for a new one. This is more secure as we are not using one card for an extended period of time but can be more complicated to set up.\n\n\n\nExtend\nAn organisation’s requirements for what it needs from a computer will change over time as technology and society develops. Having an API is a good way to ensure that you will always be able to extend your system to deal with new requirements. Extending functionality in this way is much easier and less risky than modifying a system that has been written as one monolithic unity.\nAn example here could be if you had to generate a new report from your system. It may already provide some reporting but up until now you have had to take the information from an old report and manipulate it in Excel. This can be error prone and time consuming. Instead, you can use the API to get the information you need and write a program to turn this information into a report. Using an API also has the advantage that you can use an existing system without modifying it or interrupting its uptime. Your code can be entirely separate. (Case Study OpenAthens Reporting API helps librarians demonstrate value)\n\n\nExtract\nEventually, a computer system will come to the end of its life and need replacing, or maybe a system is being replaced because it did not live up to expectations. In this scenario, being able to get all your data out of that system is critical. An API is an excellent way to do this. It may even be possible to write a program that use the API of your old system to supply the API of your new system with information, saving everybody a lot of time!\n\n\nInsurance\nSometimes, circumstances change around a system. It might be that requirements change, or an organisation finds itself doing something new. An API is a kind of insurance policy in these circumstances. It potentially allows you to extend the functionality of a system to meet new challenges. These might be something you need to do continuously, or just once. For example, you might want to bulk update the classification of some books. With an API you could write a program that would go through your collection, look for matching criteria and update accordingly. By always having access to your own data via an API, you have the insurance of being able to react flexibly if circumstances change.",
    "crumbs": [
      "TOPIC GUIDES",
      "APIs: A starter guide for Librarians"
    ]
  },
  {
    "objectID": "api.html#hands-on-activity-and-other-self-guided-tutorials",
    "href": "api.html#hands-on-activity-and-other-self-guided-tutorials",
    "title": "APIs: A starter guide for Librarians",
    "section": "Hands-on activity and other self-guided tutorial(s)",
    "text": "Hands-on activity and other self-guided tutorial(s)\nLet’s try a few real-world examples of getting information from an API as this is the easiest way to understand the process.\n\nExercise 1: Using an API for the very first time\n1. Introduction\nIn this exercise, adapted from Using an API: a hands on exercise a tutorial created for British Library staff by Owen Stephens) you are going to use a Google Spreadsheet to retrieve records from the Flickr API and display the results.\nThe API you are going to use simply allows you to submit some search terms and get a list of results in a format called RSS. You are going to use a Spreadsheet to submit a search to the API, and display the results.\n2. Understanding the API\nThe API you are going to use is an interface to Flickr, a photo sharing website where many cultural heritage institutions have hosted some of their collection images. Flickr has a very powerful API with lots of functions, but for simplicity in this exercise you are just going to use the Flickr RSS feeds, rather than the full API which is more complex and requires you to register.\nBefore you can start working with the API, you need to understand how it works. To do this, we are going to look at an example URL:\nhttps://api.flickr.com/services/feeds/photos_public.gne?tags=food&format=rss\nThe first part of the URL is the address of the API. Everything after the ‘?’ are ‘parameters’ which form the input to the API. There are two parameters listed and they each consist of the parameter name, followed by an ‘=’ sign, then a value.\nThe URL and parameters breakdown like this:\n\n\n\nURL Part\nExplanation\n\n\n\n\nhttps://api.flickr.com/services/feeds/photos_public.gne\nThe address of the API\n\n\ntags=food\nThe ‘tags parameter – contains a list of tags (separated by commas) to be used to filter the list of images returned by the API. In this case just the single tag ‘food’ is listed.\n\n\nformat=rss\nformat=rss\n\n\n\n3. Using the API\nTo use the API, you are going to use a Google Spreadsheet. Go to http://drive.google.com and login to your Google account. Create a Google Spreadsheet\nThe first thing to do is build the API call (the query you are going to submit to the API).\nFirst some labels:\nIn cell A1 enter the text ‘API Address’\nIn cell A2 enter the text ‘Tags’\nIn cell A3 enter the text ‘Format’\nIn cell A4 enter ‘API Call’\nIn cell A5 enter ‘Results’\nNow, based on the information we were able to obtain by understanding the API we can fill values into column B as follows:\nIn cell B1 enter the address of the API\nIn cell B2 enter a simple, one word tag\nIn cell B3 enter the text ‘rss’ (omitting the inverted commas)\nThe first three rows of the spreadsheet should look something like (with whatever tag you’ve chased to search in B2):\n\nYou now have all the parameters we need to build the API call. To do this you want to create a URL very similar to the one you looked at above. You can do this using a handy spreadsheet function/formula called ‘Concatenate’ which allows you to combine the contents of a number of spreadsheet cells with other text.\nIn Cell B4 type the following formula:\n=CONCATENATE(B1,“?”,“tags=”,B2,“&format=”,B3)\nThis joins the contents of cells B1, B2 with the text included in inverted commas in formula. Once you have entered this formula and pressed enter your spreadsheet should look like:\n\nThe final step is to send this query, and retrieve and display the results. This is where the fact that the API returns results as an RSS feed comes in extremely useful. Google Spreadsheets has a special function for retrieving and displaying RSS feeds.\nTo use this, in Cell B5 type the following formula:\n=importFeed(B4)\nBecause Google Spreadsheets knows what an RSS feed is, and understands it will contain one or more ‘items’ with a ‘title’ and a ‘link’ it will do the rest for us. Hit enter, and see the results.\nCongratulations! You have built an API query, and displayed the results.\nYou have:\n* Explored an API for Flickr\n* Seen how you can ‘call’ the API by adding some parameters to a URL\n* Understood how the API returns results in RSS format\n* Used this knowledge to build a Google Spreadsheet which searches for a tag on Flickr and displays the results\n4. Going Further\nFurther parameters that this API accepts are:\n\nid\nids\ntagmode\nformat\nlang\n\nThese are documented at https://www.flickr.com/services/feeds/docs/photos_public/. When adding parameters to a URL, you use the ‘&’ sign between each parameter e.g.\nhttps://api.flickr.com/services/feeds/photos_public.gne?tags=food&id=23577728@N07\nThis searches for all photos tagged with ‘food’ from a specific user (user id = 23577728@N07)\nBy adding a row to the spreadsheet, for this parameter, and modifying the ‘concatenate’ statement that builds the API Call, can you make the spreadsheet only return images with a specific tag in the British Library Flickr collection? (The Flickr ID for the British Library is ‘12403504@N02’\n\n\nExercise 2: Find out information for a location using Google APIs\n1. Go to https://developers.google.com/maps/documentation/places/web-service/text-search in your browser  2. Click on “Web Service” as the platform 3. You may be asked to log in using your Google account. 4. Click on the “API” button in the right-hand section. 5. Click on the “Fullscreen” icon along the top of this section, it is the icon that looks like edges of a square. 6. In the APIs Explorer window, click on “HTTP” – this lets you see the API request in terms of the web requests that are made. 7. The “Request Body” is the information you are going to send. In this case, the name of the place you would like to know more about. 8. Try a place you know, e.g. “British Library” as the value 9. Click “Execute” 10. You may be prompted to authorise the request, do so.\nAll being well you will see a response in the right-hand side. “200” will be prominently displayed, you might remember this code from the “How did the request go?” section earlier. Underneath, you will see a structured response with everything Google knows about that place. Notice lots of information mixed in together, what type of location it is, coordinates on a map and opening hours are examples of what you might see.\n\n\nOther online tutorials for beginners to try:\n\nJoshua Dull has created a useful workshop in the style of the Library Carpentries you could have a look at called APIs for Libraries\nOpenLibrary has some APIs you can experiment with just in a browser https://openlibrary.org/developers/api and in particular I can recommend having a play around in their sandbox which gives a great illustration of the code involved in API requests and API responses swagger/docs | Open Library\nThe Programming Historian has a lot of great API tutorials you can try which will walk you through using APIs for different purposes such as Fetching and Parsing Data from the Web with OpenRefine | Programming Historian\n\n\n\nOnce you’re feeling a little more confident, these tutorials will help you go further:\n\nWikimedia offers some incredibly useful APIs of particular interest to libraries who contribute to or have collection items there. They have a whole tutorial to help beginners: Getting started with Wikimedia APIs - API Portal\nDataquest has a nice tutorial on using the Python language to call APIs: https://www.dataquest.io/blog/api-in-python/\nYou can even use APIs to integrate with the latest AI tools, some examples from OpenAI are here: https://platform.openai.com/docs/quickstart?language-preference=curl\nOnce you are a bit more confident with how APIs work, why not try designing one? For example, how would you go about designing an API for a publisher to allow them to keep track of books, editions and authors?",
    "crumbs": [
      "TOPIC GUIDES",
      "APIs: A starter guide for Librarians"
    ]
  },
  {
    "objectID": "api.html#recommended-readingviewing",
    "href": "api.html#recommended-readingviewing",
    "title": "APIs: A starter guide for Librarians",
    "section": "Recommended Reading/Viewing",
    "text": "Recommended Reading/Viewing\nMany great resources are available on the web to tell you more about APIs.\n\nIntroduction to APIs | DARIAH-Campus (embed video)\nWhat is an API? IBM https://www.ibm.com/think/topics/api\nWhat is a REST API? Postman: https://www.youtube.com/watch?v=PfujVETI-i4\nWhat is a REST API? IBM: https://www.youtube.com/watch?v=lsMQRaeKNDk\nUK Government list of APIs: https://www.api.gov.uk/#uk-public-sector-apis\nWhat is an API? Trove API introduction - GLAM Workbench",
    "crumbs": [
      "TOPIC GUIDES",
      "APIs: A starter guide for Librarians"
    ]
  },
  {
    "objectID": "api.html#finding-communities-of-practice",
    "href": "api.html#finding-communities-of-practice",
    "title": "APIs: A starter guide for Librarians",
    "section": "Finding Communities of Practice",
    "text": "Finding Communities of Practice\nThis guide is intended only as a first step for starting your journey with APIs and as you start experimenting and getting hands-on experience you will undoubtedly have further questions or need for support from those who have experience with APIs. Many organisations providing APIs will have support or contact info for questions and troubleshooting so look out for those. You can also join a community such as AI4LAM community where you can connect with lots of professionals working at the intersection of technology and cultural heritage. Stackexchange is a popular discussion board where you can post your software related questions.",
    "crumbs": [
      "TOPIC GUIDES",
      "APIs: A starter guide for Librarians"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "RECOMMENDED READING LISTS",
    "section": "",
    "text": "RECOMMENDED READING LISTS\nThere is no shortage of recommended reading lists out there, here we try and highlight a few of the most up to date and useful lists out there for the sector today!\nZotero Library for Digital Scholarship and Data Science Essentials for Library Professionals\nThis library contains links to all of the resources referenced within Topic Guides and across our site.\nZotero | Groups &gt; collections as data - projects, initiatives, readings, tools, datasets\nOngoing collection of projects, readings, initiatives, tools, and datasets that are in some way or another related to collections as data. This group is an open resource, welcoming contributions from anyone who has a resource to share.\n[TODO] Data Science in Libraries, is there a Zotero?"
  }
]